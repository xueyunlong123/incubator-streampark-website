<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-default" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.3">
<title data-rh="true">China Union&#x27;s Flink Real-Time Computing Platform Ops Practice | Apache StreamPark (incubating)</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://streampark.apache.org/blog/streampark-usercase-chinaunion"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="China Union&#x27;s Flink Real-Time Computing Platform Ops Practice | Apache StreamPark (incubating)"><meta data-rh="true" name="description" content="Abstract"><meta data-rh="true" property="og:description" content="Abstract"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2024-01-21T04:16:34.000Z"><meta data-rh="true" property="article:tag" content="StreamPark,Production Practice,FlinkSQL"><link data-rh="true" rel="icon" href="/image/favicon.ico"><link data-rh="true" rel="canonical" href="https://streampark.apache.org/blog/streampark-usercase-chinaunion"><link data-rh="true" rel="alternate" href="https://streampark.apache.org/blog/streampark-usercase-chinaunion" hreflang="en"><link data-rh="true" rel="alternate" href="https://streampark.apache.org/zh-CN/blog/streampark-usercase-chinaunion" hreflang="zh-CN"><link data-rh="true" rel="alternate" href="https://streampark.apache.org/blog/streampark-usercase-chinaunion" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Apache StreamPark (incubating) RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Apache StreamPark (incubating) Atom Feed"><link rel="stylesheet" href="/assets/css/styles.ba1da1ae.css">
<link rel="preload" href="/assets/js/runtime~main.1da04f6e.js" as="script">
<link rel="preload" href="/assets/js/main.74e43f65.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function e(e){document.documentElement.setAttribute("data-theme",e)}var t=function(){var e=null;try{e=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(e){}return e}()||function(){var e=null;try{e=localStorage.getItem("theme")}catch(e){}return e}();null!==t?e(t):window.matchMedia("(prefers-color-scheme: dark)").matches?e("dark"):window.matchMedia("(prefers-color-scheme: light)").matches?e("light"):e("dark")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/image/logo.png" alt="StreamPark Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/image/logo.png" alt="StreamPark Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div></a><a class="navbar__item navbar__link" href="/docs/intro">Documentation</a><a class="navbar__item navbar__link" href="/download">Download</a><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">Community</a><ul class="dropdown__menu"><li><a href="https://www.apache.org/foundation/policies/conduct" target="_blank" rel="noopener noreferrer" class="dropdown__link">Code of conduct</a></li><li><a class="dropdown__link" href="/community/contribution_guide/mailing_lists">Join the mailing lists</a></li><li><a class="dropdown__link" href="/community/contribution_guide/become_committer">Become A Committer</a></li><li><a class="dropdown__link" href="/community/contribution_guide/become_pmc_member">Become A PMC member</a></li><li><a class="dropdown__link" href="/community/contribution_guide/new_committer_process">New Committer Process</a></li><li><a class="dropdown__link" href="/community/contribution_guide/new_pmc_ember_process">New PMC Member Process</a></li><li><a class="dropdown__link" href="/community/submit_guide/document">Documentation Notice</a></li><li><a class="dropdown__link" href="/community/submit_guide/submit_code">Submit Code</a></li><li><a class="dropdown__link" href="/community/submit_guide/code_style_and_quality_guide">Code style and quality guide</a></li><li><a class="dropdown__link" href="/community/release/how_to_release">How to release</a></li><li><a class="dropdown__link" href="/community/release/how_to_verify_release">How to Verify Release</a></li></ul></div><a class="navbar__item navbar__link" href="/team">Team</a><a class="navbar__item navbar__link" href="/user">Users</a><div class="navbar__item dropdown dropdown--hoverable"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link">ASF</a><ul class="dropdown__menu"><li><a href="https://www.apache.org/" target="_blank" rel="noopener noreferrer" class="dropdown__link">Foundation</a></li><li><a href="https://www.apache.org/licenses/" target="_blank" rel="noopener noreferrer" class="dropdown__link">License</a></li><li><a href="https://www.apache.org/events/current-event" target="_blank" rel="noopener noreferrer" class="dropdown__link">Events</a></li><li><a href="https://www.apache.org/security/" target="_blank" rel="noopener noreferrer" class="dropdown__link">Security</a></li><li><a href="https://www.apache.org/foundation/sponsorship.html" target="_blank" rel="noopener noreferrer" class="dropdown__link">Sponsorship</a></li><li><a href="https://www.apache.org/foundation/policies/privacy.html" target="_blank" rel="noopener noreferrer" class="dropdown__link">Privacy</a></li><li><a href="https://www.apache.org/foundation/thanks.html" target="_blank" rel="noopener noreferrer" class="dropdown__link">Thanks</a></li></ul></div><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">Blog</a><a href="https://github.com/apache/incubator-streampark/issues/507" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">FAQ</a><a href="https://github.com/apache/incubator-streampark" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_nlXk"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>English</a><ul class="dropdown__menu"><li><a href="/blog/streampark-usercase-chinaunion" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="en">English</a></li><li><a href="/zh-CN/blog/streampark-usercase-chinaunion" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh-CN">简体中文</a></li></ul></div><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently dark mode)" aria-label="Switch between dark and light mode (currently dark mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"><div class="navbar__search searchBarContainer_NW3z"><input placeholder="Search" aria-label="Search" class="navbar__search-input"><div class="loadingRing_RJI3 searchBarLoadingRing_YnHq"><div></div><div></div><div></div><div></div></div></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="container-wrapper"><div class="container margin-vert--lg"><div class="row"><aside class="col col--2 overflow-hidden" style="opacity:0;transform:translateX(-100px) translateZ(0)"><nav class="sidebar_brwN thin-scrollbar" aria-label="Blog recent posts navigation"><div class="backButton_MCHS"><svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24"><path fill="currentColor" d="M8 7v4L2 6l6-5v4h5a8 8 0 1 1 0 16H4v-2h9a6 6 0 0 0 0-12H8Z"></path></svg></div><a class="sidebarItemTitle_r4Q1 margin-bottom--sm" href="/blog">近期文章</a><ul class="sidebarItemList_QwSx clean-list"><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/blog/streampark-flink-on-k8s">StreamPark Flink on Kubernetes practice</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/blog/flink-development-framework-streampark">StreamPark - Powerful Flink Development Framework</a></li><li class="sidebarItem_lnhn"><a aria-current="page" class="sidebarItemLink_yNGZ sidebarItemLinkActive_oSRm" href="/blog/streampark-usercase-chinaunion">China Union&#x27;s Flink Real-Time Computing Platform Ops Practice</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/blog/streampark-usercase-bondex-with-paimon">Based on Apache Paimon + StreamPark&#x27;s Streaming Data Warehouse Practice by Bondex</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/blog/streampark-usercase-shunwang">StreamPark in the Large-Scale Production Practice at Shunwang Technology</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/blog/streampark-usercase-dustess">StreamPark&#x27;s Best Practices at Dustess, Simplifying Complexity for the Ultimate Experience</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/blog/streampark-usercase-joyme">StreamPark&#x27;s Production Practice in Joyme</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/blog/streampark-usercase-haibo">An All-in-One Computation Tool in Haibo Tech&#x27;s Production Practice and facilitation in Smart City Construction</a></li><li class="sidebarItem_lnhn"><a class="sidebarItemLink_yNGZ" href="/blog/streampark-usercase-ziru">Ziroom&#x27;s Real-Time Computing Platform Practice Based on Apache StreamPark</a></li></ul></nav></aside><main class="col col--8 overflow-hidden" itemscope="" itemtype="http://schema.org/Blog"><div><div class="row" style="margin:0"><div class="col col--12 article__details article-bg"><article itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><meta itemprop="description" content="Abstract"><header><h1 class="margin-bottom--md blogPostTitle_thoQ text--center post--titleLink" itemprop="headline">China Union&#x27;s Flink Real-Time Computing Platform Ops Practice</h1><div class="container_iJTo margin-vert--md"><time datetime="2024-01-21T04:16:34.000Z" itemprop="datePublished">January 21, 2024</time> · <!-- -->17 min read</div></header><div id="__blog-post-container" class="markdown" itemprop="articleBody"><p><img loading="lazy" src="/assets/images/overall_architecture-efc4272dcb2fcdadac42d40cf1a6a931.png" width="1080" height="597" class="img_ev3q"></p><p><strong>Abstract:</strong> This article is compiled from the sharing of Mu Chunjin, the head of China Union Data Science&#x27;s real-time computing team and Apache StreamPark Committer, at the Flink Forward Asia 2022 platform construction session. The content of this article is mainly divided into four parts:</p><ul><li>Introduction to the Real-Time Computing Platform Background</li><li>Operational Challenges of Flink Real-Time Jobs</li><li>Integrated Management Based on StreamPark</li><li>Future Planning and Evolution</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="introduction-to-the-real-time-computing-platform-background"><strong>Introduction to the Real-Time Computing Platform Background</strong><a href="#introduction-to-the-real-time-computing-platform-background" class="hash-link" aria-label="Direct link to introduction-to-the-real-time-computing-platform-background" title="Direct link to introduction-to-the-real-time-computing-platform-background">​</a></h2><p>The image above depicts the overall architecture of the real-time computing platform. At the bottom layer, we have the data sources. Due to some sensitive information, the detailed information of the data sources is not listed. It mainly includes three parts: business databases, user behavior logs, and user location. China Union has a vast number of data sources, with just the business databases comprising tens of thousands of tables. The data is primarily processed through Flink SQL and the DataStream API. The data processing workflow includes real-time parsing of data sources by Flink, real-time computation of rules, and real-time products. Users perform real-time data subscriptions on the visualization subscription platform. They can draw an electronic fence on the map and set some rules, such as where the data comes from, how long it stays inside the fence, etc. They can also filter some features. User information that meets these rules will be pushed in real-time. Next is the real-time security part. If a user connects to a high-risk base station or exhibits abnormal operational behavior, we may suspect fraudulent activity and take actions such as shutting down the phone number, among other things. Additionally, there are some real-time features of users and a real-time big screen display.</p><p><img loading="lazy" src="/assets/images/data_processing_processes-6b611077be80fd421d883accd5acb423.png" width="1080" height="593" class="img_ev3q"></p><p>The image above provides a detailed workflow of data processing.</p><p>The first part is collection and parsing. Our data sources come from business databases, including OGG and DTS format messages, log messages, user behavior, and user location data, totaling over 50 different data sources. This number is expected to gradually increase. All data sources are processed in real-time using Flink, and Metrics have been added to monitor the latency of data sources.</p><p>The second part is real-time computing. This stage deals with a massive amount of data, in the trillions, supporting over 10,000 real-time data subscriptions. There are more than 200 Flink tasks. We encapsulate a certain type of business into a scenario, and a single Flink job can support multiple subscriptions in the same scenario. Currently, the number of Flink jobs is continuously increasing, and in the future, it might increase to over 500. One of the major challenges faced here is the real-time association of trillion-level data with electronic fences and user features on a daily basis. There are tens of thousands of electronic fences, and user features involve hundreds of millions of users. Initially, we stored electronic fence information and user features in HBase, but this led to significant pressure on HBase, frequent performance issues, and data latency. Furthermore, once data backlog occurred, it took a long time to clear. Thanks to the powerful Flink State, we have now stored the electronic fence information and user features in the state, which has adequately supported high-concurrency scenarios. We have also added performance monitoring for data processing. Finally, there are some applications for real-time products and marketing touchpoints on the front end.</p><p><img loading="lazy" src="/assets/images/platform_evolution-9d3427a9bb13529e6a6540f6a77e152b.png" width="1080" height="483" class="img_ev3q"></p><p>In 2018, we adopted a third-party black-box computing engine, which did not support flexible customization of personalized functions, and depended heavily on external systems, resulting in high loads on these external systems and complex operations and maintenance. In 2019, we utilized Spark Streaming&#x27;s micro-batch processing. From 2020, we began to use Flink for stream computing. Starting from 2021, almost all Spark Streaming micro-batch processing tasks have been replaced by Flink. At the same time, Apache StreamPark was launched to manage our Flink jobs.</p><p><img loading="lazy" src="/assets/images/platform_background-e591fd5ed3391480217c668f70519d28.png" width="1080" height="493" class="img_ev3q"></p><p>To summarize the platform background, it mainly includes the following parts:</p><ul><li>Large data volume: processing an average of trillions of data per day.</li><li>Numerous data sources: integrated with more than 50 types of real-time data sources.</li><li>Numerous subscriptions: supported more than 10,000 data service subscriptions.</li><li>Numerous users: supported the usage of more than 30 internal and external users.</li></ul><p><img loading="lazy" src="/assets/images/operational_background-dd9ae29be9c5d959a649bb9dd8f7a1dc.png" width="1080" height="562" class="img_ev3q"></p><p>The operational maintenance background can also be divided into the following parts:</p><ul><li>High support demand: More than 50 types of data sources, and over 10,000 data service subscriptions.</li><li>Numerous real-time jobs: Currently, there are 200+ Flink production jobs, and the number is continuously and rapidly increasing, potentially reaching 500+ in the future.</li><li>High frequency of launches: There are new or enhanced Flink jobs going live every day.</li><li>Numerous developers: Over 50 R&amp;D personnel are involved in developing Flink real-time computing tasks.</li><li>Numerous users: Over 30 internal and external organizations&#x27; users are utilizing the platform.</li><li>Low monitoring latency: Once an issue is identified, we must address it immediately to avoid user complaints.</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="flink-实时作业运维挑战"><strong>Flink 实时作业运维挑战</strong><a href="#flink-实时作业运维挑战" class="hash-link" aria-label="Direct link to flink-实时作业运维挑战" title="Direct link to flink-实时作业运维挑战">​</a></h2><p><img loading="lazy" src="/assets/images/difficulties-81db2f256a9e39ae8c9ba9730aa37585.png" width="1080" height="481" class="img_ev3q"></p><p>Given the platform and operational maintenance background, particularly with the increasing number of Flink jobs, we have encountered significant challenges in two main areas: job operation and maintenance dilemmas, and business support difficulties.</p><p>In terms of job operation and maintenance dilemmas, firstly, the job deployment process is lengthy and inefficient. Under China Union&#x27;s principle that security is the top priority, deploying programs on servers involves connecting to a VPN, logging in through the 4A system, packaging and compiling, deploying, and then starting the program. This entire process is quite long. Initially, when developing Flink, we started jobs using scripts, leading to uncontrollable code branches. After deployment, it was also difficult to trace back. Moreover, it&#x27;s challenging to synchronize scripts with code on git because developers tend to prefer directly modifying scripts on the server, easily forgetting to upload changes to git.</p><p>Due to various factors in the job operation and maintenance difficulties, business support challenges arise, such as a high rate of failures during launch, impact on data quality, lengthy launch times, high data latency, and issues with missed alarm handling, leading to complaints. In addition, the impact on our business is unclear, and once a problem arises, addressing the issue becomes the top priority.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="基于-streampark-一体化管理"><strong>基于 StreamPark 一体化管理</strong><a href="#基于-streampark-一体化管理" class="hash-link" aria-label="Direct link to 基于-streampark-一体化管理" title="Direct link to 基于-streampark-一体化管理">​</a></h2><p><img loading="lazy" src="/assets/images/job_management-57ac8eebee7ab32d4d55008faade15ff.png" width="1080" height="510" class="img_ev3q"></p><p>In response to the two dilemmas mentioned above, we have resolved many issues through StreamPark&#x27;s integrated management. First, let&#x27;s take a look at the dual evolution of StreamPark, which includes Flink Job Management and Flink Job DevOps Platform. In terms of job management, StreamPark supports deploying Flink real-time jobs to different clusters, such as Flink&#x27;s native Standalone mode, and the Session, Application, and PerJob modes of Flink on Yarn. In the latest version, it will support Kubernetes Native Session mode. The middle layer includes project management, job management, cluster management, team management, variable management, and alarm management.</p><ul><li>Project Management: When deploying a Flink program, you can fill in the git address in project management and select the branch you want to deploy.</li><li>Job Management: You can specify the execution mode of the Flink job, such as which type of cluster you want to submit to. You can also configure some resources, such as the number of TaskManagers, the memory size of TaskManager/JobManager, parallelism, etc. Additionally, you can set up some fault tolerance measures; for instance, if a Flink job fails, StreamPark can support automatic restarts, and it also supports the input of some dynamic parameters.</li><li>Cluster Management: You can add and manage big data clusters through the interface.</li><li>Team Management: In the actual production process of an enterprise, there are multiple teams, and these teams are isolated from each other.</li><li>Variable Management: You can maintain some variables in one place. For example, you can define Kafka&#x27;s Broker address as a variable. When configuring Flink jobs or SQL, you can replace the Broker&#x27;s IP with a variable. Moreover, if this Kafka needs to be decommissioned later, you can also use this variable to check which jobs are using this cluster, facilitating some subsequent processes.</li><li>Alarm Management: Supports multiple alarm modes, such as WeChat, DingTalk, SMS, and email.</li></ul><p>StreamPark supports the submission of Flink SQL and Flink Jar, allows for resource configuration, and supports state tracking, indicating whether the state is running, failed, etc. Additionally, it provides a metrics dashboard and supports the viewing of various logs.</p><p><img loading="lazy" src="/assets/images/devops_platform-97e53d17c155a4d98431a1ab52a7bd13.png" width="1080" height="501" class="img_ev3q"></p><p>The Flink Job DevOps platform primarily consists of the following parts:</p><ul><li>Teams: StreamPark supports multiple teams, each with its team administrator who has all permissions. There are also team developers who only have a limited set of permissions.</li><li>Compilation and Packaging: When creating a Flink project, you can configure the git address, branch, and packaging commands in the project, and then compile and package with a single click of the build button.</li><li>Release and Deployment: During release and deployment, a Flink job is created. Within the Flink job, you can choose the execution mode, deployment cluster, resource settings, fault tolerance settings, and fill in variables. Finally, the Flink job can be started or stopped with a single click.</li><li>State Monitoring: After the Flink job is started, real-time tracking of its state begins, including Flink&#x27;s running status, runtime duration, Checkpoint information, etc. There is also support for one-click redirection to Flink&#x27;s Web UI.</li><li>Logs and Alerts: This includes logs from the build and start-up processes and supports alerting methods such as DingTalk, WeChat, email, and SMS.</li></ul><p><img loading="lazy" src="/assets/images/multi_team_support-ea9b19ef43d528e9be9016efa65f80fc.png" width="1080" height="477" class="img_ev3q"></p><p>Companies generally have multiple teams working on real-time jobs simultaneously. In our company, this includes a real-time data collection team, a data processing team, and a real-time marketing team. StreamPark supports resource isolation for multiple teams.</p><p><img loading="lazy" src="/assets/images/platformized_management-f3f784103707c8e3b67a3bcdda5a3dd6.png" width="1080" height="600" class="img_ev3q"></p><p>Management of the Flink job platform faces the following challenges:</p><ul><li>Numerous scripts: There are several hundred scripts on the platform, scattered across multiple servers.</li><li>Various types of scripts: When starting Flink jobs, there are start scripts, stop scripts, and daemon scripts, and it is very difficult to control operation permissions.</li><li>Inconsistent scripts: The scripts on the server are inconsistent with the scripts on git.</li><li>Difficult to ascertain script ownership: It is unclear who is responsible for the Flink jobs and their purpose.</li><li>Uncontrollable branches: When starting a job, you need to specify the git branch in the script, resulting in untraceable branches.</li></ul><p>Based on the challenges mentioned above, StreamPark has addressed the issues of unclear ownership and untraceable branches through project management. This is because when creating a project, you need to manually specify certain branches. Once the packaging is successful, these branches are recorded. Job management centralizes configurations, preventing scripts from being too dispersed. Additionally, there is strict control over the permissions for starting and stopping jobs, preventing an uncontrollable state due to script permissions. StreamPark interacts with clusters through interfaces to obtain job information, allowing for more precise job control.</p><p>Referring to the image above, you can see at the bottom of the diagram that packaging is conducted through project management, configuration is done via job management, and then it is released. This process allows for one-click start and stop operations, and jobs can be submitted through the API.</p><p><img loading="lazy" alt="图片" src="/assets/images/development_efficiency-2b27930ac18721c40acb006c03806e69.png" width="1080" height="591" class="img_ev3q"></p><p>In the early stages, we needed to go through seven steps for deployment, including connecting to a VPN, logging in through 4A, executing compile scripts, executing start scripts, opening Yarn, searching for the job name, and entering the Flink UI. StreamPark supports one-click deployment for four of these steps, including one-click packaging, one-click release, one-click start, and one-click access to the Flink UI.</p><p><img loading="lazy" alt="图片" src="/assets/images/submission_process-bb3efd39e3f2e76595995647327be75a.png" width="1080" height="548" class="img_ev3q"></p><p>The image above illustrates the job submission process of our StreamPark platform. Firstly, StreamPark proceeds to release the job, during which some resources are uploaded. Following that, the job is submitted, accompanied by various configured parameters, and it is published to the cluster using the Flink Submit method via an API call. At this point, there are multiple Flink Submit instances corresponding to different execution modes, such as Yarn Session, Yarn Application, Kubernetes Session, Kubernetes Application, and so on; all of these are controlled here. After submitting the job, if it is a Flink on Yarn job, the platform will acquire the Application ID or Job ID of the Flink job. This ID is then stored in our database. Similarly, if the job is executed based on Kubernetes, a Job ID will be obtained. Subsequently, when tracking the job status, we primarily use these stored IDs to monitor the state of the job.</p><p><img loading="lazy" alt="图片" src="/assets/images/status_acquisition_bottleneck-436fee79261994fd26eda735d2833e70.png" width="1080" height="599" class="img_ev3q"></p><p>As mentioned above, in the case of Flink on Yarn jobs, two IDs are acquired upon job submission: the Application ID and the Job ID. These IDs are used to retrieve the job status. However, when there is a large number of Flink jobs, certain issues may arise. StreamPark utilizes a status retriever that periodically sends requests to the ResourceManager every five seconds, using the Application ID or Job ID stored in our database. If there are a considerable number of jobs, during each polling cycle, the ResourceManager is responsible for calling the Job Manager&#x27;s address to access its status. This can lead to significant pressure on the number of connections to the ResourceManager and an overall increase in the number of connections.</p><p>In the diagram mentioned earlier, the connection count to the ResourceManager shows periodic and sustained increases, indicating that the ResourceManager is in a relatively critical state. This is evidenced by monitoring data from the server, which indeed shows a higher number of connections to the ResourceManager.</p><p><img loading="lazy" alt="图片" src="/assets/images/state_optimization-06c675fa387cb316cc225fb0b1576451.png" width="1080" height="596" class="img_ev3q"></p><p>To address the issues mentioned above, we have made some optimizations in StreamPark. Firstly, after submitting a job, StreamPark saves the Application ID or Job ID, and it also retrieves and stores the direct access address of the Job Manager in the database. Therefore, instead of polling the ResourceManager for job status, it can directly call the addresses of individual Job Managers to obtain the real-time status. This significantly reduces the number of connections to the ResourceManager. As can be seen from the latter part of the diagram above, there are basically no significant spikes in connection counts, which substantially alleviates the pressure on the ResourceManager. Moreover, this ensures that as the number of Flink jobs continues to grow, the system will not encounter bottlenecks in status retrieval.</p><p><img loading="lazy" alt="图片" src="/assets/images/state_recovery-7d0a5ecaf3c3af7ffe33f85abf3d51a8.png" width="1080" height="573" class="img_ev3q"></p><p>Another issue that StreamPark resolves is safeguarding Flink&#x27;s state recovery. In the past, when we used scripts for operations and maintenance, especially during business upgrades, it was necessary to recover from the latest checkpoint when starting Flink. However, developers often forgot to recover from the previous checkpoint, leading to significant data quality issues and complaints. StreamPark&#x27;s process is designed to mitigate this issue. Upon the initial start of a Flink job, it polls every five seconds to retrieve checkpoint records, saving them in a database. When manually stopping a Flink job through StreamPark, users have the option to perform a savepoint. If this option is selected, the path of the savepoint is saved in the database. In addition, records of each checkpoint are also stored in the database. When restarting a Flink job, the system defaults to using the latest checkpoint or savepoint record. This effectively prevents issues associated with failing to recover from the previous checkpoint. It also avoids the resource wastage caused by having to rerun jobs with offset rollbacks to address problems, while ensuring consistency in data processing.</p><p><img loading="lazy" alt="图片" src="/assets/images/multiple_environments_and_components-85e9f3f218c9c5ef79d3792aec9540ac.png" width="1080" height="576" class="img_ev3q"></p><p>StreamPark also addresses the challenges associated with referencing multiple components across various environments. In a corporate setting, there are typically multiple environments, such as development, testing, and production. Each environment generally includes multiple components, such as Kafka, HBase, Redis, etc. Additionally, within a single environment, there may be multiple instances of the same component. For example, in a real-time computing platform at China Union, when consuming data from an upstream Kafka cluster and writing the relevant data to a downstream Kafka cluster, two sets of Kafka are involved within the same environment. It can be challenging to determine the specific environment and component based solely on IP addresses. To address this, we define the IP addresses of all components as variables. For instance, the Kafka cluster variable, Kafka.cluster, exists in development, testing, and production environments, but it points to different Broker addresses in each. Thus, regardless of the environment in which a Flink job is configured, referencing this variable is sufficient. This approach significantly reduces the incidence of operational failures in production environments.</p><p><img loading="lazy" alt="图片" src="/assets/images/multiple_execution_modes-56bb5cc794122dd7ac987f57999afb33.png" width="1080" height="585" class="img_ev3q"></p><p>StreamPark supports multiple execution modes for Flink, including three deployment modes based on Yarn: Application, Perjob, and Session. Additionally, it supports two deployment modes for Kubernetes: Application and Session, as well as some Remote modes.</p><p><img loading="lazy" alt="图片" src="/assets/images/versioning-641f09a5fcccd37dda2ed9d4cac14413.png" width="1080" height="389" class="img_ev3q"></p><p>StreamPark also supports multiple versions of Flink. For example, while our current version is 1.14.x, we would like to experiment with the new 1.16.x release. However, it’s not feasible to upgrade all existing jobs to 1.16.x. Instead, we can opt to upgrade only the new jobs to 1.16.x, allowing us to leverage the benefits of the new version while maintaining compatibility with the older version.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="future-planning-and-evolution"><strong>Future Planning and Evolution</strong><a href="#future-planning-and-evolution" class="hash-link" aria-label="Direct link to future-planning-and-evolution" title="Direct link to future-planning-and-evolution">​</a></h2><p><img loading="lazy" alt="图片" src="/assets/images/contribution_and_enhancement-bbb20c198ecc048735b12e40157115e2.png" width="1080" height="418" class="img_ev3q"></p><p>In the future, we will increase our involvement in the development of StreamPark, and we have planned the following directions for enhancement:</p><ul><li>High Availability: StreamPark currently does not support high availability, and this aspect needs further strengthening.</li><li>State Management: In enterprise practices, each operator in a Flink job has a UID. If the Flink UID is not set, it could lead to situations where state recovery is not possible when upgrading the Flink job. This issue cannot be solved through the platform at the moment. Therefore, we plan to add this functionality to the platform. We will introduce a feature that checks whether the operator has a UID set when submitting a Flink Jar. If not, a reminder will be issued to avoid state recovery issues every time a Flink job is deployed. Previously, when facing such situations, we had to use the state processing API to deserialize from the original state, and then create a new state using the state processing API for the upgraded Flink to load.</li><li>More Detailed Monitoring: Currently, StreamPark supports sending alerts when a Flink job fails. We hope to also send alerts when a Task fails, and need to know the reason for the failure. In addition, enhancements are needed in job backpressure monitoring alerts, Checkpoint timeout alerts, failure alerts, and performance metric collection.</li><li>Stream-Batch Integration: Explore a platform that integrates both streaming and batch processing, combining the Flink stream-batch unified engine with data lake storage that supports stream-batch unification.</li></ul><p><img loading="lazy" src="/assets/images/road_map-1a30ee719bdadf2e0ea31d6ea9e957bc.png" width="1080" height="488" class="img_ev3q"></p><p>The above diagram represents the Roadmap for StreamPark.</p><ul><li>Data Source: StreamPark will support rapid integration with more data sources, achieving one-click data onboarding.</li><li>Operation Center: Acquire more Flink Metrics to further enhance the capabilities in monitoring and operation.</li><li>K8S-operator: The existing Flink on K8S is somewhat cumbersome, having gone through the processes of packaging Jars, building images, and pushing images. There is a need for future improvements and optimization, and we are actively embracing the upstream K8S-operator integration.</li><li>Streaming Data Warehouse: Enhance support for Flink SQL job capabilities, simplify the submission of Flink SQL jobs, and plan to integrate with Flink SQL Gateway. Enhance capabilities in the SQL data warehouse domain, including metadata storage, unified table creation syntax validation, runtime testing, and interactive queries, while actively embracing Flink upstream to explore real-time data warehouses and streaming data warehouses.</li></ul></div><footer class="row docusaurus-mt-lg blogPostFooterDetailsFull_Wr5y"><div class="post-footer"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/stream-park">StreamPark</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/production-practice">Production Practice</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/flink-sql">FlinkSQL</a></li></ul></div><div class="col col-3 text--right"><a href="https://github.com/apache/incubator-streampark-website/edit/dev/blog/2-streampark-usercase-chinaunion.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div></div></footer></article></div></div></div><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/blog/flink-development-framework-streampark"><div class="pagination-nav__sublabel">Newer Post</div><div class="pagination-nav__label">StreamPark - Powerful Flink Development Framework</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/blog/streampark-usercase-bondex-with-paimon"><div class="pagination-nav__sublabel">Older Post</div><div class="pagination-nav__label">Based on Apache Paimon + StreamPark&#x27;s Streaming Data Warehouse Practice by Bondex</div></a></nav></main><div class="col col--2"><div class="tableOfContents_jeP5 thin-scrollbar" style="opacity:0;transform:translateX(100px) translateZ(0)"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#introduction-to-the-real-time-computing-platform-background" class="table-of-contents__link toc-highlight"><strong>Introduction to the Real-Time Computing Platform Background</strong></a></li><li><a href="#flink-实时作业运维挑战" class="table-of-contents__link toc-highlight"><strong>Flink 实时作业运维挑战</strong></a></li><li><a href="#基于-streampark-一体化管理" class="table-of-contents__link toc-highlight"><strong>基于 StreamPark 一体化管理</strong></a></li><li><a href="#future-planning-and-evolution" class="table-of-contents__link toc-highlight"><strong>Future Planning and Evolution</strong></a></li></ul></div></div></div></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title"></div><ul class="footer__items clean-list"><li class="footer__item">
                  <div class="footer-left-box">
                    <div class="flex align-center footer-system">
                      <span class="system-title">About StreamPark</span>
                    </div>
                    <p>Make stream processing easier! easy-to-use streaming application development framework and operation platform</p>
                  </div>
                </li></ul></div><div class="col footer__col"><div class="footer__title">Resource</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/intro">Documentation</a></li><li class="footer__item"><a href="https://github.com/apache/incubator-streampark/releases" target="_blank" rel="noopener noreferrer" class="footer__link-item">Releases<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://github.com/apache/incubator-streampark/issues/507" target="_blank" rel="noopener noreferrer" class="footer__link-item">FAQ<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/apache/incubator-streampark" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://github.com/apache/incubator-streampark/issues" target="_blank" rel="noopener noreferrer" class="footer__link-item">Issue Tracker<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://github.com/apache/incubator-streampark/pulls" target="_blank" rel="noopener noreferrer" class="footer__link-item">Pull Requests<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">Follow</div><ul class="footer__items clean-list"><li class="footer__item">
                <div class="subscribe-box">
                  <div class="d-flex align-items-center" style="margin-bottom: 30px;padding-top: 11px">
                    <div class="subscribe-input flex-fill">
                      <input class="form-control" id="email_address" maxlength="60" name="email_address" placeholder="Subscribe with us">
                    </div>
                    <div class="subscribe-submit-inner">
                      <a class="btn btn-white m-0" type="submit" href="mailto:dev-subscribe@streampark.apache.org">
                        <span><i class="fa fa-paper-plane text-white"></i></span>
                      </a>
                    </div>
                  </div>
                  <ul class="icon-bottom">
                    <li>
                      <a href="javascript:void(0)">
                        <i class="fa fa-wechat"></i>
                        <div class="wechat-dropdown"><img src="/image/join_wechat.png" alt="weChat"></div>
                      </a>
                    </li>
                    <li><a href="javascript:void(0)"><i class="fa fa-twitter"></i></a></li>
                    <li><a href="javascript:void(0)"><i class="fa fa-slack"></i></a></li>
                    <li><a href="javascript:void(0)"><i class="fa fa-facebook"></i></a></li>
                  </ul>
                </div>
              </li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">
        <div style="text-align: left;margin-top:30px">
          <div class="d-flex align-items-center">
            <div>
              <a href="https://incubator.apache.org/" class="footerLogoLink" one-link-mark="yes">
                <img src="/image/apache-incubator.svg" alt="Apache Incubator logo" class="footer__logo">
              </a>
            </div>
            <div>
              <p style="font-family: Avenir-Medium;font-size: 14px;color: #999;line-height: 25px;">
              Apache StreamPark is an effort undergoing incubation at The Apache Software Foundation (ASF), sponsored by the Apache Incubator. Incubation is required of all newly accepted projects until a further review indicates that the infrastructure, communications, and decision making process have stabilized in a manner consistent with other successful ASF projects. While incubation status is not necessarily a reflection of the completeness or stability of the code, it does indicate that the project has yet to be fully endorsed by the ASF.
              </p>
            </div>
          </div>

          <div style="border-top: 1px solid #525252;min-height: 60px;line-height: 25px;text-align: left;font-family: Avenir-Medium;font-size: 14px;color: #999;display: flex;align-items: center;">
            <span>
              Copyright © 2022-2024 The Apache Software Foundation. Apache StreamPark, StreamPark, and its feather logo are trademarks of The Apache Software Foundation.
            </span>
          </div>
        </div></div></div></div></footer></div>
<script src="/assets/js/runtime~main.1da04f6e.js"></script>
<script src="/assets/js/main.74e43f65.js"></script>
</body>
</html>