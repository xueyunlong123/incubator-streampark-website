<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://streampark.apache.org/blog</id>
    <title>Apache StreamPark (incubating) Blog</title>
    <updated>2024-01-21T04:16:34.000Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://streampark.apache.org/blog"/>
    <subtitle>Apache StreamPark (incubating) Blog</subtitle>
    <icon>https://streampark.apache.org/image/favicon.ico</icon>
    <entry>
        <title type="html"><![CDATA[StreamPark Flink on Kubernetes practice]]></title>
        <id>https://streampark.apache.org/blog/streampark-flink-on-k8s</id>
        <link href="https://streampark.apache.org/blog/streampark-flink-on-k8s"/>
        <updated>2024-01-21T04:16:34.000Z</updated>
        <summary type="html"><![CDATA[Wuxin Technology was founded in January 2018. The current main business includes the research and development, design, manufacturing and sales of RELX brand products. With core technologies and capabilities covering the entire industry chain, RELX is committed to providing users with products that are both high quality and safe]]></summary>
        <content type="html"><![CDATA[<p>Wuxin Technology was founded in January 2018. The current main business includes the research and development, design, manufacturing and sales of RELX brand products. With core technologies and capabilities covering the entire industry chain, RELX is committed to providing users with products that are both high quality and safe.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="why-choose-native-kubernetes"><strong>Why Choose Native Kubernetes</strong><a href="#why-choose-native-kubernetes" class="hash-link" aria-label="Direct link to why-choose-native-kubernetes" title="Direct link to why-choose-native-kubernetes">​</a></h2><p>Native Kubernetes offers the following advantages:</p><ul><li><p>Shorter Failover time</p></li><li><p>Resource hosting can be implemented without the need to manually create TaskManager Pods, which can be automatically destroyed</p></li><li><p>With more convenient HA, in Native Kubernetes mode after Flink version 1.12, you can rely on the Leader election mechanism of native Kubernetes to complete JobManager's HA</p><p>The main difference between Native Kubernetes and Standalone Kubernetes lies in the way Flink interacts with Kubernetes and the resulting series of advantages. Standalone Kubernetes requires users to customize the Kubernetes resource description files of JobManager and TaskManager. When submitting a job, you need to use kubectl combined with the resource description file to start the Flink cluster. The Native Kubernetes mode Flink Client integrates a Kubernetes Client, which can directly communicate with the Kubernetes API Server to complete the creation of JobManager Deployment and ConfigMap. After JobManager Development is created, the Resource Manager module in it can directly communicate with the Kubernetes API Server to complete the creation and destruction of TaskManager pods and the elastic scaling of Taskmanager. Therefore, it is recommended to use Flink on Native Kubernetes mode to deploy Flink tasks in production environments.</p></li></ul><p><img loading="lazy" src="/assets/images/nativekubernetes_architecture-ad376f8ae79ab66d90d95742e8335d53.png" width="1080" height="401" class="img_ev3q"></p><p>When Flink On Kubernetes meets StreamPark</p><p>  Flink on Native Kubernetes currently supports Application mode and Session mode. Compared with the two, Application mode deployment avoids the resource isolation problem and client resource consumption problem of Session mode. Therefore, it is recommended to use Application Mode to deploy Flink tasks in <strong> production environments. </strong>Let’s take a look at the method of using the original script and the process of using StreamPark to develop and deploy a Flink on Native Kubernetes job.
Deploy Kubernetes using scripts</p><p>In the absence of a platform that supports Flink on Kubernetes task development and deployment, you need to use scripts to submit and stop tasks. This is also the default method provided by Flink. The specific steps are as follows:</p><ol><li>Prepare the kubectl and Docker command running environment on the Flink client node, create the Kubernetes Namespace and Service Account used to deploy the Flink job, and perform RBAC</li><li>Write a Dockerfile file to package the Flink base image and the user’s job Jar together</li></ol><div class="language-dockerfile codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-dockerfile codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">FROM flink:1.13.6-scala_2.11</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">RUN mkdir -p $FLINK_HOME/usrlib</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">COPY my-flink-job.jar $FLINK_HOME/usrlib/my-flink-job.jar</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ol start="3"><li>Use Flink client script to start Flink tasks</li></ol><div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">./bin/flink run-application </span><span class="token punctuation" style="color:rgb(248, 248, 242)">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    --target kubernetes-application </span><span class="token punctuation" style="color:rgb(248, 248, 242)">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    -Dkubernetes.namespace</span><span class="token operator">=</span><span class="token plain">flink-cluster </span><span class="token punctuation" style="color:rgb(248, 248, 242)">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    -Dkubernetes.jobmanager.service-account</span><span class="token operator">=</span><span class="token plain">default </span><span class="token punctuation" style="color:rgb(248, 248, 242)">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    -Dkubernetes.cluster-id</span><span class="token operator">=</span><span class="token plain">my-first-application-cluster </span><span class="token punctuation" style="color:rgb(248, 248, 242)">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    -Dkubernetes.container.image</span><span class="token operator">=</span><span class="token plain">relx_docker_url/streamx/relx_flink_1.13.6-scala_2.11:latest </span><span class="token punctuation" style="color:rgb(248, 248, 242)">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    -Dkubernetes.rest-service.exposed.type</span><span class="token operator">=</span><span class="token plain">NodePort </span><span class="token punctuation" style="color:rgb(248, 248, 242)">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    local:///opt/flink/usrlib/my-flink-job.jar</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ol start="4"><li>Use the Kubectl command to obtain the WebUI access address and JobId of the Flink job.</li></ol><div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">kubectl -n flink-cluster get svc</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ol start="5"><li>Stop the job using Flink command</li></ol><div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">./bin/flink cancel</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    --target kubernetes-application</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    -Dkubernetes.cluster-id</span><span class="token operator">=</span><span class="token plain">my-first-application-cluster</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    -Dkubernetes.namespace</span><span class="token operator">=</span><span class="token plain">flink-cluster </span><span class="token operator">&lt;</span><span class="token plain">jobId</span><span class="token operator">&gt;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>  The above is the process of deploying a Flink task to Kubernetes using the most original script method provided by Flink. Only the most basic task submission is achieved. If it is to reach the production use level, there are still a series of problems that need to be solved, such as: the method is too Originally, it was unable to adapt to large batches of tasks, unable to record task checkpoints and real-time status tracking, difficult to operate and monitor tasks, had no alarm mechanism, and could not be managed in a centralized manner, etc.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="deploy-flink-on-kubernetes-using-streampark"><strong>Deploy Flink on Kubernetes using StreamPark</strong><a href="#deploy-flink-on-kubernetes-using-streampark" class="hash-link" aria-label="Direct link to deploy-flink-on-kubernetes-using-streampark" title="Direct link to deploy-flink-on-kubernetes-using-streampark">​</a></h2><p>  There will be higher requirements for using Flink on Kubernetes in enterprise-level production environments. Generally, you will choose to build your own platform or purchase related commercial products. No matter which solution meets the product capabilities: large-scale task development and deployment, status tracking, operation and maintenance monitoring , failure alarms, unified task management, high availability, etc. are common demands.</p><p>  In response to the above issues, we investigated open source projects in the open source field that support the development and deployment of Flink on Kubernetes tasks. During the investigation, we also encountered other excellent open source projects. After comprehensively comparing multiple open source projects, we came to the conclusion: <strong>StreamPark has great performance in either completness, user experience, or stability, so we finally chose StreamPark as our one-stop real-time computing platform. </strong></p><p>  Let’s take a look at how StreamPark supports Flink on Kubernetes:</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="basic-environment-configuration"><strong>Basic environment configuration</strong><a href="#basic-environment-configuration" class="hash-link" aria-label="Direct link to basic-environment-configuration" title="Direct link to basic-environment-configuration">​</a></h3><p>  Basic environment configuration includes Kubernetes and Docker repository information as well as Flink client information configuration. The simplest way for the Kubernetes basic environment is to directly copy the .kube/config of the Kubernetes node to the StreamPark node user directory, and then use the kubectl command to create a Flink-specific Kubernetes Namespace and perform RBAC configuration.</p><div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token comment" style="color:rgb(98, 114, 164)"># Create k8s namespace used by Flink jobs</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">kubectl create ns flink-cluster</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Bind RBAC resources to the default user</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">kubectl create clusterrolebinding flink-role-binding-default --clusterrole</span><span class="token operator">=</span><span class="token plain">edit --serviceaccount</span><span class="token operator">=</span><span class="token plain">flink-cluster:default</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Docker account information can be configured directly in the Docker Setting interface:</p><p><img loading="lazy" src="/assets/images/docker_setting-80acf43cf64fd390e4d50da8830671c0.png" width="1080" height="586" class="img_ev3q"></p><p>StreamPark can adapt to multi-version Flink job development. The Flink client can be configured directly on the StreamPark Setting interface:</p><p><img loading="lazy" src="/assets/images/flinkversion_setting-b170a43882590683ea0c7f109f909396.png" width="1080" height="352" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="job-development"><strong>Job development</strong><a href="#job-development" class="hash-link" aria-label="Direct link to job-development" title="Direct link to job-development">​</a></h3><p>After StreamPark has configured the basic environment, it only takes three steps to develop and deploy a Flink job:</p><p><img loading="lazy" src="/assets/images/development_process-476918cfd29159983fe26b36ef487895.png" width="1080" height="271" class="img_ev3q"></p><p>  StreamPark supports both Upload Jar and direct writing of Flink SQL jobs. <strong>Flink SQL jobs only need to enter SQL and dependencies. This method greatly improves the development experience and avoids problems such as dependency conflicts.</strong> This article does not focus on this part。</p><p>  Here you need to select the deployment mode as kubernetes application, and configure the following parameters on the job development page: The parameters in the red box are the basic parameters of Flink on Kubernetes.</p><p><img loading="lazy" src="/assets/images/kubernetes_base_parameters-1a28fec8d9d3dc57744324db4ef58551.png" width="1080" height="1104" class="img_ev3q"></p><p>  The following parameters are parameters related to Flink jobs and resources. The choice of Resolve Order is related to the code loading mode. For jobs uploaded by the Upload Jar developed by the DataStream API, choose to use Child-first, and for Flink SQL jobs, choose to use Parent-first loading.</p><p><img loading="lazy" src="/assets/images/flink_parameters-ff7790882a753bd88fbf5db9b775a0e3.png" width="1080" height="1133" class="img_ev3q"></p><p>  Finally, there are the following two heavyweight parameters. For Native Kubernetes, k8s-pod-template generally only requires pod-template configuration. Dynamic Option is a supplement to the pod-template parameters. For some personalized configurations, you can Configured in Dynamic Option. For more Dynamic Option, please directly refer to the Flink official website.</p><p><img loading="lazy" src="/assets/images/pod_template-722285f448ec8adc0fa939d0baea2d10.png" width="1080" height="1104" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="job-online"><strong>Job online</strong><a href="#job-online" class="hash-link" aria-label="Direct link to job-online" title="Direct link to job-online">​</a></h3><p>After the job development is completed, the job comes online. In this step, StreamPark has done a lot of work, as follows:</p><ul><li>Prepare environment</li><li>Dependency download in job</li><li>Build job (JAR package)</li><li>Build image</li><li>Push the image to the remote repository</li></ul><p><strong>For users: Just click the cloud-shaped online button in the task list</strong></p><p><img loading="lazy" src="/assets/images/operation-067a84b9b5b1491206780076f98e6f8d.png" width="1080" height="573" class="img_ev3q"></p><p>We can see a series of work done by StreamPark when building and pushing the image: <strong>Read the configuration, build the image, and push the image to the remote repository...</strong> I want to give StreamPark a big thumbs up!</p><p><img loading="lazy" src="/assets/images/step_details-301b14f2dbfa9c41f4c0e75a9086f0a4.png" width="948" height="1866" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="assignment-submission"><strong>Assignment submission</strong><a href="#assignment-submission" class="hash-link" aria-label="Direct link to assignment-submission" title="Direct link to assignment-submission">​</a></h3><p>  Finally, you only need to click the start Application button in Operation to start a Flink on Kubernetes job. After the job is successfully started, click on the job name to jump to the Jobmanager WebUI page. The whole process is very simple and smooth.</p><p><img loading="lazy" src="/assets/images/homework_submit-1f05dacf0fedfd1423f89ca2dec28437.png" width="1080" height="698" class="img_ev3q"></p><p>  The entire process only requires the above three steps to complete the development and deployment of a Flink on Kubernetes job on StreamPark. StreamPark's support for Flink on Kubernetes goes far beyond simply submitting a task.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="job-management"><strong>Job management</strong><a href="#job-management" class="hash-link" aria-label="Direct link to job-management" title="Direct link to job-management">​</a></h3><p><strong>After the job is submitted, StreamPark can obtain the latest checkpoint address of the task, the running status of the task, and the real-time resource consumption information of the cluster in real time. It can very conveniently start and stop the running task with one click, and supports recording the savepoint location when stopping the job. , as well as functions such as restoring the state from savepoint when restarting, thus ensuring the data consistency of the production environment and truly possessing the one-stop development, deployment, operation and maintenance monitoring capabilities of Flink on Kubernetes.</strong></p><p>Next, let’s take a look at how StreamPark supports this capability:</p><ul><li><p><strong>Record checkpoint in real time</strong></p><p>After the job is submitted, sometimes it is necessary to change the job logic but to ensure data consistency, then the platform needs to have the ability to record the location of each checkpoint in real time, as well as the ability to record the last savepoint location when stopped. StreamPark is on Flink on Kubernetes This function is implemented very well. By default, checkpoint information will be obtained and recorded in the corresponding table every 5 seconds, and according to the policy of retaining the number of checkpoints in Flink, only state.checkpoints.num-retained will be retained, and the excess will be deleted. There is an option to check the savepoint when the task is stopped. If the savepoint option is checked, the savepoint operation will be performed when the task is stopped, and the specific location of the savepoint will also be recorded in the table.</p><p>The root path of the default savepoint only needs to be configured in the Flink Home flink-conf.yaml file to automatically identify it. In addition to the default address, the root path of the savepoint can also be customized and specified when stopping.</p></li></ul><p><img loading="lazy" src="/assets/images/savepoint-b0288f5293875d156f20dbe768384076.png" width="1080" height="446" class="img_ev3q"></p><p><img loading="lazy" src="/assets/images/checkpoint-acf7379b24a3bac6695a517b425f466b.png" width="1080" height="479" class="img_ev3q"></p><ul><li><p><strong>Track running status in real time</strong></p><p>For challenges in the production environment, a very important point is whether monitoring is in place, especially for Flink on Kubernetes. This is very important and is the most basic capability. StreamPark can monitor the running status of Flink on Kubernetes jobs in real time and display it to users on the platform. Tasks can be easily retrieved based on various running statuses on the page.</p></li></ul><p><img loading="lazy" src="/assets/images/run_status-5a663d9169c0bce8f4cfb993db77ae59.png" width="1080" height="617" class="img_ev3q"></p><ul><li><p><strong>Complete alarm mechanism</strong></p><p>In addition, StreamPark also has complete alarm functions: supporting email, DingTalk, WeChat and SMS, etc. This is also an important reason why the company chose StreamPark as the one-stop platform for Flink on Kubernetes after initial research.</p></li></ul><p><img loading="lazy" src="/assets/images/alarm-c2104c1839a1b4bb668d48f092f25faa.png" width="1080" height="393" class="img_ev3q"></p><p>  From the above, we can see that StreamPark has the capabilities to support the development and deployment process of Flink on Kubernetes, including: <strong> job development capabilities, deployment capabilities, monitoring capabilities, operation and maintenance capabilities, exception handling capabilities, etc. StreamPark provides a relatively complete set of s solution. And it already has some CICD/DevOps capabilities, and the overall completion level continues to improve. It is a product that supports the full link of Flink on Kubernetes one-stop development, deployment, operation and maintenance work in the entire open source field. StreamPark is worthy of praise. </strong></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="streamparks-implementation-in-wuxin-technology"><strong>StreamPark’s implementation in Wuxin Technology</strong><a href="#streamparks-implementation-in-wuxin-technology" class="hash-link" aria-label="Direct link to streamparks-implementation-in-wuxin-technology" title="Direct link to streamparks-implementation-in-wuxin-technology">​</a></h2><p>  StreamPark was launched late in Wuxin Technology. It is currently mainly used for the development and deployment of real-time data integration jobs and real-time indicator calculation jobs. There are Jar tasks and Flink SQL tasks, all deployed using Native Kubernetes; data sources include CDC, Kafka, etc., and Sink end There are Maxcompute, kafka, Hive, etc. The following is a screenshot of the company's development environment StreamPark platform:</p><p><img loading="lazy" src="/assets/images/screenshot-2906914515b810aadb10db951d4f02bd.png" width="1080" height="706" class="img_ev3q"></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="problems-encountered">Problems encountered<a href="#problems-encountered" class="hash-link" aria-label="Direct link to Problems encountered" title="Direct link to Problems encountered">​</a></h2><p>  Any new technology has a process of exploration and fall into pitfalls. The experience of failure is precious. Here are some pitfalls and experiences that StreamPark has stepped into during the implementation of fog core technology. <strong>The content of this section is not only about StreamPark. I believe it will bring some reference to all friends who use Flink on Kubernetes</strong>.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="faqs-are-summarized-below"><strong>FAQs are summarized below</strong><a href="#faqs-are-summarized-below" class="hash-link" aria-label="Direct link to faqs-are-summarized-below" title="Direct link to faqs-are-summarized-below">​</a></h3><ul><li><p><strong>Kubernetes pod failed to pull the image</strong></p><p>The main problem is that Kubernetes pod-template lacks docker’s imagePullSecrets</p></li><li><p><strong>Scala version inconsistent</strong></p><p>Since StreamPark deployment requires a Scala environment, and Flink SQL operation requires the Flink SQL Client provided by StreamPark, it is necessary to ensure that the Scala version of the Flink job is consistent with the Scala version of StreamPark.</p></li><li><p><strong>Be aware of class conflicts</strong></p><p>When developing Flink SQL jobs, you need to pay attention to whether there are any class conflicts between the Flink image and the Flink connector and UDF. The best way to avoid class conflicts is to make the Flink image and the commonly used Flink connector and user UDF into a usable basic image. After that, other Flink SQL jobs can be reused directly.</p></li><li><p><strong>How to store checkpoint without Hadoop environment?</strong></p><p>HDFS, Alibaba Cloud OSS/AWS S3 can both perform checkpoint and savepoint storage. The Flink basic image already has support for OSS and S3. If you do not have HDFS, you can use Alibaba Cloud OSS or S3 to store status and checkpoint and savepoint data. You only need to use Flink Simply configure it in the dynamic parameters.</p></li></ul><div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">-Dstate.backend</span><span class="token operator">=</span><span class="token plain">rocksdb</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">-Dcontainerized.master.env.ENABLE_BUILT_IN_PLUGINS</span><span class="token operator">=</span><span class="token plain">flink-oss-fs-hadoop-1.13.6.jar</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">-Dcontainerized.taskmanager.env.ENABLE_BUILT_IN_PLUGINS</span><span class="token operator">=</span><span class="token plain">flink-oss-fs-hadoop-1.13.6.jar</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">-Dfs.oss.endpoint</span><span class="token operator">=</span><span class="token plain">xxyy.aliyuncs.com</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">-Dfs.oss.accessKeyId</span><span class="token operator">=</span><span class="token plain">xxxxxxxxxx</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">-Dfs.oss.accessKeySecret</span><span class="token operator">=</span><span class="token plain">xxxxxxxxxx</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">-Dstate.checkpoints.dir</span><span class="token operator">=</span><span class="token plain">oss://realtime-xxx/streamx/dev/checkpoints/</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">-Dstate.savepoints.dir</span><span class="token operator">=</span><span class="token plain">oss://realtime-xxx/streamx/dev/savepoints/</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><p><strong>The changed code did not take effect after it was republished</strong></p><p>This issue is related to the Kubernetes pod image pull policy. It is recommended to set the Pod image pull policy to Always:</p></li></ul><div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">‍-Dkubernetes.container.image.pull-policy</span><span class="token operator">=</span><span class="token plain">Always</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><p><strong>Each restart of the task will result in one more Job instance</strong></p><p>Under the premise that kubernetes-based HA is configured, when you need to stop the Flink task, you need to use cancel of StreamPark. Do not delete the Deployment of the Flink task directly through the kubernetes cluster. Because Flink's shutdown has its own shutdown process, when deleting a pod, the corresponding configuration files in the Configmap will also be deleted. Direct deletion of the pod will result in the remnants of the Configmap. When a task with the same name is restarted, two identical jobs will appear because at startup, the task will load the remaining configuration files and try to restore the closed task.</p></li><li><p><strong>How to implement kubernetes pod domain name access</strong></p><p>Domain name configuration only needs to be configured in pod-template according to Kubernetes resources. I can share with you a pod-template.yaml template that I summarized based on the above issues:</p></li></ul><div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">apiVersion</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> v1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">kind</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> Pod</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">metadata</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">name</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> pod</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">template</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">spec</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">serviceAccount</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> default</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">containers</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain"> </span><span class="token key atrule">name</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> flink</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">main</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">container</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">image</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">imagePullSecrets</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain"> </span><span class="token key atrule">name</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> regsecret</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">hostAliases</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain"> </span><span class="token key atrule">ip</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"192.168.0.1"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><span class="token key atrule">hostnames</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"node1"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain"> </span><span class="token key atrule">ip</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"192.168.0.2"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><span class="token key atrule">hostnames</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"node2"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain"> </span><span class="token key atrule">ip</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"192.168.0.3"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><span class="token key atrule">hostnames</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"node3"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="best-practices"><strong>Best Practices</strong><a href="#best-practices" class="hash-link" aria-label="Direct link to best-practices" title="Direct link to best-practices">​</a></h3><p>  Many of RELX's big data components are based on Alibaba Cloud, such as Maxcompute and Alibaba Cloud Redis. At the same time, our Flink SQL jobs need to use some UDFs. At first, we adopted the method of using Flink Base image + maven dependency + upload udf jar, but in practice we encountered some problems such as version conflicts and class conflicts. At the same time, if it is a large-volume job, the development efficiency of this method is relatively low. Finally, we packaged the commonly used Flink connectors, udf and Flink base image at the company level into a company-level base image. New Flink SQL jobs can directly write Flink SQL after using this base image, which greatly improves development efficiency.</p><p><strong>Let’s share a simple step to create a basic image：</strong></p><p><strong>1. Prepare the required JAR</strong></p><p>Place the commonly used Flink Connector Jar and the user Udf Jar in the same folder lib. The following are some commonly used connector packages in Flink 1.13.6</p><div class="language-jar codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-jar codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">bigdata-udxf-1.0.0-shaded.jar</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">flink-connector-jdbc_2.11-1.13.6.jar</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">flink-sql-connector-kafka_2.11-1.13.6.jar</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">flink-sql-connector-mysql-cdc-2.0.2.jar</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">hudi-flink-bundle_2.11-0.10.0.jar</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">ververica-connector-odps-1.13-vvr-4.0.7.jar</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">ververica-connector-redis-1.13-vvr-4.0.7.jar</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><strong>2. Prepare Dockerfile</strong></p><p>Create a Dockerfile file and place the Dockerfile file in the same folder as the above folder</p><div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">FROM flink:1.13.6-scala_2.11COPY lib </span><span class="token variable" style="color:rgb(189, 147, 249);font-style:italic">$FLINK_HOME</span><span class="token plain">/lib/</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><strong>3. Create a basic image and push it to a private repository</strong></p><div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token function" style="color:rgb(80, 250, 123)">docker</span><span class="token plain"> login --username</span><span class="token operator">=</span><span class="token plain">xxxdocker </span><span class="token punctuation" style="color:rgb(248, 248, 242)">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">build -t udf_flink_1.13.6-scala_2.11:latest </span><span class="token punctuation" style="color:rgb(248, 248, 242)">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">.docker tag udf_flink_1.13.6-scala_2.11:latest </span><span class="token punctuation" style="color:rgb(248, 248, 242)">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">k8s-harbor.xxx.com/streamx/udf_flink_1.13.6-scala_2.11:latestdocker </span><span class="token punctuation" style="color:rgb(248, 248, 242)">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">push k8s-harbor.xxx.com/streamx/udf_flink_1.13.6-scala_2.11:latest</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="future-expectations"><strong>Future Expectations</strong><a href="#future-expectations" class="hash-link" aria-label="Direct link to future-expectations" title="Direct link to future-expectations">​</a></h2><ul><li><p><strong>StreamPark supports Flink job metric monitoring</strong></p><p>It would be great if StreamPark could connect to Flink Metric data and display Flink’s real-time consumption data at every moment on the StreamPark platform.</p></li><li><p><strong>StreamPark supports Flink job log persistence</strong></p><p>For Flink deployed to YARN, if the Flink program hangs, we can go to YARN to view the historical logs. However, for Kubernetes, if the program hangs, the Kubernetes pod will disappear and there will be no way to check the logs. Therefore, users need to use tools on Kubernetes for log persistence. It would be better if StreamPark supports the Kubernetes log persistence interface.</p></li><li><p><strong>Improvement of the problem of too large image</strong></p><p>StreamPark's current image support for Flink on Kubernetes jobs is to combine the basic image and user code into a Fat image and push it to the Docker repository. The problem with this method is that it takes a long time when the image is too large. It is hoped that the basic image can be restored in the future. There is no need to hit the business code together every time, which can greatly improve development efficiency and save costs.</p></li></ul>]]></content>
        <category label="StreamPark" term="StreamPark"/>
        <category label="Production Practice" term="Production Practice"/>
        <category label="FlinkSQL" term="FlinkSQL"/>
        <category label="Kubernetes" term="Kubernetes"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[StreamPark - Powerful Flink Development Framework]]></title>
        <id>https://streampark.apache.org/blog/flink-development-framework-streampark</id>
        <link href="https://streampark.apache.org/blog/flink-development-framework-streampark"/>
        <updated>2024-01-21T04:16:34.000Z</updated>
        <summary type="html"><![CDATA[Although the Hadoop system is widely used today, its architecture is complicated, it has a high maintenance complexity, version upgrades are challenging, and due to departmental reasons, data center scheduling is prolonged. We urgently need to explore agile data platform models. With the current popularization of cloud-native architecture and the integration between lake and warehous, we have decided to use Doris as an offline data warehouse and TiDB (which is already in production) as a real-time data platform. Furthermore, because Doris has ODBC capabilities on MySQL, it can integrate external database resources and uniformly output reports.]]></summary>
        <content type="html"><![CDATA[<p>Although the Hadoop system is widely used today, its architecture is complicated, it has a high maintenance complexity, version upgrades are challenging, and due to departmental reasons, data center scheduling is prolonged. We urgently need to explore agile data platform models. With the current popularization of cloud-native architecture and the integration between lake and warehous, we have decided to use Doris as an offline data warehouse and TiDB (which is already in production) as a real-time data platform. Furthermore, because Doris has ODBC capabilities on MySQL, it can integrate external database resources and uniformly output reports.</p><p><img loading="lazy" src="/assets/images/doris-4baaea78343b928b0a798ae9238c489f.png" width="1200" height="738" class="img_ev3q"></p><h1>1. Background</h1><p>Although the Hadoop system is widely used today, its architecture is complicated, it has a high maintenance complexity, version upgrades are challenging, and due to departmental reasons, data center scheduling is prolonged. We urgently need to explore agile data platform models. With the current popularization of cloud-native architecture and the integration between lake and warehous, we have decided to use Doris as an offline data warehouse and TiDB (which is already in production) as a real-time data platform. Furthermore, because Doris has ODBC capabilities on MySQL, it can integrate external database resources and uniformly output reports.</p><p><img loading="lazy" src="/assets/images/doris-4baaea78343b928b0a798ae9238c489f.png" width="1200" height="738" class="img_ev3q"></p><center style="color:gray">(Borrowing Doris's official architecture diagram here)</center><br><br><h1>2. Challenges Faced</h1><p>For the data engine, we settled on using Spark and Flink:</p><ul><li>Use Spark on K8s client mode for offline data processing.</li><li>Use Flink on K8s Native-Application/Session mode for real-time task stream management.</li></ul><p>Here, there are some challenges we haven't fully resolved:</p><p>Those who have used the Native-Application mode know that each time a task is submitted, a new image must be packaged, pushed to a private repository, and then the Flink Run command is used to communicate with K8s to pull the image and run the Pod. After the task is submitted, you need to check the log on K8s, but:</p><ol><li>How is task runtime monitoring handled?</li><li>Do you use Cluster mode or expose ports using NodePort to access Web UI?</li><li>Can the task submission process be simplified to avoid image packaging?</li><li>How can we reduce the pressure on developers?</li></ol><br><br><h1>3. Solving the Challenges</h1><p>All of the above are challenges that need addressing. If we rely solely on the command line to submit each task, it becomes unrealistic. As the number of tasks increases, it becomes unmanageable. Addressing these challenges became inevitable.</p><br><h2 class="anchor anchorWithStickyNavbar_LWe7" id="simplifying-image-building">Simplifying Image Building<a href="#simplifying-image-building" class="hash-link" aria-label="Direct link to Simplifying Image Building" title="Direct link to Simplifying Image Building">​</a></h2><p>Firstly, regarding the need for a secondary build of the native Flink image: we utilized MinIO as external storage and mounted it directly on each host node using s3-fuse via DaemonSet. The jar packages we need to submit can all be managed there. In this way, even if we scale the Flink nodes up or down, S3 mounts can automatically scale.</p><p><img loading="lazy" src="/assets/images/k8s-9a28cd8f0e9c996501193f591ebe22b0.png" width="1141" height="582" class="img_ev3q"></p><p>From Flink version 1.13 onwards, Pod Template support has been added. We can use volume mounts in the Pod Template to mount host directories into each pod, allowing Flink programs to run directly on K8s without packaging them into images. As shown in the diagram above, we first mount S3 using the s3-fuse Pod to the <code>/mnt/data-s3fs</code> directory on Node 1 and Node 2, and then mount <code>/mnt/data-s3fs</code> into Pod A.</p><p>However, because object storage requires the entire object to be rewritten for random writes or file appends, this method is only suitable for frequent reads. This perfectly fits our current scenario.</p><br><h2 class="anchor anchorWithStickyNavbar_LWe7" id="introducing-streampark">Introducing StreamPark<a href="#introducing-streampark" class="hash-link" aria-label="Direct link to Introducing StreamPark" title="Direct link to Introducing StreamPark">​</a></h2><p>Previously, when we wrote Flink SQL, we generally used Java to wrap SQL, packed it into a jar package, and submitted it to the S3 platform through the command line. This approach has always been unfriendly; the process is cumbersome, and the costs for development and operations are too high. We hoped to further streamline the process by abstracting the Flink TableEnvironment, letting the platform handle initialization, packaging, and running Flink tasks, and automating the building, testing, and deployment of Flink applications.</p><p>This is an era of open-source uprising. Naturally, we turned our attention to the open-source realm: among numerous open-source projects, after comparing various projects, we found that both Zeppelin and StreamPark provide substantial support for Flink and both claim to support Flink on K8s. Eventually, both were shortlisted for our selection. Here's a brief comparison of their support for K8s (if there have been updates since, please kindly correct).</p><table><thead><tr><td>Feature</td><td>Zeppelin</td><td>StreamPark</td></tr></thead><tbody><tr><td>Task Status Monitoring</td><td>Somewhat limited, not suitable as a task status monitoring tool.</td><td>Highly capable</td></tr><tr><td>Task Resource Management</td><td>None</td><td>Exists, but the current version is not very robust.</td></tr><tr><td>Local Deployment</td><td>On the lower side. In on K8s mode, you can only deploy Zeppelin in K8s. Otherwise, you need to connect the Pod and external network, which is rarely done in production.</td><td>Can be deployed locally</td></tr><tr><td>Multi-language Support</td><td>High - Supports multiple languages such as Python/Scala/Java.</td><td>Average - Currently, K8s mode and YARN mode support FlinkSQL, and based on individual needs, you can use Java/Scala to develop DataStream.</td></tr><tr><td>Flink WebUI Proxy</td><td>Currently not very comprehensive. The main developer is considering integrating Ingress.</td><td>Good - Currently supports ClusterIp/NodePort/LoadBalance modes.</td></tr><tr><td>Learning Curve</td><td>Low cost. Needs to learn additional parameters, which differ somewhat from native FlinkSQL.</td><td>No cost. In K8s mode, FlinkSQL is supported in its native SQL format; also supports Custom-Code (user writes code for developing Datastream/FlinkSQL tasks).</td></tr><tr><td>Support for Multiple Flink Versions</td><td>Supported</td><td>Supported</td></tr><tr><td>Intrusion into Native Flink Image</td><td>Invasive. You need to pre-deploy the jar package in the Flink image, which will start in the same Pod as JobManager and communicate with the zeppelin-server.</td><td>Non-invasive, but it will generate many images that need to be cleaned up regularly.</td></tr><tr><td>Multi-version Code Management</td><td>Supported</td><td>Supported</td></tr></tbody></table><center style="color:gray">(PS: This comparison is based on our perspective as evaluators. We hold the utmost respect for the developers of both platforms.)</center><br><p>During our research process, we communicated with the main developers of both tools multiple times. After our repeated studies and assessments, we eventually decided to adopt StreamPark as our primary Flink development tool for now.</p><video src="http://assets.streamxhub.com/streamx-video.mp4" controls="" width="100%" height="100%"></video><center style="color:gray">(StreamPark's official splash screen)</center><br><p>After extended development and testing by our team, StreamPark currently boasts:</p><ul><li>Comprehensive <span style="color:red">SQL validation capabilities</span></li><li>It has achieved <span style="color:red">automatic build/push for images</span></li><li>Using a custom class loader and through the Child-first loading method, it <span style="color:red">addresses both YARN and K8s operational modes</span> and <span style="color:red">supports the seamless switch between multiple Flink versions</span></li><li>It deeply integrates with Flink-Kubernetes, returning a WebUI after task submission, and via remote REST API + remote K8s, it can <span style="color:red">track task execution status</span></li><li>It supports versions like <span style="color:red">Flink 1.12, 1.13, 1.14, and more</span></li></ul><p>This effectively addresses most of the challenges we currently face in development and operations.</p><video src="http://assets.streamxhub.com/streamx-1.2.0.mp4" controls="" width="100%" height="100%"></video><center style="color:gray">(Demo video showcasing StreamPark's support for multiple Flink versions)</center><br><p>In its latest release, version 1.2.0, StreamPark provides robust support for both K8s-Native-Application and K8s-Session-Application modes.</p><video src="http://assets.streamxhub.com/streamx-k8s.mp4" controls="" width="100%" height="100%"></video><center style="color:gray">(StreamPark's K8s deployment demo video)</center><br><h3 class="anchor anchorWithStickyNavbar_LWe7" id="k8s-native-application-mode">K8s Native Application Mode<a href="#k8s-native-application-mode" class="hash-link" aria-label="Direct link to K8s Native Application Mode" title="Direct link to K8s Native Application Mode">​</a></h3><p>Within StreamPark, all we need to do is configure the relevant parameters, fill in the corresponding dependencies in the Maven POM, or upload the dependency jar files. Once we click on 'Apply', the specified dependencies will be generated. This implies that we can also compile all the UDFs we use into jar files, as well as various connector.jar files, and use them directly in SQL. As illustrated below:</p><p><img loading="lazy" src="/assets/images/dependency-a3b9ff29795acb8a1fd4ed6bb773d53e.png" width="1080" height="461" class="img_ev3q"></p><p>The SQL validation capability is roughly equivalent to that of Zeppelin:</p><p><img loading="lazy" src="/assets/images/sqlverify-7e12cf343c9c81fcbc2e20f8d7588f1b.png" width="1080" height="619" class="img_ev3q"></p><p>We can also specify resources, designate dynamic parameters within Flink Run as Dynamic Options, and even integrate these parameters with a Pod Template.</p><p><img loading="lazy" src="/assets/images/pod-d46370aaff2c34c4fe6a584c0524b28e.png" width="1080" height="574" class="img_ev3q"></p><p>After saving the program, when clicking to run, we can also specify a savepoint. Once the task is successfully submitted, StreamPark will, based on the FlinkPod's network Exposed Type (be it loadBalancer, NodePort, or ClusterIp), return the corresponding WebURL, seamlessly enabling a WebUI redirect. However, as of now, due to security considerations within our online private K8s cluster, there hasn't been a connection established between the Pod and client node network (and there's currently no plan for this). Hence, we only employ NodePort. If the number of future tasks increases significantly, and there's a need for ClusterIP, we might consider deploying StreamPark in K8s or further integrate it with Ingress.</p><p><img loading="lazy" src="/assets/images/start-71fbb288851d022c450a6bd34e8b4dc2.png" width="1080" height="522" class="img_ev3q"></p><p>Note: If the K8s master uses a vip for load balancing, the Flink 1.13 version will return the vip's IP address. This issue has been rectified in the 1.14 version.</p><p>Below is the specific submission process in the K8s Application mode:</p><p><img loading="lazy" src="/assets/images/flow-c2227ba0cc1f59f78e2164fdb3657223.png" width="1080" height="949" class="img_ev3q"></p><center style="color:gray">(The above is a task submission flowchart, drawn based on personal understanding. If there are inaccuracies, your understanding is appreciated.)</center><br><h3 class="anchor anchorWithStickyNavbar_LWe7" id="k8s-native-session-mode">K8s Native Session Mode<a href="#k8s-native-session-mode" class="hash-link" aria-label="Direct link to K8s Native Session Mode" title="Direct link to K8s Native Session Mode">​</a></h3><p>StreamPark also offers robust support for the <span style="color:red"> K8s Native-Session mode</span>, which lays a solid technical foundation for our subsequent offline FlinkSQL development or for segmenting certain resources.</p><p>To use the Native-Session mode, one must first use the Flink command to create a Flink cluster that operates within K8s. For instance:</p><div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">./kubernetes-session.sh </span><span class="token punctuation" style="color:rgb(248, 248, 242)">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">-Dkubernetes.cluster-id</span><span class="token operator">=</span><span class="token plain">flink-on-k8s-flinkSql-test </span><span class="token punctuation" style="color:rgb(248, 248, 242)">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">-Dkubernetes.context</span><span class="token operator">=</span><span class="token plain">XXX </span><span class="token punctuation" style="color:rgb(248, 248, 242)">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">-Dkubernetes.namespace</span><span class="token operator">=</span><span class="token plain">XXXX </span><span class="token punctuation" style="color:rgb(248, 248, 242)">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">-Dkubernetes.service-account</span><span class="token operator">=</span><span class="token plain">XXXX </span><span class="token punctuation" style="color:rgb(248, 248, 242)">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">-Dkubernetes.container.image</span><span class="token operator">=</span><span class="token plain">XXXX </span><span class="token punctuation" style="color:rgb(248, 248, 242)">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">-Dkubernetes.container.image.pull-policy</span><span class="token operator">=</span><span class="token plain">Always </span><span class="token punctuation" style="color:rgb(248, 248, 242)">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">-Dkubernetes.taskmanager.node-selector</span><span class="token operator">=</span><span class="token plain">XXXX </span><span class="token punctuation" style="color:rgb(248, 248, 242)">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">-Dkubernetes.rest-service.exposed.type</span><span class="token operator">=</span><span class="token plain">Nodeport</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><img loading="lazy" src="/assets/images/flinksql-13b242feb3803b15e6698635a79065b4.png" width="1080" height="664" class="img_ev3q"></p><p>As shown in the image above, we use that ClusterId as the Kubernetes ClusterId task parameter for StreamPark. Once the task is saved and submitted, it quickly transitions to a 'Running' state:</p><p><img loading="lazy" src="/assets/images/detail-e9ee4c14e45068bea5e1edabec596bee.png" width="1080" height="529" class="img_ev3q"></p><p>Following the application info's WebUI link:</p><p><img loading="lazy" src="/assets/images/dashboard-78745d8d3ebe422b166a17631bfbe622.png" width="1080" height="520" class="img_ev3q"></p><p>It becomes evident that StreamPark essentially uploads the jar package to the Flink cluster through REST API and then schedules the task for execution.</p><br><h3 class="anchor anchorWithStickyNavbar_LWe7" id="custom-code-mode">Custom Code Mode<a href="#custom-code-mode" class="hash-link" aria-label="Direct link to Custom Code Mode" title="Direct link to Custom Code Mode">​</a></h3><p>To our delight, StreamPark also provides support for coding DataStream/FlinkSQL tasks. For special requirements, we can achieve our implementations in Java/Scala. You can compose tasks following the scaffold method recommended by StreamPark or write a standard Flink task. By adopting this approach, we can delegate code management to git, utilizing the platform for automated compilation, packaging, and deployment. Naturally, if functionality can be achieved via SQL, we would prefer not to customize DataStream, thereby minimizing unnecessary operational complexities.</p><br><br><h1>4. Feedback and Future Directions</h1><h2 class="anchor anchorWithStickyNavbar_LWe7" id="suggestions-for-improvement">Suggestions for Improvement<a href="#suggestions-for-improvement" class="hash-link" aria-label="Direct link to Suggestions for Improvement" title="Direct link to Suggestions for Improvement">​</a></h2><p>StreamPark, similar to any other new tools, does have areas for further enhancement based on our current evaluations:</p><ul><li><strong>Strengthening Resource Management</strong>: Features like multi-file system jar resources and robust task versioning are still awaiting additions.</li><li><strong>Enriching Frontend Features</strong>: For instance, once a task is added, functionalities like copying could be integrated.</li><li><strong>Visualization of Task Submission Logs</strong>: The process of task submission involves loading class files, jar packaging, building and submitting images, and more. A failure at any of these stages could halt the task. However, error logs are not always clear, or due to some anomaly, the exceptions aren't thrown as expected, leaving users puzzled about rectifications.</li></ul><p>It's a universal truth that innovations aren't perfect from the outset. Although minor issues exist and there are areas for improvement with StreamPark, its merits outweigh its limitations. As a result, we've chosen StreamPark as our Flink DevOps platform. We're also committed to collaborating with its main developers to refine StreamPark further. We wholeheartedly invite others to use it and contribute towards its advancement.</p><br><h2 class="anchor anchorWithStickyNavbar_LWe7" id="future-prospects">Future Prospects<a href="#future-prospects" class="hash-link" aria-label="Direct link to Future Prospects" title="Direct link to Future Prospects">​</a></h2><ul><li>We'll keep our focus on Doris and plan to unify business data with log data in Doris, leveraging Flink to realize lakehouse capabilities.</li><li>Our next step is to explore integrating StreamPark with DolphinScheduler 2.x. This would enhance DolphinScheduler's offline tasks, and gradually we aim to replace Spark with Flink for a unified batch-streaming solution.</li><li>Drawing from our own experiments with S3, after building the fat-jar, we're considering bypassing image building. Instead, we'll mount PVC directly to the Flink Pod's directory using Pod Template, refining the code submission process even further.</li><li>We plan to persistently implement StreamPark in our production environment. Collaborating with community developers, we aim to boost StreamPark's Flink stream development, deployment, and monitoring capabilities. Our collective vision is to evolve StreamPark into a holistic stream data DevOps platform.</li></ul><p>Resources:</p><p>StreamPark GitHub: <a href="https://github.com/apache/incubator-streampark" target="_blank" rel="noopener noreferrer">https://github.com/apache/incubator-streampark</a> <br>
Doris GitHub: <a href="https://github.com/apache/doris" target="_blank" rel="noopener noreferrer">https://github.com/apache/doris</a></p><p><img loading="lazy" src="/assets/images/author-c3dabbb31d7cea1b5164a75a94ca3008.png" width="900" height="500" class="img_ev3q"></p>]]></content>
        <category label="StreamPark" term="StreamPark"/>
        <category label="DataStream" term="DataStream"/>
        <category label="FlinkSQL" term="FlinkSQL"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[China Union's Flink Real-Time Computing Platform Ops Practice]]></title>
        <id>https://streampark.apache.org/blog/streampark-usercase-chinaunion</id>
        <link href="https://streampark.apache.org/blog/streampark-usercase-chinaunion"/>
        <updated>2024-01-21T04:16:34.000Z</updated>
        <summary type="html"><![CDATA[Abstract]]></summary>
        <content type="html"><![CDATA[<p><img loading="lazy" src="/assets/images/overall_architecture-efc4272dcb2fcdadac42d40cf1a6a931.png" width="1080" height="597" class="img_ev3q"></p><p><strong>Abstract:</strong> This article is compiled from the sharing of Mu Chunjin, the head of China Union Data Science's real-time computing team and Apache StreamPark Committer, at the Flink Forward Asia 2022 platform construction session. The content of this article is mainly divided into four parts:</p><ul><li>Introduction to the Real-Time Computing Platform Background</li><li>Operational Challenges of Flink Real-Time Jobs</li><li>Integrated Management Based on StreamPark</li><li>Future Planning and Evolution</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="introduction-to-the-real-time-computing-platform-background"><strong>Introduction to the Real-Time Computing Platform Background</strong><a href="#introduction-to-the-real-time-computing-platform-background" class="hash-link" aria-label="Direct link to introduction-to-the-real-time-computing-platform-background" title="Direct link to introduction-to-the-real-time-computing-platform-background">​</a></h2><p>The image above depicts the overall architecture of the real-time computing platform. At the bottom layer, we have the data sources. Due to some sensitive information, the detailed information of the data sources is not listed. It mainly includes three parts: business databases, user behavior logs, and user location. China Union has a vast number of data sources, with just the business databases comprising tens of thousands of tables. The data is primarily processed through Flink SQL and the DataStream API. The data processing workflow includes real-time parsing of data sources by Flink, real-time computation of rules, and real-time products. Users perform real-time data subscriptions on the visualization subscription platform. They can draw an electronic fence on the map and set some rules, such as where the data comes from, how long it stays inside the fence, etc. They can also filter some features. User information that meets these rules will be pushed in real-time. Next is the real-time security part. If a user connects to a high-risk base station or exhibits abnormal operational behavior, we may suspect fraudulent activity and take actions such as shutting down the phone number, among other things. Additionally, there are some real-time features of users and a real-time big screen display.</p><p><img loading="lazy" src="/assets/images/data_processing_processes-6b611077be80fd421d883accd5acb423.png" width="1080" height="593" class="img_ev3q"></p><p>The image above provides a detailed workflow of data processing.</p><p>The first part is collection and parsing. Our data sources come from business databases, including OGG and DTS format messages, log messages, user behavior, and user location data, totaling over 50 different data sources. This number is expected to gradually increase. All data sources are processed in real-time using Flink, and Metrics have been added to monitor the latency of data sources.</p><p>The second part is real-time computing. This stage deals with a massive amount of data, in the trillions, supporting over 10,000 real-time data subscriptions. There are more than 200 Flink tasks. We encapsulate a certain type of business into a scenario, and a single Flink job can support multiple subscriptions in the same scenario. Currently, the number of Flink jobs is continuously increasing, and in the future, it might increase to over 500. One of the major challenges faced here is the real-time association of trillion-level data with electronic fences and user features on a daily basis. There are tens of thousands of electronic fences, and user features involve hundreds of millions of users. Initially, we stored electronic fence information and user features in HBase, but this led to significant pressure on HBase, frequent performance issues, and data latency. Furthermore, once data backlog occurred, it took a long time to clear. Thanks to the powerful Flink State, we have now stored the electronic fence information and user features in the state, which has adequately supported high-concurrency scenarios. We have also added performance monitoring for data processing. Finally, there are some applications for real-time products and marketing touchpoints on the front end.</p><p><img loading="lazy" src="/assets/images/platform_evolution-9d3427a9bb13529e6a6540f6a77e152b.png" width="1080" height="483" class="img_ev3q"></p><p>In 2018, we adopted a third-party black-box computing engine, which did not support flexible customization of personalized functions, and depended heavily on external systems, resulting in high loads on these external systems and complex operations and maintenance. In 2019, we utilized Spark Streaming's micro-batch processing. From 2020, we began to use Flink for stream computing. Starting from 2021, almost all Spark Streaming micro-batch processing tasks have been replaced by Flink. At the same time, Apache StreamPark was launched to manage our Flink jobs.</p><p><img loading="lazy" src="/assets/images/platform_background-e591fd5ed3391480217c668f70519d28.png" width="1080" height="493" class="img_ev3q"></p><p>To summarize the platform background, it mainly includes the following parts:</p><ul><li>Large data volume: processing an average of trillions of data per day.</li><li>Numerous data sources: integrated with more than 50 types of real-time data sources.</li><li>Numerous subscriptions: supported more than 10,000 data service subscriptions.</li><li>Numerous users: supported the usage of more than 30 internal and external users.</li></ul><p><img loading="lazy" src="/assets/images/operational_background-dd9ae29be9c5d959a649bb9dd8f7a1dc.png" width="1080" height="562" class="img_ev3q"></p><p>The operational maintenance background can also be divided into the following parts:</p><ul><li>High support demand: More than 50 types of data sources, and over 10,000 data service subscriptions.</li><li>Numerous real-time jobs: Currently, there are 200+ Flink production jobs, and the number is continuously and rapidly increasing, potentially reaching 500+ in the future.</li><li>High frequency of launches: There are new or enhanced Flink jobs going live every day.</li><li>Numerous developers: Over 50 R&amp;D personnel are involved in developing Flink real-time computing tasks.</li><li>Numerous users: Over 30 internal and external organizations' users are utilizing the platform.</li><li>Low monitoring latency: Once an issue is identified, we must address it immediately to avoid user complaints.</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="flink-实时作业运维挑战"><strong>Flink 实时作业运维挑战</strong><a href="#flink-实时作业运维挑战" class="hash-link" aria-label="Direct link to flink-实时作业运维挑战" title="Direct link to flink-实时作业运维挑战">​</a></h2><p><img loading="lazy" src="/assets/images/difficulties-81db2f256a9e39ae8c9ba9730aa37585.png" width="1080" height="481" class="img_ev3q"></p><p>Given the platform and operational maintenance background, particularly with the increasing number of Flink jobs, we have encountered significant challenges in two main areas: job operation and maintenance dilemmas, and business support difficulties.</p><p>In terms of job operation and maintenance dilemmas, firstly, the job deployment process is lengthy and inefficient. Under China Union's principle that security is the top priority, deploying programs on servers involves connecting to a VPN, logging in through the 4A system, packaging and compiling, deploying, and then starting the program. This entire process is quite long. Initially, when developing Flink, we started jobs using scripts, leading to uncontrollable code branches. After deployment, it was also difficult to trace back. Moreover, it's challenging to synchronize scripts with code on git because developers tend to prefer directly modifying scripts on the server, easily forgetting to upload changes to git.</p><p>Due to various factors in the job operation and maintenance difficulties, business support challenges arise, such as a high rate of failures during launch, impact on data quality, lengthy launch times, high data latency, and issues with missed alarm handling, leading to complaints. In addition, the impact on our business is unclear, and once a problem arises, addressing the issue becomes the top priority.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="基于-streampark-一体化管理"><strong>基于 StreamPark 一体化管理</strong><a href="#基于-streampark-一体化管理" class="hash-link" aria-label="Direct link to 基于-streampark-一体化管理" title="Direct link to 基于-streampark-一体化管理">​</a></h2><p><img loading="lazy" src="/assets/images/job_management-57ac8eebee7ab32d4d55008faade15ff.png" width="1080" height="510" class="img_ev3q"></p><p>In response to the two dilemmas mentioned above, we have resolved many issues through StreamPark's integrated management. First, let's take a look at the dual evolution of StreamPark, which includes Flink Job Management and Flink Job DevOps Platform. In terms of job management, StreamPark supports deploying Flink real-time jobs to different clusters, such as Flink's native Standalone mode, and the Session, Application, and PerJob modes of Flink on Yarn. In the latest version, it will support Kubernetes Native Session mode. The middle layer includes project management, job management, cluster management, team management, variable management, and alarm management.</p><ul><li>Project Management: When deploying a Flink program, you can fill in the git address in project management and select the branch you want to deploy.</li><li>Job Management: You can specify the execution mode of the Flink job, such as which type of cluster you want to submit to. You can also configure some resources, such as the number of TaskManagers, the memory size of TaskManager/JobManager, parallelism, etc. Additionally, you can set up some fault tolerance measures; for instance, if a Flink job fails, StreamPark can support automatic restarts, and it also supports the input of some dynamic parameters.</li><li>Cluster Management: You can add and manage big data clusters through the interface.</li><li>Team Management: In the actual production process of an enterprise, there are multiple teams, and these teams are isolated from each other.</li><li>Variable Management: You can maintain some variables in one place. For example, you can define Kafka's Broker address as a variable. When configuring Flink jobs or SQL, you can replace the Broker's IP with a variable. Moreover, if this Kafka needs to be decommissioned later, you can also use this variable to check which jobs are using this cluster, facilitating some subsequent processes.</li><li>Alarm Management: Supports multiple alarm modes, such as WeChat, DingTalk, SMS, and email.</li></ul><p>StreamPark supports the submission of Flink SQL and Flink Jar, allows for resource configuration, and supports state tracking, indicating whether the state is running, failed, etc. Additionally, it provides a metrics dashboard and supports the viewing of various logs.</p><p><img loading="lazy" src="/assets/images/devops_platform-97e53d17c155a4d98431a1ab52a7bd13.png" width="1080" height="501" class="img_ev3q"></p><p>The Flink Job DevOps platform primarily consists of the following parts:</p><ul><li>Teams: StreamPark supports multiple teams, each with its team administrator who has all permissions. There are also team developers who only have a limited set of permissions.</li><li>Compilation and Packaging: When creating a Flink project, you can configure the git address, branch, and packaging commands in the project, and then compile and package with a single click of the build button.</li><li>Release and Deployment: During release and deployment, a Flink job is created. Within the Flink job, you can choose the execution mode, deployment cluster, resource settings, fault tolerance settings, and fill in variables. Finally, the Flink job can be started or stopped with a single click.</li><li>State Monitoring: After the Flink job is started, real-time tracking of its state begins, including Flink's running status, runtime duration, Checkpoint information, etc. There is also support for one-click redirection to Flink's Web UI.</li><li>Logs and Alerts: This includes logs from the build and start-up processes and supports alerting methods such as DingTalk, WeChat, email, and SMS.</li></ul><p><img loading="lazy" src="/assets/images/multi_team_support-ea9b19ef43d528e9be9016efa65f80fc.png" width="1080" height="477" class="img_ev3q"></p><p>Companies generally have multiple teams working on real-time jobs simultaneously. In our company, this includes a real-time data collection team, a data processing team, and a real-time marketing team. StreamPark supports resource isolation for multiple teams.</p><p><img loading="lazy" src="/assets/images/platformized_management-f3f784103707c8e3b67a3bcdda5a3dd6.png" width="1080" height="600" class="img_ev3q"></p><p>Management of the Flink job platform faces the following challenges:</p><ul><li>Numerous scripts: There are several hundred scripts on the platform, scattered across multiple servers.</li><li>Various types of scripts: When starting Flink jobs, there are start scripts, stop scripts, and daemon scripts, and it is very difficult to control operation permissions.</li><li>Inconsistent scripts: The scripts on the server are inconsistent with the scripts on git.</li><li>Difficult to ascertain script ownership: It is unclear who is responsible for the Flink jobs and their purpose.</li><li>Uncontrollable branches: When starting a job, you need to specify the git branch in the script, resulting in untraceable branches.</li></ul><p>Based on the challenges mentioned above, StreamPark has addressed the issues of unclear ownership and untraceable branches through project management. This is because when creating a project, you need to manually specify certain branches. Once the packaging is successful, these branches are recorded. Job management centralizes configurations, preventing scripts from being too dispersed. Additionally, there is strict control over the permissions for starting and stopping jobs, preventing an uncontrollable state due to script permissions. StreamPark interacts with clusters through interfaces to obtain job information, allowing for more precise job control.</p><p>Referring to the image above, you can see at the bottom of the diagram that packaging is conducted through project management, configuration is done via job management, and then it is released. This process allows for one-click start and stop operations, and jobs can be submitted through the API.</p><p><img loading="lazy" alt="图片" src="/assets/images/development_efficiency-2b27930ac18721c40acb006c03806e69.png" width="1080" height="591" class="img_ev3q"></p><p>In the early stages, we needed to go through seven steps for deployment, including connecting to a VPN, logging in through 4A, executing compile scripts, executing start scripts, opening Yarn, searching for the job name, and entering the Flink UI. StreamPark supports one-click deployment for four of these steps, including one-click packaging, one-click release, one-click start, and one-click access to the Flink UI.</p><p><img loading="lazy" alt="图片" src="/assets/images/submission_process-bb3efd39e3f2e76595995647327be75a.png" width="1080" height="548" class="img_ev3q"></p><p>The image above illustrates the job submission process of our StreamPark platform. Firstly, StreamPark proceeds to release the job, during which some resources are uploaded. Following that, the job is submitted, accompanied by various configured parameters, and it is published to the cluster using the Flink Submit method via an API call. At this point, there are multiple Flink Submit instances corresponding to different execution modes, such as Yarn Session, Yarn Application, Kubernetes Session, Kubernetes Application, and so on; all of these are controlled here. After submitting the job, if it is a Flink on Yarn job, the platform will acquire the Application ID or Job ID of the Flink job. This ID is then stored in our database. Similarly, if the job is executed based on Kubernetes, a Job ID will be obtained. Subsequently, when tracking the job status, we primarily use these stored IDs to monitor the state of the job.</p><p><img loading="lazy" alt="图片" src="/assets/images/status_acquisition_bottleneck-436fee79261994fd26eda735d2833e70.png" width="1080" height="599" class="img_ev3q"></p><p>As mentioned above, in the case of Flink on Yarn jobs, two IDs are acquired upon job submission: the Application ID and the Job ID. These IDs are used to retrieve the job status. However, when there is a large number of Flink jobs, certain issues may arise. StreamPark utilizes a status retriever that periodically sends requests to the ResourceManager every five seconds, using the Application ID or Job ID stored in our database. If there are a considerable number of jobs, during each polling cycle, the ResourceManager is responsible for calling the Job Manager's address to access its status. This can lead to significant pressure on the number of connections to the ResourceManager and an overall increase in the number of connections.</p><p>In the diagram mentioned earlier, the connection count to the ResourceManager shows periodic and sustained increases, indicating that the ResourceManager is in a relatively critical state. This is evidenced by monitoring data from the server, which indeed shows a higher number of connections to the ResourceManager.</p><p><img loading="lazy" alt="图片" src="/assets/images/state_optimization-06c675fa387cb316cc225fb0b1576451.png" width="1080" height="596" class="img_ev3q"></p><p>To address the issues mentioned above, we have made some optimizations in StreamPark. Firstly, after submitting a job, StreamPark saves the Application ID or Job ID, and it also retrieves and stores the direct access address of the Job Manager in the database. Therefore, instead of polling the ResourceManager for job status, it can directly call the addresses of individual Job Managers to obtain the real-time status. This significantly reduces the number of connections to the ResourceManager. As can be seen from the latter part of the diagram above, there are basically no significant spikes in connection counts, which substantially alleviates the pressure on the ResourceManager. Moreover, this ensures that as the number of Flink jobs continues to grow, the system will not encounter bottlenecks in status retrieval.</p><p><img loading="lazy" alt="图片" src="/assets/images/state_recovery-7d0a5ecaf3c3af7ffe33f85abf3d51a8.png" width="1080" height="573" class="img_ev3q"></p><p>Another issue that StreamPark resolves is safeguarding Flink's state recovery. In the past, when we used scripts for operations and maintenance, especially during business upgrades, it was necessary to recover from the latest checkpoint when starting Flink. However, developers often forgot to recover from the previous checkpoint, leading to significant data quality issues and complaints. StreamPark's process is designed to mitigate this issue. Upon the initial start of a Flink job, it polls every five seconds to retrieve checkpoint records, saving them in a database. When manually stopping a Flink job through StreamPark, users have the option to perform a savepoint. If this option is selected, the path of the savepoint is saved in the database. In addition, records of each checkpoint are also stored in the database. When restarting a Flink job, the system defaults to using the latest checkpoint or savepoint record. This effectively prevents issues associated with failing to recover from the previous checkpoint. It also avoids the resource wastage caused by having to rerun jobs with offset rollbacks to address problems, while ensuring consistency in data processing.</p><p><img loading="lazy" alt="图片" src="/assets/images/multiple_environments_and_components-85e9f3f218c9c5ef79d3792aec9540ac.png" width="1080" height="576" class="img_ev3q"></p><p>StreamPark also addresses the challenges associated with referencing multiple components across various environments. In a corporate setting, there are typically multiple environments, such as development, testing, and production. Each environment generally includes multiple components, such as Kafka, HBase, Redis, etc. Additionally, within a single environment, there may be multiple instances of the same component. For example, in a real-time computing platform at China Union, when consuming data from an upstream Kafka cluster and writing the relevant data to a downstream Kafka cluster, two sets of Kafka are involved within the same environment. It can be challenging to determine the specific environment and component based solely on IP addresses. To address this, we define the IP addresses of all components as variables. For instance, the Kafka cluster variable, Kafka.cluster, exists in development, testing, and production environments, but it points to different Broker addresses in each. Thus, regardless of the environment in which a Flink job is configured, referencing this variable is sufficient. This approach significantly reduces the incidence of operational failures in production environments.</p><p><img loading="lazy" alt="图片" src="/assets/images/multiple_execution_modes-56bb5cc794122dd7ac987f57999afb33.png" width="1080" height="585" class="img_ev3q"></p><p>StreamPark supports multiple execution modes for Flink, including three deployment modes based on Yarn: Application, Perjob, and Session. Additionally, it supports two deployment modes for Kubernetes: Application and Session, as well as some Remote modes.</p><p><img loading="lazy" alt="图片" src="/assets/images/versioning-641f09a5fcccd37dda2ed9d4cac14413.png" width="1080" height="389" class="img_ev3q"></p><p>StreamPark also supports multiple versions of Flink. For example, while our current version is 1.14.x, we would like to experiment with the new 1.16.x release. However, it’s not feasible to upgrade all existing jobs to 1.16.x. Instead, we can opt to upgrade only the new jobs to 1.16.x, allowing us to leverage the benefits of the new version while maintaining compatibility with the older version.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="future-planning-and-evolution"><strong>Future Planning and Evolution</strong><a href="#future-planning-and-evolution" class="hash-link" aria-label="Direct link to future-planning-and-evolution" title="Direct link to future-planning-and-evolution">​</a></h2><p><img loading="lazy" alt="图片" src="/assets/images/contribution_and_enhancement-bbb20c198ecc048735b12e40157115e2.png" width="1080" height="418" class="img_ev3q"></p><p>In the future, we will increase our involvement in the development of StreamPark, and we have planned the following directions for enhancement:</p><ul><li>High Availability: StreamPark currently does not support high availability, and this aspect needs further strengthening.</li><li>State Management: In enterprise practices, each operator in a Flink job has a UID. If the Flink UID is not set, it could lead to situations where state recovery is not possible when upgrading the Flink job. This issue cannot be solved through the platform at the moment. Therefore, we plan to add this functionality to the platform. We will introduce a feature that checks whether the operator has a UID set when submitting a Flink Jar. If not, a reminder will be issued to avoid state recovery issues every time a Flink job is deployed. Previously, when facing such situations, we had to use the state processing API to deserialize from the original state, and then create a new state using the state processing API for the upgraded Flink to load.</li><li>More Detailed Monitoring: Currently, StreamPark supports sending alerts when a Flink job fails. We hope to also send alerts when a Task fails, and need to know the reason for the failure. In addition, enhancements are needed in job backpressure monitoring alerts, Checkpoint timeout alerts, failure alerts, and performance metric collection.</li><li>Stream-Batch Integration: Explore a platform that integrates both streaming and batch processing, combining the Flink stream-batch unified engine with data lake storage that supports stream-batch unification.</li></ul><p><img loading="lazy" src="/assets/images/road_map-1a30ee719bdadf2e0ea31d6ea9e957bc.png" width="1080" height="488" class="img_ev3q"></p><p>The above diagram represents the Roadmap for StreamPark.</p><ul><li>Data Source: StreamPark will support rapid integration with more data sources, achieving one-click data onboarding.</li><li>Operation Center: Acquire more Flink Metrics to further enhance the capabilities in monitoring and operation.</li><li>K8S-operator: The existing Flink on K8S is somewhat cumbersome, having gone through the processes of packaging Jars, building images, and pushing images. There is a need for future improvements and optimization, and we are actively embracing the upstream K8S-operator integration.</li><li>Streaming Data Warehouse: Enhance support for Flink SQL job capabilities, simplify the submission of Flink SQL jobs, and plan to integrate with Flink SQL Gateway. Enhance capabilities in the SQL data warehouse domain, including metadata storage, unified table creation syntax validation, runtime testing, and interactive queries, while actively embracing Flink upstream to explore real-time data warehouses and streaming data warehouses.</li></ul>]]></content>
        <category label="StreamPark" term="StreamPark"/>
        <category label="Production Practice" term="Production Practice"/>
        <category label="FlinkSQL" term="FlinkSQL"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Based on Apache Paimon + StreamPark's Streaming Data Warehouse Practice by Bondex]]></title>
        <id>https://streampark.apache.org/blog/streampark-usercase-bondex-with-paimon</id>
        <link href="https://streampark.apache.org/blog/streampark-usercase-bondex-with-paimon"/>
        <updated>2024-01-21T04:16:34.000Z</updated>
        <summary type="html"><![CDATA[Foreword: This article mainly introduces the implementation of a streaming data warehouse by Bondex, a supply chain logistics service provider, in the process of digital transformation using the Paimon + StreamPark platform. We provide an easy-to-follow operational manual with the Apache StreamPark integrated stream-batch platform to help users submit Flink tasks and quickly master the use of Paimon.]]></summary>
        <content type="html"><![CDATA[<p><img loading="lazy" src="/assets/images/Bondex-b9280a2451e6984d91f7747acaa10b97.png" width="1080" height="460" class="img_ev3q"></p><p><strong>Foreword: </strong>This article mainly introduces the implementation of a streaming data warehouse by Bondex, a supply chain logistics service provider, in the process of digital transformation using the Paimon + StreamPark platform. We provide an easy-to-follow operational manual with the Apache StreamPark integrated stream-batch platform to help users submit Flink tasks and quickly master the use of Paimon.</p><ul><li>Introduction to Company Business</li><li>Pain Points and Selection in Big Data Technology</li><li>Production Practice</li><li>Troubleshooting Analysis</li><li>Future Planning</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="01-introduction-to-company-business">01 Introduction to Company Business<a href="#01-introduction-to-company-business" class="hash-link" aria-label="Direct link to 01 Introduction to Company Business" title="Direct link to 01 Introduction to Company Business">​</a></h2><p>Bondex Group has always focused on the field of supply chain logistics. By creating an excellent international logistics platform, it provides customers with end-to-end one-stop intelligent supply chain logistics services. The group currently has over 2,000 employees, an annual turnover of more than 12 billion RMB, a network covering over 200 ports globally, and more than 80 branches and subsidiaries at home and abroad, aiding Chinese enterprises to connect with the world.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="business-background"><strong>Business Background</strong><a href="#business-background" class="hash-link" aria-label="Direct link to business-background" title="Direct link to business-background">​</a></h3><p>As the company continues to expand and the complexity of its business increases, in order to better achieve resource optimization and process improvement, the Operations and Process Management Department needs to monitor the company's business operations in real time to ensure the stability and efficiency of business processes.</p><p>The Operations and Process Management Department is responsible for overseeing the execution of various business processes within the company, including the volume of orders for sea, air, and rail transport across different regions and business divisions, large customer order volumes, route order volumes, the amount of business entrusted to each operation site for customs, warehousing, and land transportation, as well as the actual revenue and expenses of each region and business division on the day. Through monitoring and analysis of these processes, the company can identify potential issues and bottlenecks, propose measures for improvement and suggestions, in order to optimize operational efficiency.</p><p><strong>Real-Time Data Warehouse Architecture:</strong></p><p><img loading="lazy" src="/assets/images/realtime_warehouse-418beb6d713966065d731eb8417b8a6e.png" width="1080" height="447" class="img_ev3q"></p><p>The current system requires direct collection of real-time data from the production system, but there are multiple data sources that need to be associated for queries. The Fanruan report is not user-friendly when dealing with multiple data sources and cannot re-aggregate multiple data sources. Scheduled queries to the production system database can put pressure on it, affecting the stable operation of the production system. Therefore, we need to introduce a warehouse that can handle real-time data through <a href="https://github.com/ververica/flink-cdc-connectors" target="_blank" rel="noopener noreferrer">Flink CDC</a> technology for stream processing. This data warehouse needs to be able to collect real-time data from multiple data sources and on this basis, perform complex associated SQL queries, machine learning, etc., and avoid unscheduled queries to the production system, thereby reducing the load on the production system and ensuring its stable operation.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="02-big-data-technology-pain-points-and-selection">02 Big Data Technology Pain Points and Selection<a href="#02-big-data-technology-pain-points-and-selection" class="hash-link" aria-label="Direct link to 02 Big Data Technology Pain Points and Selection" title="Direct link to 02 Big Data Technology Pain Points and Selection">​</a></h2><p>Since its establishment, the Bondex big data team has always focused on using efficient operational tools or platforms to achieve effective staffing arrangements, optimize repetitive labor, and reduce manual operations.</p><p>While offline batch data processing has been able to support the group's basic cockpit and management reporting, the Transportation Management Department of the group has proposed the need for real-time statistics on order quantities and operational volumes. The finance department has expressed the need for a real-time display of cash flow. In this context, a big data-based integrated stream-batch solution became imperative.</p><p>Although the big data department has already utilized <a href="https://github.com/apache/doris" target="_blank" rel="noopener noreferrer">Apache Doris</a> for integrated storage and computing of lakehouse architecture and has published articles on lakehouse construction in the Doris community, there are some issues that need to be addressed, such as the inability to reuse streaming data storage, the inaccessibility of intermediate layer data, and the inability to perform real-time aggregation calculations.</p><p>Sorted by the evolution of architecture over recent years, the common architectural solutions are as follows:</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="hadoop-architecture"><strong>Hadoop Architecture</strong><a href="#hadoop-architecture" class="hash-link" aria-label="Direct link to hadoop-architecture" title="Direct link to hadoop-architecture">​</a></h3><p>The demarcation point between traditional data warehouses and internet data warehouses dates back to the early days of the internet when the requirements for data analysis were not high, mainly focusing on reports with low real-time needs to support decision-making. This gave rise to offline data analysis solutions.</p><p><strong>Advantages: </strong>Supports a rich variety of data types, capable of massive computations, low requirements for machine configurations, low timeliness, fault-tolerant.</p><p><strong>Disadvantages: </strong>Does not support real-time; complex to maintain; the query optimizer is not as good as MPP, slow response.</p><p>Selection Basis: Does not support real-time; maintenance is complex, which does not conform to the principle of streamlined staffing; poor performance.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="lambda-architecture"><strong>Lambda Architecture</strong><a href="#lambda-architecture" class="hash-link" aria-label="Direct link to lambda-architecture" title="Direct link to lambda-architecture">​</a></h3><p>Lambda Architecture is a real-time big data processing framework proposed by Nathan Marz, the author of Storm. Marz developed the famous real-time big data processing framework <a href="https://github.com/apache/storm" target="_blank" rel="noopener noreferrer">Apache Storm</a> while working at Twitter, and the Lambda Architecture is the culmination of his years of experience in distributed big data systems.</p><p><img loading="lazy" src="/assets/images/lambda-e357a7e34ced4e82971d4b86acc790b4.png" width="764" height="413" class="img_ev3q"></p><p>Data stream processing is divided into three layers: Serving Layer, Speed Layer, and Batch Layer:</p><ul><li>Batch Layer: Processes offline data and eventually provides a view service to the business;</li><li>Speed Layer: Processes real-time incremental data and eventually provides a view service to the business;</li><li>Serving Layer: Responds to user requests, performs aggregation calculations on offline and incremental data, and ultimately provides the service;</li></ul><p>The advantage is that offline and real-time computations are separated, using two sets of frameworks, which makes the architecture stable.</p><p>The disadvantage is that it is difficult to maintain consistency between offline and real-time data, and operational staff need to maintain two sets of frameworks and three layers of architecture. Developers need to write three sets of code.</p><p>Selection Basis: Data consistency is uncontrollable; operations and development require significant workload, which does not conform to the principle of streamlined staffing.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="kappa-architecture"><strong>Kappa Architecture</strong><a href="#kappa-architecture" class="hash-link" aria-label="Direct link to kappa-architecture" title="Direct link to kappa-architecture">​</a></h3><p>The Kappa Architecture uses a single stream-processing framework to address both offline and real-time data, solving all problems with a real-time stream, with the goal of providing fast and reliable query access to results. It is highly suitable for various data processing workloads, including continuous data pipelines, real-time data processing, machine learning models and real-time analytics, IoT systems, and many other use cases with a single technology stack.</p><p>It is typically implemented using a streaming processing engine such as Apache Flink, Apache Storm, Apache Kinesis, Apache Kafka, designed to handle large data streams and provide fast and reliable query results.</p><p><img loading="lazy" src="/assets/images/kappa-924eb8691ece5d996d9aa740e5b79230.png" width="1080" height="281" class="img_ev3q"></p><p><strong>Advantages: </strong>Single data stream processing framework.</p><p><strong>Disadvantages: </strong>Although its architecture is simpler compared to Lambda Architecture, the setup and maintenance of the streaming processing framework are relatively complex, and it lacks true offline data processing capabilities; storing large amounts of data in streaming platforms can be costly.</p><p>Selection Basis: The capability for offline data processing needs to be retained, and costs controlled.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="iceberg"><strong>Iceberg</strong><a href="#iceberg" class="hash-link" aria-label="Direct link to iceberg" title="Direct link to iceberg">​</a></h3><p>Therefore, we also researched <a href="https://github.com/apache/iceberg" target="_blank" rel="noopener noreferrer">Apache Iceberg</a>, whose snapshot feature can to some extent achieve streaming-batch integration. However, the issue with it is that the real-time table layer based on Kafka is either not queryable or cannot reuse existing tables, with a strong dependency on Kafka. It requires the use of Kafka to write intermediate results to Iceberg tables, increasing system complexity and maintainability.</p><p>Selection Basis: A Kafka-free real-time architecture has been implemented, intermediate data cannot be made queryable or reusable.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="streaming-data-warehouse-continuation-of-the-kappa-architecture"><strong>Streaming Data Warehouse (Continuation of the Kappa Architecture)</strong><a href="#streaming-data-warehouse-continuation-of-the-kappa-architecture" class="hash-link" aria-label="Direct link to streaming-data-warehouse-continuation-of-the-kappa-architecture" title="Direct link to streaming-data-warehouse-continuation-of-the-kappa-architecture">​</a></h3><p>Since the FTS0.3.0 version, the BonDex big data team has participated in the construction of a streaming data warehouse, aiming to further reduce the complexity of the data processing framework and streamline personnel configuration. The initial principle was to get involved with the trend, to continuously learn and improve, and to move closer to cutting-edge technology. The team unanimously believes that it is essential to embrace challenges and "cross the river by feeling the stones." Fortunately, after several iterations, the problems that initially arose have been gradually resolved with the efficient cooperation of the community.</p><p><strong>The architecture of the streaming data warehouse is as follows:</strong></p><p><img loading="lazy" src="/assets/images/streaming_warehouse-ab83b309ef461f3907c2df023143c817.png" width="854" height="494" class="img_ev3q"></p><p>Continuing the characteristics of the Kappa architecture with a single stream processing framework, the advantage lies in the fact that the underlying Paimon technology support makes the data traceable throughout the entire chain. The data warehouse layer architecture can be reused, while also considering the processing capabilities of both offline and real-time data, reducing the waste of storage and computing resources.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="03-production-practices">03 Production Practices<a href="#03-production-practices" class="hash-link" aria-label="Direct link to 03 Production Practices" title="Direct link to 03 Production Practices">​</a></h2><p>This solution adopts Flink Application on K8s clusters, with Flink CDC for real-time ingestion of relational database data from business systems. Tasks for Flink + Paimon Streaming Data Warehouse are submitted through the StreamPark task platform, with the Trino engine ultimately used to access Finereport for service provision and developer queries. Paimon's underlying storage supports the S3 protocol, and as the company's big data services rely on Alibaba Cloud, Object Storage Service (OSS) is used as the data filesystem.</p><p><a href="https://github.com/apache/incubator-streampark" target="_blank" rel="noopener noreferrer">StreamPark</a> is a real-time computing platform that leverages the powerful capabilities of <a href="https://github.com/apache/incubator-paimon" target="_blank" rel="noopener noreferrer">Paimon</a> to process real-time data streams. This platform offers the following key features:</p><p><strong>Real-time Data Processing: </strong>StreamPark supports the submission of real-time data stream tasks, capable of real-time acquisition, transformation, filtering, and analysis of data. This is extremely important for applications that require rapid response to real-time data, such as real-time monitoring, real-time recommendations, and real-time risk control.</p><p><strong>Scalability: </strong>Capable of efficiently processing large-scale real-time data with good scalability. It can operate in a distributed computing environment, automatically handling parallelization, fault recovery, and load balancing to ensure efficient and reliable data processing.</p><p><strong>Flink Integration: </strong>Built on <a href="https://github.com/apache/flink" target="_blank" rel="noopener noreferrer">Apache Flink</a>, it leverages Flink’s powerful stream processing engine for high performance and robustness. Users can fully utilize the features and ecosystem of Flink, such as its extensive connectors, state management, and event-time processing.</p><p><strong>Ease of Use: </strong>Provides a straightforward graphical interface and simplified API, enabling easy construction and deployment of data processing tasks without needing to delve into underlying technical details.</p><p>By submitting Paimon tasks on the StreamPark platform, we can establish a full-link real-time flowing, queryable, and layered reusable Pipline.</p><p><img loading="lazy" src="/assets/images/pipline-60b68a9487092b6866020ce983a85ac0.png" width="1080" height="496" class="img_ev3q"></p><p>The main components versions used are as follows:</p><ul><li>flink-1.16.0-scala-2.12</li><li>paimon-flink-1.16-0.4-20230424.001927-40.jar</li><li>apache-streampark_2.12-2.0.0</li><li>kubernetes v1.18.3</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="environment-setup"><strong>Environment Setup</strong><a href="#environment-setup" class="hash-link" aria-label="Direct link to environment-setup" title="Direct link to environment-setup">​</a></h3><p>Download flink-1.16.0-scala-2.12.tar.gz which can be obtained from the official Flink website. Download the corresponding version of the package to the StreamPark deployment server.</p><div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token comment" style="color:rgb(98, 114, 164)"># Unzip</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token function" style="color:rgb(80, 250, 123)">tar</span><span class="token plain"> zxvf flink-1.16.0-scala-2.12.tar.gz</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Modify the flink-conf configuration file and start the cluster</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">jobmanager.rpc.address: localhost</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">jobmanager.rpc.port: </span><span class="token number">6123</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">jobmanager.bind-host: localhost</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">jobmanager.memory.process.size: 4096m</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">taskmanager.bind-host: localhost</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">taskmanager.host: localhost</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">taskmanager.memory.process.size: 4096m</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">taskmanager.numberOfTaskSlots: </span><span class="token number">4</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">parallelism.default: </span><span class="token number">4</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">akka.ask.timeout: 100s</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">web.timeout: </span><span class="token number">1000000</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)">#checkpoints&amp;&amp;savepoints</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">state.checkpoints.dir: file:///opt/flink/checkpoints</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">state.savepoints.dir: file:///opt/flink/savepoints</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">execution.checkpointing.interval: 2min</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># When the job is manually canceled/paused, the Checkpoint state information of the job will be retained</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">execution.checkpointing.externalized-checkpoint-retention: RETAIN_ON_CANCELLATION</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">state.backend: rocksdb</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Number of completed Checkpoints to retain</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">state.checkpoints.num-retained: </span><span class="token number">2000</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">state.backend.incremental: </span><span class="token boolean">true</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">execution.checkpointing.checkpoints-after-tasks-finish.enabled: </span><span class="token boolean">true</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)">#OSS</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">fs.oss.endpoint: oss-cn-zhangjiakou-internal.aliyuncs.com</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">fs.oss.accessKeyId: xxxxxxxxxxxxxxxxxxxxxxx</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">fs.oss.accessKeySecret: xxxxxxxxxxxxxxxxxxxxxxx</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">fs.oss.impl: org.apache.hadoop.fs.aliyun.oss.AliyunOSSFileSystem</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">jobmanager.execution.failover-strategy: region</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">rest.port: </span><span class="token number">8081</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">rest.address: localhost</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>It is suggested to add FLINK_HOME locally for convenient troubleshooting before deploying on k8s.</p><p>vim /etc/profile</p><div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token comment" style="color:rgb(98, 114, 164)">#FLINK</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token builtin class-name" style="color:rgb(189, 147, 249)">export</span><span class="token plain"> </span><span class="token assign-left variable" style="color:rgb(189, 147, 249);font-style:italic">FLINK_HOME</span><span class="token operator">=</span><span class="token plain">/data/src/flink-1.16.0-scala-2.12</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token builtin class-name" style="color:rgb(189, 147, 249)">export</span><span class="token plain"> </span><span class="token assign-left variable environment constant" style="color:rgb(189, 147, 249);font-style:italic">PATH</span><span class="token operator">=</span><span class="token environment constant" style="color:rgb(189, 147, 249)">$PATH</span><span class="token builtin class-name" style="color:rgb(189, 147, 249)">:</span><span class="token variable" style="color:rgb(189, 147, 249);font-style:italic">$FLINK_HOME</span><span class="token plain">/bin</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token builtin class-name" style="color:rgb(189, 147, 249)">source</span><span class="token plain"> /etc/profile</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>In StreamPark, add Flink conf:</p><p><img loading="lazy" src="/assets/images/flink_conf-1c8b9773c6678621a140320ae2a8525f.jpg" width="1080" height="427" class="img_ev3q"></p><p>To build the Flink 1.16.0 base image, pull the corresponding version of the image from Docker Hub.</p><div class="language-dockerfile codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-dockerfile codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Pull the image</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">docker pull flink:1.16.0-scala_2.12-java8</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Tag the image</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">docker tagflink:1.16.0-scala_2.12-java8  registry-vpc.cn-zhangjiakou.aliyuncs.com/xxxxx/flink:1.16.0-scala_2.12-java8</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Push to the company repository</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">docker pushregistry-vpc.cn-zhangjiakou.aliyuncs.com/xxxxx/flink:1.16.0-scala_2.12-java8</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Create a Dockerfile &amp; target directory to place the flink-oss-fs-hadoop JAR package in that directory. Download the shaded Hadoop OSS file system jar package from:</p><p><a href="https://repository.apache.org/snapshots/org/apache/paimon/paimon-oss/" target="_blank" rel="noopener noreferrer">https://repository.apache.org/snapshots/org/apache/paimon/paimon-oss/</a></p><p>.</p><p>├── Dockerfile</p><p>└── target</p><p> └── flink-oss-fs-hadoop-1.16.0.jar</p><div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token function" style="color:rgb(80, 250, 123)">touch</span><span class="token plain"> Dockerfile</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token function" style="color:rgb(80, 250, 123)">mkdir</span><span class="token plain"> target</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)">#vim Dockerfile</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">FROM registry-vpc.cn-zhangjiakou.aliyuncs.com/xxxxx/flink:1.16.0-scala_2.12-java8</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">RUN </span><span class="token function" style="color:rgb(80, 250, 123)">mkdir</span><span class="token plain"> /opt/flink/plugins/oss-fs-hadoop</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">COPY target/flink-oss-fs-hadoop-1.16.0.jar  /opt/flink/plugins/oss-fs-hadoop</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="build-base-image"><strong>Build base image</strong><a href="#build-base-image" class="hash-link" aria-label="Direct link to build-base-image" title="Direct link to build-base-image">​</a></h3><div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token function" style="color:rgb(80, 250, 123)">docker</span><span class="token plain"> build -t flink-table-store:v1.16.0 </span><span class="token builtin class-name" style="color:rgb(189, 147, 249)">.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token function" style="color:rgb(80, 250, 123)">docker</span><span class="token plain"> tag flink-table-store:v1.16.0 registry-vpc.cn-zhangjiakou.aliyuncs.com/xxxxx/flink-table-store:v1.16.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token function" style="color:rgb(80, 250, 123)">docker</span><span class="token plain"> push registry-vpc.cn-zhangjiakou.aliyuncs.com/xxxxx/flink-table-store:v1.16.0</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Next, prepare the Paimon jar package. You can download the corresponding version from the Apache <a href="https://repository.apache.org/content/groups/snapshots/org/apache/paimon" target="_blank" rel="noopener noreferrer">Repository</a>. It's important to note that it should be consistent with the major version of Flink.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="managing-jobs-with-streampark"><strong>Managing Jobs with StreamPark</strong><a href="#managing-jobs-with-streampark" class="hash-link" aria-label="Direct link to managing-jobs-with-streampark" title="Direct link to managing-jobs-with-streampark">​</a></h3><p><strong>Prerequisites:</strong></p><ul><li>Kubernetes client connection configuration</li><li>Kubernetes RBAC configuration</li><li>Container image repository configuration (the free version of Alibaba Cloud image is used in this case)</li><li>Create a PVC resource to mount checkpoints/savepoints</li></ul><p><strong>Kubernetes Client Connection Configuration:</strong></p><p>Copy the k8s master node's <code>~/.kube/config</code> configuration directly to the directory on the StreamPark server, then execute the following command on the StreamPark server to display the k8s cluster as running, which indicates successful permission and network verification.</p><div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">kubectl cluster-info</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Kubernetes RBAC Configuration, create the streampark namespace:</p><div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">kubectl create ns streampark</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Use the default account to create the clusterrolebinding resource:</p><div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">kubectl create secret docker-registry streamparksecret </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">--docker-server</span><span class="token operator">=</span><span class="token plain">registry-vpc.cn-zhangjiakou.aliyuncs.com </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">--docker-username</span><span class="token operator">=</span><span class="token plain">xxxxxx </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">--docker-password</span><span class="token operator">=</span><span class="token plain">xxxxxx -n streamx```</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><strong>Container Image Registry Configuration:</strong></p><p>In this case, Alibaba Cloud's Container Registry Service (ACR) is used, but you can also substitute it with a self-hosted image service such as Harbor.</p><p>Create a namespace named StreamPark (set the security setting to private).</p><p><img loading="lazy" src="/assets/images/aliyun-43dec052b5792743675fb5a0e5980ebc.png" width="1080" height="316" class="img_ev3q"></p><p>Configure the image repository in StreamPark; task build images will be pushed to the repository.</p><p><img loading="lazy" src="/assets/images/dockersystem_setting-60d5b7d9e930185cf1a9a404beab9dc0.png" width="1080" height="360" class="img_ev3q"></p><p>Create a k8s secret key to pull images from ACR; streamparksecret is the name of the secret, customizable.</p><div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">kubectl create secret docker-registry streamparksecret </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">--docker-server</span><span class="token operator">=</span><span class="token plain">registry-vpc.cn-zhangjiakou.aliyuncs.com </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">--docker-username</span><span class="token operator">=</span><span class="token plain">xxxxxx </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">--docker-password</span><span class="token operator">=</span><span class="token plain">xxxxxx -n streamx</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Creation of PVC Resources for Checkpoints/Savepoints, Utilizing Alibaba Cloud's OSS for K8S Persistence</p><p><strong>OSS CSI Plugin:</strong></p><p>The OSS CSI plugin can be used to help simplify storage management. You can use the CSI configuration to create a PV, and define PVCs and pods as usual. For the YAML file reference, visit:
<a href="https://bondextest.oss-cn-zhangjiakou.aliyuncs.com/ossyaml.zip" target="_blank" rel="noopener noreferrer">https://bondextest.oss-cn-zhangjiakou.aliyuncs.com/ossyaml.zip</a></p><p><strong>Configuration Requirements:</strong></p><p>-<!-- --> Create a service account with the necessary RBAC permissions, please refer as below:</p><p><a href="https://github.com/kubernetes-sigs/alibaba-cloud-csi-driver/blob/master/docs/oss.md" target="_blank" rel="noopener noreferrer">https://github.com/kubernetes-sigs/alibaba-cloud-csi-driver/blob/master/docs/oss.md</a></p><div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">kubectl -f rbac.yaml</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>-<!-- --> Deploy the OSS CSI Plugin:</p><div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">kubectl -f oss-plugin.yaml</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>-<!-- --> Create PV for CP (Checkpoints) &amp; SP (Savepoints):</p><div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">kubectl -f checkpoints_pv.yaml kubectl -f savepoints_pv.yaml</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>-<!-- --> Create PVC for CP &amp; SP:</p><div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">kubectl -f checkpoints_pvc.yaml kubectl -f savepoints_pvc.yaml</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Once the dependent environment is configured, we can start using Paimon for layered development of the streaming data warehouse.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="case-study"><strong>Case Study</strong><a href="#case-study" class="hash-link" aria-label="Direct link to case-study" title="Direct link to case-study">​</a></h3><p>Real-time calculation of sea and air freight consignment volumes.</p><p>Job Submission: Initialize Paimon catalog configuration.</p><p><img loading="lazy" src="/assets/images/paimon_catalog_setting-aa6a826f1cb1a7d9c90fc3fae71a0ef3.png" width="592" height="637" class="img_ev3q"></p><div class="language-sql codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sql codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">SET</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'execution.runtime-mode'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'streaming'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">set</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'table.exec.sink.upsert-materialize'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'none'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">SET</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'sql-client.execution.result-mode'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'tableau'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)">-- Create and use FTS Catalog with underlying storage solution using Alibaba Cloud OSS</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">CREATE</span><span class="token plain"> CATALOG </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">table_store</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">WITH</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'type'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'paimon'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'warehouse'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'oss://xxxxx/xxxxx'</span><span class="token plain"> </span><span class="token comment" style="color:rgb(98, 114, 164)"># customize oss storage path</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">USE</span><span class="token plain"> CATALOG </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">table_store</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>A single job extracts table data from postgres, mysql, and sqlserver databases and writes it into Paimon.</p><p><img loading="lazy" src="/assets/images/application_setting-48542837b22debfeca15eddaf6ea93a0.png" width="1080" height="533" class="img_ev3q"></p><p><img loading="lazy" src="/assets/images/pom-949e43be1f8e611776858b7573047de2.jpg" width="1080" height="597" class="img_ev3q"></p><p><img loading="lazy" src="/assets/images/pod_template-4a36a24383f78f09d3090e5ddf7fe1fa.png" width="1080" height="623" class="img_ev3q"></p><p><strong>Details are as follows:</strong></p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">Development Mode：Flink SQL</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Execution Mode ：kubernetes application</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Flink Version ：flink-1.16.0-scala-2.12</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Kubernetes Namespace ：streamx</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Kubernetes ClusterId ：(Task name can be customized)</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Base image uploaded to Alibaba Cloud Image Repository</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Flink Base Docker Image ：registry-vpc.cn-zhangjiakou.aliyuncs.com/xxxxx/flink-table-store:v1.16.0    </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Rest-Service Exposed Type：NodePort</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Paimon base dependency package:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">paimon-flink-1.16-0.4-20230424.001927-40.jar</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">flink-shaded-hadoop-2-uber-2.8.3-10.0.jar</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># FlinkCDC dependency package download address:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">https://github.com/ververica/flink-cdc-connectors/releases/tag/release-2.2.0</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><strong>pod template:</strong></p><div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token key atrule">apiVersion</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> v1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">kind</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> Pod</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">metadata</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">name</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> pod</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">template</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">spec</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">containers</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain"> </span><span class="token key atrule">name</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> flink</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">main</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">container</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">volumeMounts</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain"> </span><span class="token key atrule">name</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> flink</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">checkpoints</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">csi</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">pvc</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token key atrule">mountPath</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> /opt/flink/checkpoints</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain"> </span><span class="token key atrule">name</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> flink</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">savepoints</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">csi</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">pvc</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token key atrule">mountPath</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> /opt/flink/savepoints</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">volumes</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain"> </span><span class="token key atrule">name</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> flink</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">checkpoints</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">csi</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">pvc</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">persistentVolumeClaim</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><span class="token key atrule">claimName</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> flink</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">checkpoints</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">csi</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">pvc</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain"> </span><span class="token key atrule">name</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> flink</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">savepoints</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">csi</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">pvc</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">persistentVolumeClaim</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      </span><span class="token key atrule">claimName</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> flink</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">savepoints</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">csi</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">pvc</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">imagePullSecrets</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain"> </span><span class="token key atrule">name</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> streamparksecret</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><strong>Flink sql：</strong></p><ol><li>Establish the relationship between the source table and the ODS table in Paimon, here it is a one-to-one mapping between the source table and the target table.</li></ol><div class="language-sql codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sql codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token comment" style="color:rgb(98, 114, 164)">-- PostgreSQL database example</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">CREATE</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">TEMPORARY</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">TABLE</span><span class="token plain"> </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">shy_doc_hdworkdochd</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">doccode</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">50</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token operator">not</span><span class="token plain"> </span><span class="token boolean">null</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Primary Key'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">businessmodel</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">450</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Business Model'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">businesstype</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">450</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain">  </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Business Type'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">transporttype</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">50</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Transportation Type'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">bookingguid</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">50</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Operation Number'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">PRIMARY</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">KEY</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">doccode</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> ENFORCED</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">WITH</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'connector'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'postgres-cdc'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'hostname'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Database server IP address'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'port'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Port number'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'username'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Username'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'password'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Password'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'database-name'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Database name'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'schema-name'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'dev'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'decoding.plugin.name'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'wal2json'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'table-name'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'doc_hdworkdochd'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'debezium.slot.name'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'hdworkdochdslotname03'</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">CREATE</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">TEMPORARY</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">TABLE</span><span class="token plain"> </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">shy_base_enterprise</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">entguid</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">50</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token operator">not</span><span class="token plain"> </span><span class="token boolean">null</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Primary Key'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">entorgcode</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">450</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Customer Code'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">entnature</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">450</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain">  </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Customer Type'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">entfullname</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">50</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Customer Full Name'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">PRIMARY</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">KEY</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">entguid</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">entorgcode</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> ENFORCED</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">WITH</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'connector'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'postgres-cdc'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'hostname'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Database server IP address'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'port'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Port number'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'username'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Username'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'password'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Password'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'database-name'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Database name'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'schema-name'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'dev'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'decoding.plugin.name'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'wal2json'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'table-name'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'base_enterprise'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'debezium.snapshot.mode'</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">'never'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token comment" style="color:rgb(98, 114, 164)">-- Incremental synchronization (ignore this property for full + incremental)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'debezium.slot.name'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'base_enterprise_slotname03'</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)">-- Create the corresponding target table in the ods layer on Paimon according to the source table structure</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">CREATE</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">TABLE</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">IF</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">EXISTS</span><span class="token plain"> ods</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">ods_shy_jh_doc_hdworkdochd</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">o_year</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">BIGINT</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token boolean">NULL</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Partition Field'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">create_date</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">timestamp</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token boolean">NULL</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Creation Time'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">PRIMARY</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">KEY</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">o_year</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">doccode</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> ENFORCED</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> PARTITIONED </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">BY</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">o_year</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">WITH</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'changelog-producer.compaction-interval'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'2m'</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token operator">LIKE</span><span class="token plain"> </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">shy_doc_hdworkdochd</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">EXCLUDING CONSTRAINTS EXCLUDING OPTIONS</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">CREATE</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">TABLE</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">IF</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">EXISTS</span><span class="token plain"> ods</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">ods_shy_base_enterprise</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">create_date</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">timestamp</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token boolean">NULL</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Creation Time'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">PRIMARY</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">KEY</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">entguid</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">entorgcode</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> ENFORCED</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">WITH</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'changelog-producer.compaction-interval'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'2m'</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token operator">LIKE</span><span class="token plain"> </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">shy_base_enterprise</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">EXCLUDING CONSTRAINTS EXCLUDING OPTIONS</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)">-- Set the job name, execute the job task to write the source table data into the corresponding Paimon table in real time</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">SET</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'pipeline.name'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'ods_doc_hdworkdochd'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">INSERT</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">INTO</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">ods</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">ods_shy_jh_doc_hdworkdochd</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">SELECT</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token operator">*</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">YEAR</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">docdate</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">AS</span><span class="token plain"> </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">o_year</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">TO_TIMESTAMP</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">CONVERT_TZ</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">cast</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">CURRENT_TIMESTAMP</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">as</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'UTC'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Asia/Shanghai'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">AS</span><span class="token plain"> </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">create_date</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">FROM</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">shy_doc_hdworkdochd</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">where</span><span class="token plain"> </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">docdate</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token operator">is</span><span class="token plain"> </span><span class="token operator">not</span><span class="token plain"> </span><span class="token boolean">null</span><span class="token plain"> </span><span class="token operator">and</span><span class="token plain"> </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">docdate</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token operator">&gt;</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'2023-01-01'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">SET</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'pipeline.name'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'ods_shy_base_enterprise'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">INSERT</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">INTO</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">ods</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">ods_shy_base_enterprise</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">SELECT</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token operator">*</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">TO_TIMESTAMP</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">CONVERT_TZ</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">cast</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">CURRENT_TIMESTAMP</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">as</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'UTC'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Asia/Shanghai'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">AS</span><span class="token plain"> </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">create_date</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">FROM</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">shy_base_enterprise</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">where</span><span class="token plain"> entorgcode </span><span class="token operator">is</span><span class="token plain"> </span><span class="token operator">not</span><span class="token plain"> </span><span class="token boolean">null</span><span class="token plain"> </span><span class="token operator">and</span><span class="token plain"> entorgcode </span><span class="token operator">&lt;&gt;</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">''</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)">-- MySQL database example</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">CREATE</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">TEMPORARY</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">TABLE</span><span class="token plain"> </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">doc_order</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">id</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">BIGINT</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token boolean">NULL</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Primary Key'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">order_no</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">50</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token boolean">NULL</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Order Number'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">business_no</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">50</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'OMS Service Number'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">is_deleted</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">int</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Is Deleted'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">PRIMARY</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">KEY</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">id</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> ENFORCED</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">WITH</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'connector'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'mysql-cdc'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'hostname'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Database server address'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'port'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Port number'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'username'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Username'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'password'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Password'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'database-name'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Database name'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'table-name'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'doc_order'</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)">-- Create the corresponding target table in the ods layer on Paimon according to the source table structure</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">CREATE</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">TABLE</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">IF</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">EXISTS</span><span class="token plain"> ods</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">ods_bondexsea_doc_order</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">o_year</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">BIGINT</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token boolean">NULL</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Partition Field'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">create_date</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">timestamp</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token boolean">NULL</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Creation Time'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">PRIMARY</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">KEY</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">o_year</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">id</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> ENFORCED</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> PARTITIONED </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">BY</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">o_year</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">WITH</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'changelog-producer.compaction-interval'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'2m'</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token operator">LIKE</span><span class="token plain"> </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">doc_order</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">EXCLUDING CONSTRAINTS EXCLUDING OPTIONS</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)">-- Set the job name, execute the job task to write the source table data into the corresponding Paimon table in real time</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">SET</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'pipeline.name'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'ods_bondexsea_doc_order'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">INSERT</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">INTO</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">ods</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">ods_bondexsea_doc_order</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">SELECT</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token operator">*</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">YEAR</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">gmt_create</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">AS</span><span class="token plain"> </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">o_year</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">TO_TIMESTAMP</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">CONVERT_TZ</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">cast</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">CURRENT_TIMESTAMP</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">as</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'UTC'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Asia/Shanghai'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">AS</span><span class="token plain"> </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">create_date</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">FROM</span><span class="token plain"> </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">doc_order</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">where</span><span class="token plain"> gmt_create </span><span class="token operator">&gt;</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'2023-01-01'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)">-- SQL Server database example</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">CREATE</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">TEMPORARY</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">TABLE</span><span class="token plain"> </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">OrderHAWB</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">HBLIndex</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">50</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token boolean">NULL</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Primary Key'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">CustomerNo</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">50</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Customer Number'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">CreateOPDate</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">timestamp</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Billing Date'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">PRIMARY</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">KEY</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">HBLIndex</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> ENFORCED</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">WITH</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'connector'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'sqlserver-cdc'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'hostname'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Database server address'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'port'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Port number'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'username'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Username'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'password'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Password'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'database-name'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Database name'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'schema-name'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'dbo'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)">-- 'debezium.snapshot.mode' = 'initial' -- Extract both full and incremental</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'scan.startup.mode'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'latest-offset'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token comment" style="color:rgb(98, 114, 164)">-- Extract only incremental data</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'table-name'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'OrderHAWB'</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)">-- Create the corresponding target table in the ods layer on Paimon according to the source table structure</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">CREATE</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">TABLE</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">IF</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">EXISTS</span><span class="token plain"> ods</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">ods_airsea_airfreight_orderhawb</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">o_year</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">BIGINT</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token boolean">NULL</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Partition Field'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">create_date</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">timestamp</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token boolean">NULL</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Creation Time'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">PRIMARY</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">KEY</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">o_year</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">HBLIndex</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> ENFORCED</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> PARTITIONED </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">BY</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">o_year</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">WITH</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'changelog-producer.compaction-interval'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'2m'</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token operator">LIKE</span><span class="token plain"> </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">OrderHAWB</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">EXCLUDING CONSTRAINTS EXCLUDING OPTIONS</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)">-- Set the job name, execute the job task to write the source table data into the corresponding Paimon table in real time</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">SET</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'pipeline.name'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'ods_airsea_airfreight_orderhawb'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">INSERT</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">INTO</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">ods</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">ods_airsea_airfreight_orderhawb</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">SELECT</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">RTRIM</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">HBLIndex</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">as</span><span class="token plain"> </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">HBLIndex</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">CreateOPDate</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">YEAR</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">CreateOPDate</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">AS</span><span class="token plain"> </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">o_year</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">TO_TIMESTAMP</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">CONVERT_TZ</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">cast</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">CURRENT_TIMESTAMP</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">as</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'UTC'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Asia/Shanghai'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">AS</span><span class="token plain"> </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">create_date</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">FROM</span><span class="token plain"> </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">OrderHAWB</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">where</span><span class="token plain"> CreateOPDate </span><span class="token operator">&gt;</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'2023-01-01'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>The real-time data writing effect of the business table into the Paimon ods table is as follows:</p><p><img loading="lazy" src="/assets/images/ods-bc0d5ecbef808b0ca349311569803f18.png" width="1080" height="422" class="img_ev3q"></p><ol start="2"><li>Flatten the data from the ods layer tables and write it into the dwd layer. This process is essentially about merging the related business tables from the ods layer into the dwd layer. The main focus here is on processing the value of the count_order field. Since the data in the source table may be logically or physically deleted, using the count function for statistics may lead to issues. Therefore, we use the sum aggregate to calculate the order quantity. Each reference_no corresponds to a count_order of 1. If it is logically voided, it will be processed as 0 through SQL, and Paimon will automatically handle physical deletions.</li></ol><p>For the dim dimension table, we directly use the dimension table processed in Doris, as the update frequency of the dimension table is low, so there was no need for secondary development within Paimon.</p><div class="language-sql codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sql codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token comment" style="color:rgb(98, 114, 164)">-- Create a wide table at the paimon-dwd layer</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">CREATE</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">TABLE</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">IF</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">EXISTS</span><span class="token plain"> dwd</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">dwd_business_order</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">reference_no</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">50</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token boolean">NULL</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Primary key for the consignment order number'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">bondex_shy_flag</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">8</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token boolean">NULL</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Differentiator'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">is_server_item</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">int</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token boolean">NULL</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Whether it has been linked to an order'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">order_type_name</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">50</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token boolean">NULL</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Business category'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">consignor_date</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">DATE</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Statistic date'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">consignor_code</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">50</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Customer code'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">consignor_name</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">160</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Customer name'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">sales_code</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">32</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token boolean">NULL</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Sales code'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">sales_name</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">200</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token boolean">NULL</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Sales name'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">delivery_center_op_id</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">32</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token boolean">NULL</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Delivery number'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">delivery_center_op_name</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">200</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token boolean">NULL</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Delivery name'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">pol_code</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">100</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token boolean">NULL</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'POL code'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">pot_code</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">100</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token boolean">NULL</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'POT code'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">port_of_dest_code</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">100</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token boolean">NULL</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'POD code'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">is_delete</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">int</span><span class="token plain"> </span><span class="token operator">not</span><span class="token plain"> </span><span class="token boolean">NULL</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Whether it is void'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">order_status</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">8</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token boolean">NULL</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Order status'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">count_order</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">BIGINT</span><span class="token plain"> </span><span class="token operator">not</span><span class="token plain"> </span><span class="token boolean">NULL</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Order count'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">o_year</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">BIGINT</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token boolean">NULL</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Partition field'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">create_date</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">timestamp</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token boolean">NULL</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Creation time'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">PRIMARY</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">KEY</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">o_year</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">reference_no</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">bondex_shy_flag</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> ENFORCED</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> PARTITIONED </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">BY</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">o_year</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">WITH</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)">-- Set 2 buckets under each partition</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'bucket'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'2'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'changelog-producer'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'full-compaction'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'snapshot.time-retained'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'2h'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'changelog-producer.compaction-interval'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'2m'</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)">-- Set the job name to merge the related business tables from the ods layer into the dwd layer</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">SET</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'pipeline.name'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'dwd_business_order'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">INSERT</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">INTO</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">dwd</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">dwd_business_order</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">SELECT</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">o</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">doccode</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">YEAR</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">o</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">docdate</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">AS</span><span class="token plain"> o_year</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">TO_TIMESTAMP</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">CONVERT_TZ</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">cast</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">CURRENT_TIMESTAMP</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">as</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'UTC'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Asia/Shanghai'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">AS</span><span class="token plain"> </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">create_date</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">FROM</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">ods</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">ods_shy_jh_doc_hdworkdochd o</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">INNER</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">JOIN</span><span class="token plain"> ods</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">ods_shy_base_enterprise en </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">ON</span><span class="token plain"> o</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">businessguid </span><span class="token operator">=</span><span class="token plain"> en</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">entguid</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">LEFT</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">JOIN</span><span class="token plain"> dim</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">dim_hhl_user_code sales </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">ON</span><span class="token plain"> o</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">salesguid </span><span class="token operator">=</span><span class="token plain"> sales</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">USER_GUID</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">LEFT</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">JOIN</span><span class="token plain"> dim</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">dim_hhl_user_code op </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">ON</span><span class="token plain"> o</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">bookingguid </span><span class="token operator">=</span><span class="token plain"> op</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">USER_GUID</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">UNION</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">ALL</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">SELECT</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">business_no</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">YEAR</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"> gmt_create </span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">AS</span><span class="token plain"> o_year</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">TO_TIMESTAMP</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">CONVERT_TZ</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">cast</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">CURRENT_TIMESTAMP</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">as</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'UTC'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Asia/Shanghai'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">AS</span><span class="token plain"> </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">create_date</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">FROM</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">ods</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">ods_bondexsea_doc_order</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">UNION</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">ALL</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">SELECT</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  HBLIndex</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">YEAR</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"> CreateOPDate </span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">AS</span><span class="token plain"> o_year</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">TO_TIMESTAMP</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">CONVERT_TZ</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">cast</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">CURRENT_TIMESTAMP</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">as</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'UTC'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Asia/Shanghai'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">AS</span><span class="token plain"> </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">create_date</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">FROM</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  ods</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">ods_airsea_airfreight_orderhawb</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>In the Flink UI, you can see the ods data is joined and cleansed in real-time through Paimon to the table dwd_business_order.</p><p><img loading="lazy" src="/assets/images/dwd_business_order-a017b7fa6dac855794cf9720a0421090.png" width="1080" height="646" class="img_ev3q"></p><ol start="2"><li>The data from the dwd layer is lightly aggregated to the dwm layer, and the related data is written into the dwm.dwm_business_order_count table. The data in this table will perform a sum on the aggregated fields based on the primary key, with the sum_orderCount field being the result of the aggregation. Paimon will automatically handle the data that is physically deleted during the sum.</li></ol><div class="language-sql codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sql codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token comment" style="color:rgb(98, 114, 164)">-- Create a lightweight summary table on the dwm layer, summarizing the order volume by date, sales, operation, business category, customer, port of loading, and destination port</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">CREATE</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">TABLE</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">IF</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">EXISTS</span><span class="token plain"> dwm</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">dwm_business_order_count</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">l_year</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">BIGINT</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token boolean">NULL</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Statistic year'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">l_month</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">BIGINT</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token boolean">NULL</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Statistic month'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">l_date</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">DATE</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token boolean">NULL</span><span class="token plain">  </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Statistic date'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">bondex_shy_flag</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">8</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token boolean">NULL</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Identifier'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">order_type_name</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">50</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token boolean">NULL</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Business category'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">is_server_item</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">int</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token boolean">NULL</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Whether an order has been associated'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">customer_code</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">50</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token boolean">NULL</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Customer code'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">sales_code</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">50</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token boolean">NULL</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Sales code'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">delivery_center_op_id</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">50</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token boolean">NULL</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Delivery ID'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">pol_code</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">100</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token boolean">NULL</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Port of loading code'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">pot_code</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">100</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token boolean">NULL</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Transshipment port code'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">port_of_dest_code</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">100</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token boolean">NULL</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Destination port code'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">customer_name</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">200</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token boolean">NULL</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Customer name'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">sales_name</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">200</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token boolean">NULL</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Sales name'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">delivery_center_op_name</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">200</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token boolean">NULL</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Delivery name'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">sum_orderCount</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">BIGINT</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token boolean">NULL</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Order count'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">create_date</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">timestamp</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token boolean">NULL</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Creation time'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">PRIMARY</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">KEY</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">l_year</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">             </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">l_month</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">             </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">l_date</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">             </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">order_type_name</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">             </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">bondex_shy_flag</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">             </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">is_server_item</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">             </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">customer_code</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">             </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">sales_code</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">             </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">delivery_center_op_id</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">             </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">pol_code</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">             </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">pot_code</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">             </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">port_of_dest_code</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> ENFORCED</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">WITH</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'changelog-producer'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'full-compaction'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token string" style="color:rgb(255, 121, 198)">'changelog-producer.compaction-interval'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'2m'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token string" style="color:rgb(255, 121, 198)">'merge-engine'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'aggregation'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token comment" style="color:rgb(98, 114, 164)">-- Use aggregation to calculate sum</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token string" style="color:rgb(255, 121, 198)">'fields.sum_orderCount.aggregate-function'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'sum'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token string" style="color:rgb(255, 121, 198)">'fields.create_date.ignore-retract'</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">'true'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token string" style="color:rgb(255, 121, 198)">'fields.sales_name.ignore-retract'</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">'true'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token string" style="color:rgb(255, 121, 198)">'fields.customer_name.ignore-retract'</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">'true'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token string" style="color:rgb(255, 121, 198)">'snapshot.time-retained'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'2h'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'fields.delivery_center_op_name.ignore-retract'</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">'true'</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)">-- Set the job name</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">SET</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'pipeline.name'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'dwm_business_order_count'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">INSERT</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">INTO</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">dwm</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">dwm_business_order_count</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">SELECT</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">YEAR</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">o</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">consignor_date</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">AS</span><span class="token plain"> </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">l_year</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">MONTH</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">o</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">consignor_date</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">AS</span><span class="token plain"> </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">l_month</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">TO_TIMESTAMP</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">CONVERT_TZ</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">cast</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">CURRENT_TIMESTAMP</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">as</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'UTC'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Asia/Shanghai'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">AS</span><span class="token plain"> create_date</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">FROM</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">dwd</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">dwd_business_order</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> o</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>The Flink UI effect is as follows: the data from dwd_business_orders is aggregated into dwm_business_order_count:</p><p><img loading="lazy" src="/assets/images/dwm_business_order_count-1abbcf7d6b31f15e49f2e035ecfdb8d7.png" width="194" height="649" class="img_ev3q"></p><ol start="4"><li>Aggregate the data from the dwm layer to the dws layer, where the dws layer performs summaries at even finer dimensions.</li></ol><div class="language-sql codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sql codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token comment" style="color:rgb(98, 114, 164)">-- Create a table to aggregate daily order counts by operator and business type</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">CREATE</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">TABLE</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">IF</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">EXISTS</span><span class="token plain"> dws</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">dws_business_order_count_op</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">l_year</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">BIGINT</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token boolean">NULL</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Statistic Year'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">l_month</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">BIGINT</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token boolean">NULL</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Statistic Month'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">l_date</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">DATE</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token boolean">NULL</span><span class="token plain">  </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Statistic Date'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">order_type_name</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">50</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token boolean">NULL</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Business Category'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">delivery_center_op_id</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">50</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token boolean">NULL</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Delivery ID'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">delivery_center_op_name</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token number">200</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token boolean">NULL</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Delivery Name'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">sum_orderCount</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">BIGINT</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token boolean">NULL</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Order Count'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">create_date</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">timestamp</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> </span><span class="token boolean">NULL</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">COMMENT</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Creation Time'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">PRIMARY</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">KEY</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">l_year</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">l_month</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">l_date</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">order_type_name</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">delivery_center_op_id</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token operator">NOT</span><span class="token plain"> ENFORCED</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">WITH</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token string" style="color:rgb(255, 121, 198)">'merge-engine'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'aggregation'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token comment" style="color:rgb(98, 114, 164)">-- Use aggregation to compute sum</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token string" style="color:rgb(255, 121, 198)">'fields.sum_orderCount.aggregate-function'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'sum'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token string" style="color:rgb(255, 121, 198)">'fields.create_date.ignore-retract'</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">'true'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token string" style="color:rgb(255, 121, 198)">'snapshot.time-retained'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'2h'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token string" style="color:rgb(255, 121, 198)">'fields.delivery_center_op_name.ignore-retract'</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">'true'</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)">-- Set the job name</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">SET</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'pipeline.name'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'dws_business_order_count_op'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">INSERT</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">INTO</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  dws</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">dws_business_order_count_op</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">SELECT</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  o</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">l_year</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">o</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">l_month</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">o</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">l_date</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">o</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">order_type_name</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">o</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">delivery_center_op_id</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">o</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">delivery_center_op_name</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">o</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">sum_orderCount</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">TO_TIMESTAMP</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">CONVERT_TZ</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">cast</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">CURRENT_TIMESTAMP</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">as</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">varchar</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'UTC'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'Asia/Shanghai'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">AS</span><span class="token plain"> create_date</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">FROM</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  dwm</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">dwm_business_order_count</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> o</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>The Flink UI reflects the following: Data from <code>dws_business_order_count_op</code> is written to <code>dws_business_order_count_op</code>:</p><p><img loading="lazy" src="/assets/images/dws_business_order_count_op-72bb62943dcef89451b47db142cfe689.png" width="191" height="630" class="img_ev3q"></p><p>Overall Data Flow Example</p><p><img loading="lazy" src="/assets/images/all_datastream-f095c45ce30fe21e178eac323c6a7a37.jpg" width="1080" height="515" class="img_ev3q"></p><p>Source Table:</p><p><img loading="lazy" src="/assets/images/source-afa30e0d3ab0116582cc4bd7831ce2ca.png" width="1080" height="100" class="img_ev3q"></p><p>paimon-ods:</p><p><img loading="lazy" src="/assets/images/paimon-ods-876cf67ff375c0b5cb67d4a0e555b1a3.png" width="1080" height="94" class="img_ev3q"></p><p>paimon-dwd:</p><p><img loading="lazy" src="/assets/images/paimon-dwd-d3b020d2bd2b78c26944a6928be39e4e.png" width="1080" height="95" class="img_ev3q"></p><p>paimon-dwm:</p><p><img loading="lazy" src="/assets/images/paimon-dwm-778a748d6b64c9e61d73e6b6da1d625f.png" width="1080" height="39" class="img_ev3q"></p><p>paimon-dws:</p><p><img loading="lazy" src="/assets/images/paimon-dws-632e1291e21c4f628f7e87ca03ae5c6f.png" width="1080" height="56" class="img_ev3q"></p><p>A special reminder: When extracting from SQL Server databases, if the source table is too large, a full extraction will lock the table. It is recommended to use incremental extraction if the business allows. For a full extraction, SQL Server can use an interim approach where the full data is imported into MySQL, then from MySQL to Paimon-ODS, and later incremental extraction is done through SQL Server.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="04-troubleshooting-and-analysis">04 Troubleshooting and Analysis<a href="#04-troubleshooting-and-analysis" class="hash-link" aria-label="Direct link to 04 Troubleshooting and Analysis" title="Direct link to 04 Troubleshooting and Analysis">​</a></h2><p><strong>1. Inaccurate Aggregated Data Calculation</strong></p><p>SQL Server CDC collects data into the Paimon table, explanation:</p><p><strong>DWD table:</strong></p><p>'changelog-producer' = 'input'</p><p><strong>ADS table:</strong></p><p>'merge-engine' = 'aggregation', -- Using aggregation to compute sum</p><p>'fields.sum_amount.aggregate-function' = 'sum'</p><p>The ADS layer's aggregated table uses agg sum, which can result in the DWD data stream not generating update_before, creating an incorrect data stream with update_after. For example, if the upstream source table updates from 10 to 30, the DWD layer's data will change to 30, and the ADS aggregation layer's data will also change to 30. But now it turns into an append data, resulting in incorrect data of 10+30=40.</p><p>Solution:</p><p>By specifying 'changelog-producer' = 'full-compaction',
Table Store will compare the results between full compactions and produce the differences as changelog.
The latency of changelog is affected by the frequency of full compactions.</p><p>By specifying changelog-producer.compaction-interval table property (default value 30min),
users can define the maximum interval between two full compactions to ensure latency.
This table property does not affect normal compactions and they may still be performed once in a while by writers to reduce reader costs.</p><p>This approach can solve the above mentioned issue. However, it has led to a new problem. The default changelog-producer.compaction-interval is 30 minutes, meaning that it takes 30 minutes for changes upstream to be reflected in the ads query. During production, it has been found that changing the compaction interval to 1 minute or 2 minutes can cause inaccuracies in the ADS layer aggregation data again.</p><div class="language-sql codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sql codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token string" style="color:rgb(255, 121, 198)">'changelog-producer.compaction-interval'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'2m'</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>When writing into the Flink Table Store, it is necessary to configure table.exec.sink.upsert-materialize= none to avoid generating an upsert stream, ensuring that the Flink Table Store can retain a complete changelog for subsequent stream read operations.</p><div class="language-sql codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sql codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">set</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'table.exec.sink.upsert-materialize'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'none'</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><strong>2. The same sequence.field causes the dwd detailed wide table to not receive data updates</strong></p><p><strong>mysql cdc collects data into the paimon table</strong></p><p>Explanation:</p><p>After executing an update on the MySQL source, the data modifications are successfully synchronized to the dwd_orders table.</p><p><img loading="lazy" src="/assets/images/dwd_orders-8343ec8277c69354f8ee7cac0c4c9f91.png" width="1080" height="558" class="img_ev3q"></p><p>However, upon examining the dwd_enriched_orders table data, it is found to be unsynchronized. When starting the stream mode to observe the data, it is discovered that there is no data flow.</p><p><img loading="lazy" src="/assets/images/log-42ef92b8036ed3698fb0fbb1abdaecab.png" width="1080" height="357" class="img_ev3q"></p><p><strong>Solution:</strong></p><p>Upon investigation, it was discovered that the issue was caused by the configuration of the parameter 'sequence.field' = 'o_orderdate' (using o_orderdate to generate a sequence ID, and when merging records with the same primary key, the record with the larger sequence ID is chosen). Since the o_orderdate field does not change when modifying the price, the 'sequence.field' remains the same, leading to an uncertain order. Therefore, for ROW1 and ROW2, since their o_orderdate are the same, the update will randomly select between them. By removing this parameter, the system will normally generate a sequence number based on the input order, which will not affect the synchronization result.</p><p><strong>3. Aggregate function 'last_non_null_value' does not support retraction</strong></p><p>Error:
Caused by: java.lang.UnsupportedOperationException: Aggregate function 'last_non_null_value' does not support retraction, If you allow this function to ignore retraction messages, you can configure 'fields.${field_name}.ignore-retract'='true'.</p><p>An explanation can be found in the official documentation:</p><p>Only sum supports retraction (UPDATE_BEFORE and DELETE), other aggregate functions do not support retraction.</p><p>This can be understood as: except for the SUM function, other Agg functions do not support Retraction. To avoid errors when receiving DELETE and UPDATEBEFORE messages, it is necessary to configure 'fields.${field_name}.ignore-retract'='true' for the specified field to ignore retraction and solve this error.</p><div class="language-sql codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sql codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">WITH</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'merge-engine'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'aggregation'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token comment" style="color:rgb(98, 114, 164)">-- Use aggregation to compute sum</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'fields.sum_orderCount.aggregate-function'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'sum'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'fields.create_date.ignore-retract'</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">'true'</span><span class="token plain"> </span><span class="token comment" style="color:rgb(98, 114, 164)">#field create_date</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><strong>4. Paimon Task Interruption Failure</strong></p><p>Task abnormal interruption leads to pod crash, viewing loki logs shows akka.pattern.AskTimeoutException: Ask timed out on</p><p><img loading="lazy" src="/assets/images/loki-372203296a8af19f7a32fcd2162fdc29.png" width="1080" height="288" class="img_ev3q"></p><p>java.util.concurrent.TimeoutException: Invocation of <!-- -->[RemoteRpcInvocation(JobMasterGateway.updateTaskExecutionState(TaskExecutionState))]<!-- --> at recipient <!-- -->[akka.tcp://flink@fts-business-order-count.streampark:6123/user/rpc/jobmanager_2]<!-- --> timed out. This is usually caused by: 1) Akka failed sending the message silently, due to problems like oversized payload or serialization failures. In that case, you should find detailed error information in the logs. 2) The recipient needs more time for responding, due to problems like slow machines or network jitters. In that case, you can try to increase akka.ask.timeout.\n"</p><p>The preliminary judgment is that the triggering of akka's timeout mechanism is likely due to the above two reasons. Therefore, adjust the cluster's akka timeout settings and carry out individual task segmentation or increase resource configuration.</p><p>To proceed, let's first see how to modify the parameters:</p><table><thead><tr><th>key</th><th>default</th><th>describe</th></tr></thead><tbody><tr><td>akka.ask.timeout</td><td>10s</td><td>Timeout used for all futures and blocking Akka calls. If Flink fails due to timeouts then you should try to increase this value. Timeouts can be caused by slow machines or a congested network. The timeout value requires a time-unit specifier (ms/s/min/h/d).</td></tr><tr><td>web.timeout</td><td>600000</td><td>Timeout for asynchronous operations by the web monitor in milliseconds.</td></tr></tbody></table><p>In <code>conf/flink-conf.yaml</code>, add the following parameters at the end:</p><p><strong>akka.ask.timeout: 100s</strong></p><p><strong>web.timeout:1000000</strong></p><p>Then manually refresh the <code>flink-conf.yaml</code> in Streampark to verify if the parameters have synchronized successfully.</p><p><strong>5. snapshot no such file or directory</strong></p><p>It was discovered that <code>cp</code> (checkpoint) is failing.</p><p>[Image showing failure of cp]</p><p>Corresponding logs at the time show Snapshot missing, with the task status shown as running, but data from the MySQL source table cannot be written into the paimon ods table.</p><p>[Image showing status log]</p><p>The reason for cp failure is identified as: due to high computation and CPU intensity, threads within the TaskManager are constantly processing elements, without having time to perform the checkpoint.</p><p>The reason for being unable to read the Snapshot is: insufficient resources in the Flink cluster, leading to competition between Writer and Committer. During Full-Compaction, an incomplete Snapshot of an expired part was read. The official response to this issue has been fixed:</p><p><a href="https://github.com/apache/incubator-paimon/pull/1308" target="_blank" rel="noopener noreferrer">https://github.com/apache/incubator-paimon/pull/1308</a></p><p>And the solution to the checkpoint failure is to increase parallelism, by adding more deployment taskmanager slots and enhancing the jobmanager CPU resources.</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">-D kubernetes.jobmanager.cpu=0.8</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">-D kubernetes.jobmanager.cpu.limit-factor=1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">-D taskmanager.numberOfTaskSlots=8</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">-D jobmanager.adaptive-batch-scheduler.default-source-parallelism=2</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><img loading="lazy" src="/assets/images/dynamic_properties-33cd67364d80285f0e480974a60d52ff.jpg" width="1080" height="244" class="img_ev3q"></p><p><img loading="lazy" src="/assets/images/flink_dashboard-4bcca1ae4f103249bd7c6c48625a4959.png" width="1080" height="487" class="img_ev3q"></p><p>In complex real-time tasks, resources can be increased by modifying dynamic parameters.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="05-future-planning">05 Future Planning<a href="#05-future-planning" class="hash-link" aria-label="Direct link to 05 Future Planning" title="Direct link to 05 Future Planning">​</a></h2><ul><li>Our self-built data platform, Bondata, is integrating Paimon's metadata information, data metric system, lineage, and one-click pipeline features. This integration aims to form HCBondata's data assets and will serve as the foundation for a one-stop data governance initiative.</li><li>Subsequently, we will integrate with Trino Catalog to access Doris, realizing a one-service solution for both offline and real-time data.</li><li>We will continue to advance the pace of building an integrated streaming and batch data warehouse within the group, adopting the architecture of Doris + Paimon.</li></ul><p>Here, I would like to thank Teacher Zhixin and the StreamPark community for their strong support during the use of StreamPark + Paimon. The problems encountered in the learning process are promptly clarified and resolved. We will also actively participate in community exchanges and contributions in the future, enabling Paimon to provide more developers and enterprises with integrated stream and batch data lake solutions.</p>]]></content>
        <category label="StreamPark" term="StreamPark"/>
        <category label="Production Practice" term="Production Practice"/>
        <category label="paimon" term="paimon"/>
        <category label="streaming-warehouse" term="streaming-warehouse"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[StreamPark in the Large-Scale Production Practice at Shunwang Technology]]></title>
        <id>https://streampark.apache.org/blog/streampark-usercase-shunwang</id>
        <link href="https://streampark.apache.org/blog/streampark-usercase-shunwang"/>
        <updated>2024-01-21T04:16:34.000Z</updated>
        <summary type="html"><![CDATA[Preface: This article primarily discusses the challenges encountered by Shunwang Technology in using the Flink computation engine, and how StreamPark is leveraged as a real-time data platform to address these challenges, thus supporting the company's business on a large scale.]]></summary>
        <content type="html"><![CDATA[<p><img loading="lazy" src="/assets/images/autor-4fee09aa3abf8842dcdbb7ada1aa9409.png" width="1080" height="460" class="img_ev3q"></p><p><strong>Preface:</strong> This article primarily discusses the challenges encountered by Shunwang Technology in using the Flink computation engine, and how StreamPark is leveraged as a real-time data platform to address these challenges, thus supporting the company's business on a large scale.</p><ul><li>Introduction to the company's business</li><li>Challenges encountered</li><li>Why choose StreamPark</li><li>Implementation in practice</li><li>Benefits Brought</li><li>Future planning</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="introduction-to-the-companys-business"><strong>Introduction to the Company's Business</strong><a href="#introduction-to-the-companys-business" class="hash-link" aria-label="Direct link to introduction-to-the-companys-business" title="Direct link to introduction-to-the-companys-business">​</a></h2><p>Hangzhou Shunwang Technology Co., Ltd. was established in 2005. Upholding the corporate mission of connecting happiness through technology, it is one of the influential pan-entertainment technology service platforms in China. Over the years, the company has always been driven by products and technology, dedicated to creating immersive entertainment experiences across all scenes through digital platform services.</p><p>Since its inception, Shunwang Technology has experienced rapid business growth, serving 80,000 offline physical stores, owning more than 50 million internet users, reaching over 140 million netizens annually, with 7 out of every 10 public internet service venues using Shunwang Technology's products.</p><p>With a vast user base, Shunwang Technology has been committed to providing a superior product experience and achieving digital transformation of the enterprise. Since 2015, it has vigorously developed big data capabilities, with Flink playing a crucial role in Shunwang Technology’s real-time computing. At Shunwang Technology, real-time computing is roughly divided into four application scenarios:</p><ul><li>Real-time update of user profiles: This includes internet cafe profiles and netizen profiles.</li><li>Real-time risk control: This includes activity anti-brushing, monitoring of logins from different locations, etc.</li><li>Data synchronization: This includes data synchronization from Kafka to Hive / Iceberg / ClickHouse, etc.</li><li>Real-time data analysis: This includes real-time big screens for games, voice, advertising, live broadcasts, and other businesses.</li></ul><p>To date, Shunwang Technology has to process TB-level data daily, with a total of more than 700 real-time tasks, of which FlinkSQL tasks account for over 95%. With the rapid development of the company's business and the increased demand for data timeliness, it is expected that the number of Flink tasks will reach 900+ by the end of this year.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="challenges-encountered"><strong>Challenges Encountered</strong><a href="#challenges-encountered" class="hash-link" aria-label="Direct link to challenges-encountered" title="Direct link to challenges-encountered">​</a></h2><p>Flink, as one of the most popular real-time computing frameworks currently, boasts powerful features such as high throughput, low latency, and stateful computations. However, in our exploration, we found that while Flink has strong computational capabilities, the community has not provided effective solutions for job development management and operational issues. We have roughly summarized some of the pain points we encountered in Flink job development management into four aspects, as follows:</p><p><img loading="lazy" alt="Image" src="/assets/images/pain-4d2aee42ea7aae80eaeac17a6d51c090.png" width="1080" height="744" class="img_ev3q"></p><p>Facing a series of pain points in the management and operation of Flink jobs, we have been looking for suitable solutions to lower the barrier to entry for our developers using Flink and improve work efficiency.</p><p>Before we encountered StreamPark, we researched some companies' Flink management solutions and found that they all developed and managed Flink jobs through self-developed real-time job platforms. Consequently, we decided to develop our own real-time computing management platform to meet the basic needs of our developers for Flink job management and operation. Our platform is called Streaming-Launcher, with the following main functions:</p><p><img loading="lazy" alt="Image" src="/assets/images/launcher-766611cb0dddb99d8437ead44d0665d4.png" width="1080" height="670" class="img_ev3q"></p><p>However, as our developers continued to use Streaming-Launcher, they discovered quite a few deficiencies: the development cost for Flink remained too high, work efficiency was poor, and troubleshooting was difficult. We summarized the defects of Streaming-Launcher as follows:</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="cumbersome-sql-development-process"><strong>Cumbersome SQL Development Process</strong><a href="#cumbersome-sql-development-process" class="hash-link" aria-label="Direct link to cumbersome-sql-development-process" title="Direct link to cumbersome-sql-development-process">​</a></h3><p>Business developers need multiple tools to complete the development of a single SQL job, increasing the barrier to entry for our developers.</p><p><img loading="lazy" alt="cc0b1414ed43942e0ef5e9129c2bf817" src="/assets/images/sql_develop-ef85f6a001fb814d494c9b39eb2dfba9.png" width="1080" height="229" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="drawbacks-of-sql-client"><strong>Drawbacks of SQL-Client</strong><a href="#drawbacks-of-sql-client" class="hash-link" aria-label="Direct link to drawbacks-of-sql-client" title="Direct link to drawbacks-of-sql-client">​</a></h3><p>The SQL-Client provided by Flink currently has certain drawbacks regarding the support for job execution modes.</p><p><img loading="lazy" alt="Image" src="/assets/images/sql_client-32fd9eb063198e6f35349187eed61546.png" width="1080" height="721" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="lack-of-unified-job-management"><strong>Lack of Unified Job Management</strong><a href="#lack-of-unified-job-management" class="hash-link" aria-label="Direct link to lack-of-unified-job-management" title="Direct link to lack-of-unified-job-management">​</a></h3><p>Within Streaming-Launcher, there is no provision of a unified job management interface. Developers cannot intuitively see the job running status and can only judge the job situation through alarm information, which is very unfriendly to developers. If a large number of tasks fail at once due to Yarn cluster stability problems or network fluctuations and other uncertain factors, it is easy for developers to miss restoring a certain task while manually recovering jobs, which can lead to production accidents.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="cumbersome-problem-diagnosis-process"><strong>Cumbersome Problem Diagnosis Process</strong><a href="#cumbersome-problem-diagnosis-process" class="hash-link" aria-label="Direct link to cumbersome-problem-diagnosis-process" title="Direct link to cumbersome-problem-diagnosis-process">​</a></h3><p>To view logs for a job, developers must go through multiple steps, which to some extent reduces their work efficiency.</p><p><img loading="lazy" alt="Image" src="/assets/images/step-d945592bbe32c0e093289c6265472f1c.png" width="1080" height="122" class="img_ev3q"></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="why-use-streampark"><strong>Why Use StreamPark</strong><a href="#why-use-streampark" class="hash-link" aria-label="Direct link to why-use-streampark" title="Direct link to why-use-streampark">​</a></h2><p>Faced with the defects of our self-developed platform Streaming-Launcher, we have been considering how to further lower the barriers to using Flink and improve work efficiency. Considering the cost of human resources and time, we decided to seek help from the open-source community and look for an appropriate open-source project to manage and maintain our Flink tasks.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="01--streampark-a-powerful-tool-for-solving-flink-issues">01  <strong>StreamPark: A Powerful Tool for Solving Flink Issues</strong><a href="#01--streampark-a-powerful-tool-for-solving-flink-issues" class="hash-link" aria-label="Direct link to 01--streampark-a-powerful-tool-for-solving-flink-issues" title="Direct link to 01--streampark-a-powerful-tool-for-solving-flink-issues">​</a></h3><p>Fortunately, in early June 2022, we stumbled upon StreamPark on GitHub and embarked on a preliminary exploration full of hope. We found that StreamPark's capabilities can be broadly divided into three areas: user permission management, job operation and maintenance management, and development scaffolding.</p><p><strong>User Permission Management</strong></p><p>In the StreamPark platform, to avoid the risk of users having too much authority and making unnecessary misoperations that affect job stability and the accuracy of environmental configurations, some user permission management functions are provided. This is very necessary for enterprise-level users.</p><p><img loading="lazy" alt="Image" src="/assets/images/permission-affd274acd10773ad4531da9102f3f91.png" width="1080" height="721" class="img_ev3q"></p><p><strong>Job Operation and Maintenance Management</strong></p><p><strong>Our main focus during the research on StreamPark was its capability to manage the entire lifecycle of jobs:</strong> from development and deployment to management and problem diagnosis. <strong>Fortunately, StreamPark excels in this aspect, relieving developers from the pain points associated with Flink job management and operation.</strong> Within StreamPark’s job operation and maintenance management, there are three main modules: basic job management functions, Jar job management, and FlinkSQL job management as shown below:</p><p><img loading="lazy" alt="Image" src="/assets/images/homework_manager-96dc37860dd87f12ed55311b38116931.png" width="1080" height="542" class="img_ev3q"></p><p><strong>Development Scaffolding</strong></p><p>Further research revealed that StreamPark is not just a platform but also includes a development scaffold for Flink jobs. It offers a better solution for code-written Flink jobs, standardizing program configuration, providing a simplified programming model, and a suite of Connectors that lower the barrier to entry for DataStream development.</p><p><img loading="lazy" alt="Image" src="/assets/images/connectors-d405c391d0cfdd753e7b329433275117.png" width="1080" height="720" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="02--how-streampark-addresses-issues-of-the-self-developed-platform">02  <strong>How StreamPark Addresses Issues of the Self-Developed Platform</strong><a href="#02--how-streampark-addresses-issues-of-the-self-developed-platform" class="hash-link" aria-label="Direct link to 02--how-streampark-addresses-issues-of-the-self-developed-platform" title="Direct link to 02--how-streampark-addresses-issues-of-the-self-developed-platform">​</a></h3><p>We briefly introduced the core capabilities of StreamPark above. During the technology selection process at Shunwang Technology, we found that StreamPark not only includes the basic functions of our existing Streaming-Launcher but also offers a more complete set of solutions to address its many shortcomings. Here, we focus on the solutions provided by StreamPark for the deficiencies of our self-developed platform, Streaming-Launcher.</p><p><img loading="lazy" alt="Image" src="/assets/images/function-c2d3ad419e1676a0253d933935921a71.png" width="1080" height="720" class="img_ev3q"></p><p><strong>One-Stop Flink Job Development Capability</strong></p><p>To lower the barriers to Flink job development and improve developers' work efficiency, <strong>StreamPark provides features like FlinkSQL IDE, parameter management, task management, code management, one-click compilation, and one-click job deployment and undeployment</strong>. Our research found that these integrated features of StreamPark could further enhance developers’ work efficiency. To some extent, developers no longer need to concern themselves with the difficulties of Flink job management and operation and can focus on developing the business logic. These features also solve the pain point of cumbersome SQL development processes in Streaming-Launcher.</p><p><img loading="lazy" alt="Image" src="/assets/images/application-c99d4b0512fdb7d214e5429769629930.png" width="1080" height="959" class="img_ev3q"></p><p><strong>Support for Multiple Deployment Modes</strong></p><p>The Streaming-Launcher was not flexible for developers since it only supported the Yarn Session mode. StreamPark provides a comprehensive solution for this aspect. <strong>StreamPark fully supports all of Flink's deployment modes: Remote, Yarn Per-Job, Yarn Application, Yarn Session, K8s Session, and K8s Application,</strong> allowing developers to freely choose the appropriate running mode for different business scenarios.</p><p><strong>Unified Job Management Center</strong></p><p>For developers, job running status is one of their primary concerns. In Streaming-Launcher, due to the lack of a unified job management interface, developers had to rely on alarm information and Yarn application status to judge the state of tasks, which was very unfriendly. StreamPark addresses this issue by providing a unified job management interface, allowing for a clear view of the running status of each task.</p><p><img loading="lazy" alt="Image" src="/assets/images/management-9eb1dec5b2fa480e897cf1c12d1425d8.png" width="1080" height="572" class="img_ev3q"></p><p>In the Streaming-Launcher, developers had to go through multiple steps to diagnose job issues and locate job runtime logs. StreamPark offers a one-click jump feature that allows quick access to job runtime logs.</p><p><img loading="lazy" alt="Image" src="/assets/images/logs-e4e9f2084f1fbcf0a4afe079433cef0a.png" width="1080" height="575" class="img_ev3q"></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="practical-implementation">Practical Implementation<a href="#practical-implementation" class="hash-link" aria-label="Direct link to Practical Implementation" title="Direct link to Practical Implementation">​</a></h2><p>When introducing StreamPark to Shunwang Technology, due to the company's business characteristics and some customized requirements from the developers, we made some additions and optimizations to the functionalities of StreamPark. We have also summarized some problems encountered during the use and corresponding solutions.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="01--leveraging-the-capabilities-of-flink-sql-gateway">01  <strong>Leveraging the Capabilities of Flink-SQL-Gateway</strong><a href="#01--leveraging-the-capabilities-of-flink-sql-gateway" class="hash-link" aria-label="Direct link to 01--leveraging-the-capabilities-of-flink-sql-gateway" title="Direct link to 01--leveraging-the-capabilities-of-flink-sql-gateway">​</a></h3><p>At Shunwang Technology, we have developed the ODPS platform based on the Flink-SQL-Gateway to facilitate business developers in managing the metadata of Flink tables. Business developers perform DDL operations on Flink tables in ODPS, and then carry out analysis and query operations on the created Flink tables in StreamPark. Throughout the entire business development process, we have decoupled the creation and analysis of Flink tables, making the development process appear more straightforward.</p><p>If developers wish to query real-time data in ODPS, we need to provide a Flink SQL runtime environment. We have used StreamPark to run a Yarn Session Flink environment to support ODPS in conducting real-time queries.</p><p><img loading="lazy" alt="Image" src="/assets/images/homework-96030dec4ea9db88b42668873f5a176d.png" width="1080" height="541" class="img_ev3q"></p><p>Currently, the StreamPark community is intergrating with Flink-SQL-Gateway to further lower the barriers to developing real-time jobs.</p><p><a href="https://github.com/apache/streampark/issues/2274" target="_blank" rel="noopener noreferrer">https://github.com/apache/streampark/issues/2274</a></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="02--enhancing-flink-cluster-management-capabilities">02  <strong>Enhancing Flink Cluster Management Capabilities</strong><a href="#02--enhancing-flink-cluster-management-capabilities" class="hash-link" aria-label="Direct link to 02--enhancing-flink-cluster-management-capabilities" title="Direct link to 02--enhancing-flink-cluster-management-capabilities">​</a></h3><p>At Shunwang Technology, there are numerous jobs synchronizing data from Kafka to Iceberg / PG / Clickhouse / Hive. These jobs do not have high resource requirements and timeliness demands on Yarn. However, if Yarn Application and per-job modes are used for all tasks, where each task starts a JobManager, this would result in a waste of Yarn resources. For this reason, we decided to run these numerous data synchronization jobs in Yarn Session mode.</p><p>In practice, we found it difficult for business developers to intuitively know how many jobs are running in each Yarn Session, including the total number of jobs and the number of jobs that are running. Based on this, to facilitate developers to intuitively observe the number of jobs in a Yarn Session, we added All Jobs and Running Jobs in the Flink Cluster interface to indicate the total number of jobs and the number of running jobs in a Yarn Session.</p><p><img loading="lazy" alt="Image" src="/assets/images/cluster-96bd791c1c4f3d6144fbd1d134d89cd6.png" width="1080" height="543" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="03--enhancing-alert-capabilities">03  <strong>Enhancing Alert Capabilities</strong><a href="#03--enhancing-alert-capabilities" class="hash-link" aria-label="Direct link to 03--enhancing-alert-capabilities" title="Direct link to 03--enhancing-alert-capabilities">​</a></h3><p>Since each company's SMS alert platform is implemented differently, the StreamPark community has not abstracted a unified SMS alert function. Here, we have implemented the SMS alert function through the Webhook method.</p><p><img loading="lazy" alt="Image" src="/assets/images/alarm-8fa330c6a2d27cfd62878dcd20cd524c.png" width="1080" height="601" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="04--adding-a-blocking-queue-to-solve-throttling-issues">04  <strong>Adding a Blocking Queue to Solve Throttling Issues</strong><a href="#04--adding-a-blocking-queue-to-solve-throttling-issues" class="hash-link" aria-label="Direct link to 04--adding-a-blocking-queue-to-solve-throttling-issues" title="Direct link to 04--adding-a-blocking-queue-to-solve-throttling-issues">​</a></h3><p>In production practice, we found that when a large number of tasks fail at the same time, such as when a Yarn Session cluster goes down, platforms like Feishu/Lark and WeChat have throttling issues when multiple threads call the alert interface simultaneously. Consequently, only a portion of the alert messages will be sent by StreamPark due to the throttling issues of platforms like Feishu/Lark and WeChat, which can easily mislead developers in troubleshooting. At Shunwang Technology, we added a blocking queue and an alert thread to solve the throttling issue.</p><p><img loading="lazy" alt="Image" src="/assets/images/queue-83552f1862acff8811b74488e8fe7c05.png" width="1080" height="320" class="img_ev3q"></p><p>When the job monitoring scheduler detects an abnormality in a job, it generates a job exception message and sends it to the blocking queue. The alert thread will continuously consume messages from the blocking queue. Upon receiving a job exception message, it will send the alert to different platforms sequentially according to the user-configured alert information. Although this method might delay the alert delivery to users, in practice, we found that even with 100+ Flink jobs failing simultaneously, the delay in receiving alerts is less than 3 seconds. Such a delay is completely acceptable to our business development colleagues. This improvement has been recorded as an ISSUE and is currently under consideration for contribution to the community.</p><p><a href="https://github.com/apache/streampark/issues/2142" target="_blank" rel="noopener noreferrer">https://github.com/apache/streampark/issues/2142</a></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="benefits-brought">Benefits Brought<a href="#benefits-brought" class="hash-link" aria-label="Direct link to Benefits Brought" title="Direct link to Benefits Brought">​</a></h2><p>We started exploring and using StreamX 1.2.3 (the predecessor of StreamPark) and after more than a year of running in, we found that StreamPark truly resolves many pain points in the development management and operation and maintenance of Flink jobs.</p><p>The greatest benefit that StreamPark has brought to Shunwang Technology is the lowered threshold for using Flink and improved development efficiency. Previously, our business development colleagues had to use multiple tools such as vscode, GitLab, and a scheduling platform in the original Streaming-Launcher to complete a FlinkSQL job development. The process was tedious, going through multiple tools from development to compilation to release. StreamPark provides one-stop service, allowing job development, compilation, and release to be completed on StreamPark, simplifying the entire development process.</p><p><strong>At present, StreamPark has been massively deployed in the production environment at Shunwang Technology, with the number of FlinkSQL jobs managed by StreamPark increasing from the initial 500+ to nearly 700, while also managing more than 10 Yarn Session Clusters.</strong></p><p><img loading="lazy" alt="Image" src="/assets/images/achievements1-9eb1dec5b2fa480e897cf1c12d1425d8.png" width="1080" height="572" class="img_ev3q"></p><p><img loading="lazy" alt="Image" src="/assets/images/achievements2-5aa9b3c14892f9b1d8b054e82f3b4ad3.png" width="1080" height="545" class="img_ev3q"></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="future-plans">Future Plans<a href="#future-plans" class="hash-link" aria-label="Direct link to Future Plans" title="Direct link to Future Plans">​</a></h2><p>As one of the early users of StreamPark, Shunwang Technology has been communicating with the community for a year and participating in the polishing of StreamPark's stability. We have submitted the Bugs encountered in production operations and new Features to the community. In the future, we hope to manage the metadata information of Flink tables on StreamPark, and implement cross-data-source query analysis functions based on the Flink engine through multiple Catalogs. Currently, StreamPark is integrating with Flink-SQL-Gateway capabilities, which will greatly help in the management of table metadata and cross-data-source query functions in the future.</p><p>Since Shunwang Technology primarily runs jobs in Yarn Session mode, we hope that StreamPark can provide more support for Remote clusters, Yarn Session clusters, and K8s Session clusters, such as monitoring and alerts, and optimizing operational processes.</p><p>Considering the future, as the business develops, we may use StreamPark to manage more Flink real-time jobs, and StreamPark in single-node mode may not be safe. Therefore, we are also looking forward to the High Availability (HA) of StreamPark.</p><p>We will also participate in the construction of the capabilities of StreamPark is integrating with Flink-SQL-Gateway, enriching Flink Cluster functionality, and StreamPark HA.</p>]]></content>
        <category label="StreamPark" term="StreamPark"/>
        <category label="Production Practice" term="Production Practice"/>
        <category label="FlinkSQL" term="FlinkSQL"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[StreamPark's Best Practices at Dustess, Simplifying Complexity for the Ultimate Experience]]></title>
        <id>https://streampark.apache.org/blog/streampark-usercase-dustess</id>
        <link href="https://streampark.apache.org/blog/streampark-usercase-dustess"/>
        <updated>2024-01-21T04:16:34.000Z</updated>
        <summary type="html"><![CDATA[Abstract]]></summary>
        <content type="html"><![CDATA[<p><strong>Abstract:</strong> This article originates from the production practices of StreamPark at Dustess Information, written by the senior data development engineer, Gump. The main content includes:</p><ol><li>Technology selection</li><li>Practical implementation</li><li>Business support &amp; capability opening</li><li>Future planning</li><li>Closing remarks</li></ol><p>Dustess Information is a one-stop private domain operation management solution provider based on the WeChat Work ecosystem. It is committed to becoming the leading expert in private domain operation and management across all industries, helping enterprises build a new model of private domain operation management in the digital age, and promoting high-quality development for businesses.</p><p>Currently, Dustess has established 13 city centers nationwide, covering five major regions: North China, Central China, East China, South China, and Southwest China, providing digital marketing services to over 10,000 enterprises across more than 30 industries.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="01-technology-selection"><strong>01 Technology Selection</strong><a href="#01-technology-selection" class="hash-link" aria-label="Direct link to 01-technology-selection" title="Direct link to 01-technology-selection">​</a></h2><p>Dustess Information entered a rapid development phase in 2021. With the increase in service industries and corporate clients, the demand for real-time solutions became more pressing, necessitating the immediate implementation of a real-time computing platform.</p><p>As the company is in a phase of rapid growth, with urgent and rapidly changing needs, the team's technology selection followed these principles:</p><ul><li><strong>Speed:</strong> Due to urgent business needs, we required a quick implementation of the planned technology selection into production.</li><li><strong>Stability:</strong> On the basis of speed, the chosen technology must provide stable service for the business.</li><li><strong>Innovation:</strong> On the basis of the above, the selected technology should also be as modern as possible.</li><li><strong>Comprehensiveness:</strong> The selected technology should meet the company's rapidly developing and changing business needs, be in line with the team's long-term development goals, and support quick and efficient secondary development.</li></ul><p>Firstly, in terms of the computing engine: We chose Flink for the following reasons:</p><ul><li>Team members have an in-depth understanding of Flink and are well-versed in its source code.</li><li>Flink supports both batch and stream processing. Although the company's current batch processing architecture is based on Hive, Spark, etc., using Flink for stream computing facilitates the subsequent construction of unified batch and stream processing and lake-house architecture.</li><li>The domestic ecosystem of Flink has become increasingly mature, and Flink is starting to break boundaries towards the development of stream-based data warehousing.</li></ul><p>At the platform level, we comprehensively compared StreamPark, Apache Zeppelin, and flink-streaming-platform-web, also thoroughly read their source code and conducted an analysis of their advantages and disadvantages. We won’t elaborate on the latter two projects in this article, but those interested can search for them on GitHub. We ultimately chose StreamPark for the following reasons:</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="high-completion"><strong>High Completion</strong><a href="#high-completion" class="hash-link" aria-label="Direct link to high-completion" title="Direct link to high-completion">​</a></h3><h4 class="anchor anchorWithStickyNavbar_LWe7" id="1-supports-multiple-flink-versions"><strong>1. Supports Multiple Flink Versions</strong><a href="#1-supports-multiple-flink-versions" class="hash-link" aria-label="Direct link to 1-supports-multiple-flink-versions" title="Direct link to 1-supports-multiple-flink-versions">​</a></h4><p>//Video link (Flink Multi-Version Support Demo)</p><p>When creating a task, you can <strong>freely choose the Flink version</strong>. The Flink binary package will be automatically uploaded to HDFS (if using Yarn for submission), and only one copy of a version's binary package will be saved on HDFS. When the task is initiated, the Flink binary package in HDFS will be automatically loaded according to the context, which is very elegant. This can meet the needs for coexistence of multiple versions and for testing new versions of Flink during upgrades.</p><p><img loading="lazy" src="/assets/images/flink_home-0a6f4f2014cc87b074ef259088af2b98.png" width="1080" height="223" class="img_ev3q"></p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="2-supports-multiple-deployment-modes"><strong>2. Supports Multiple Deployment Modes</strong><a href="#2-supports-multiple-deployment-modes" class="hash-link" aria-label="Direct link to 2-supports-multiple-deployment-modes" title="Direct link to 2-supports-multiple-deployment-modes">​</a></h4><p>StreamPark supports <strong>all the mainstream submission modes</strong> for Flink, such as standalone, yarn-session, yarn application, yarn-perjob, kubernetes-session, kubernetes-application. Moreover, StreamPark does not simply piece together Flink run commands to submit tasks. Instead, it introduces the Flink Client source package and directly calls the Flink Client API for task submission. The advantages of this approach include modular code, readability, ease of extension, stability, and the ability to quickly adapt to upgrades of the Flink version.</p><p><img loading="lazy" src="/assets/images/execution_mode-1182aeb8efe9572ec98c2a2b95293dc1.png" width="1080" height="324" class="img_ev3q"></p><p>Flink SQL can greatly improve development efficiency and the popularity of Flink. StreamPark’s support for <strong>Flink SQL is very comprehensive</strong>, with an excellent SQL editor, dependency management, multi-version task management, etc. The StreamPark official website states that it will introduce metadata management integration for Flink SQL in the future. Stay tuned.</p><p><img loading="lazy" src="/assets/images/flink_sql-13f6952f92585140c5fc640b490918b0.png" width="1080" height="779" class="img_ev3q"></p><p><img loading="lazy" src="/assets/images/flink_sql_version-a02b0f0eac9c5d6c0281b7471e438b78.png" width="1080" height="736" class="img_ev3q"></p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="4-online-building-of-java-tasks"><strong>4. Online Building of JAVA Tasks</strong><a href="#4-online-building-of-java-tasks" class="hash-link" aria-label="Direct link to 4-online-building-of-java-tasks" title="Direct link to 4-online-building-of-java-tasks">​</a></h4><p>//Video link (JAVA Task Building Demo)</p><p>Although Flink SQL is now powerful enough, using JVM languages like Java and Scala to develop Flink tasks can be more flexible, more customizable, and better for tuning and improving resource utilization. The biggest problem with submitting tasks via Jar packages, compared to SQL, is the management of the Jar uploads. Without excellent tooling products, this can significantly reduce development efficiency and increase maintenance costs.</p><p>Besides supporting Jar uploads, StreamPark also provides an <strong>online update build</strong> feature, which elegantly solves the above problems:</p><ol><li><p>Create Project: Fill in the GitHub/Gitlab (supports enterprise private servers) address and username/password, and StreamPark can Pull and Build the project.</p></li><li><p>When creating a StreamPark Custom-Code task, refer to the Project, specify the main class, and optionally automate Pull, Build, and bind the generated Jar when starting the task, which is very elegant!</p></li></ol><p>At the same time, the StreamPark community is also perfecting the entire task compilation and launch process. The future StreamPark will be even more refined and professional on this foundation.</p><p><img loading="lazy" src="/assets/images/system_list-6e9c13318d5aa2cfa4cdc11ac42c5844.png" width="1080" height="362" class="img_ev3q"></p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="5-comprehensive-task-parameter-configuration"><strong>5. Comprehensive Task Parameter Configuration</strong><a href="#5-comprehensive-task-parameter-configuration" class="hash-link" aria-label="Direct link to 5-comprehensive-task-parameter-configuration" title="Direct link to 5-comprehensive-task-parameter-configuration">​</a></h4><p>For data development using Flink, the parameters submitted with Flink run are almost impossible to maintain. StreamPark has also <strong>elegantly solved</strong> this kind of problem, mainly because, as mentioned above, StreamPark directly calls the Flink Client API and has connected the entire process through the StreamPark product frontend.</p><p><img loading="lazy" src="/assets/images/parameter_configuration-94fb5d7ee0c9c04ed6d79ddb1cd3c1c7.png" width="1080" height="1001" class="img_ev3q"></p><p>As you can see, StreamPark's task parameter settings cover all the mainstream parameters, and every parameter has been thoughtfully provided with an introduction and an optimal recommendation based on best practices. This is also very beneficial for newcomers to Flink, helping them to avoid common pitfalls!</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="6-excellent-configuration-file-design"><strong>6. Excellent Configuration File Design</strong><a href="#6-excellent-configuration-file-design" class="hash-link" aria-label="Direct link to 6-excellent-configuration-file-design" title="Direct link to 6-excellent-configuration-file-design">​</a></h4><p>In addition to the native parameters for Flink tasks, which are covered by the task parameters above, StreamPark also provides a powerful <strong>Yaml configuration file</strong> mode and <strong>programming model</strong>.</p><p><img loading="lazy" src="/assets/images/extended_parameters-75c3f87809d0675c2fc82bc8d2ec096e.jpg" width="1080" height="2245" class="img_ev3q"></p><ol><li><p>For Flink SQL tasks, you can configure the parameters that StreamPark has already built-in, such as <strong>CheckPoint, retry mechanism, State Backend, table planner, mode</strong>, etc., directly using the task's Yaml configuration file.</p></li><li><p>For Jar tasks, StreamPark offers a generic programming model that encapsulates the native Flink API. Combined with the wrapper package provided by StreamPark, it can very elegantly retrieve custom parameters from the configuration file. For more details, see the documentation:</p></li></ol><p>Programming model:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">http://www.streamxhub.com/docs/development/dev-model</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Built-in Configuration File Parameters:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">http://www.streamxhub.com/docs/development/config</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>In addition:</p><p>StreamPark also <strong>supports Apache Flink native tasks</strong>. The parameter configuration can be statically maintained within the Java task internal code, covering a wide range of scenarios, such as seamless migration of existing Flink tasks, etc.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="7-checkpoint-management"><strong>7. Checkpoint Management</strong><a href="#7-checkpoint-management" class="hash-link" aria-label="Direct link to 7-checkpoint-management" title="Direct link to 7-checkpoint-management">​</a></h4><p>Regarding Flink's Checkpoint (Savepoint) mechanism, the greatest difficulty is maintenance. StreamPark has also elegantly solved this problem:</p><ul><li>StreamPark will <strong>automatically maintain</strong> the task Checkpoint directory and versions in the system for easy retrieval.</li><li>When users need to update and restart an application, they can choose whether to save a Savepoint.</li><li>When restarting a task, it is possible to choose to recover from a specified version of Checkpoint/Savepoint.</li></ul><p>As shown below, developers can very intuitively and conveniently upgrade or deal with exceptional tasks, which is very powerful.</p><p><img loading="lazy" src="/assets/images/checkpoint-e9edd22da076247770a0b40595626fb7.png" width="1080" height="483" class="img_ev3q"></p><p><img loading="lazy" src="/assets/images/recover-f1de53fdbe66c50b465d58d0a66050de.jpg" width="1053" height="391" class="img_ev3q"></p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="8-comprehensive-alerting-features"><strong>8. Comprehensive Alerting Features</strong><a href="#8-comprehensive-alerting-features" class="hash-link" aria-label="Direct link to 8-comprehensive-alerting-features" title="Direct link to 8-comprehensive-alerting-features">​</a></h4><p>For streaming computations, which are 7*24H resident tasks, monitoring and alerting are very important. StreamPark also has a <strong>comprehensive solution</strong> for these issues:</p><ul><li>It comes with an email-based alerting method, which has zero development cost and can be used once configured.</li><li>Thanks to the excellent modularity of the StreamPark source code, it's possible to enhance the code at the Task Track point and introduce the company's internal SDK for telephone, group, and other alerting methods, all with a very low development cost.</li></ul><p><img loading="lazy" src="/assets/images/alarm_email-fd4c9ba1995ec69b7557bd1378dce737.png" width="1009" height="1340" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="excellent-source-code"><strong>Excellent Source Code</strong><a href="#excellent-source-code" class="hash-link" aria-label="Direct link to excellent-source-code" title="Direct link to excellent-source-code">​</a></h3><p>Following the principle of technology selection, a new technology must be sufficiently understood in terms of underlying principles and architectural ideas before it is considered for production use. Before choosing StreamPark, its architecture and source code were subjected to in-depth study and reading. It was found that the underlying technologies used by StreamPark are very familiar to Chinese developers: MySQL, Spring Boot, Mybatis Plus, Vue, etc. The code style is unified and elegantly implemented with complete annotations. The modules are independently abstracted and reasonable, employing numerous design patterns, and the code quality is very high, making it highly suitable for troubleshooting and further development in the later stages.</p><p><img loading="lazy" src="/assets/images/code_notebook-542046feb8a312b5f6c057af551421c6.png" width="1080" height="527" class="img_ev3q"></p><p>In November 2021, StreamPark was successfully selected by Open Source China as a GVP - Gitee "Most Valuable Open Source Project," which speaks volumes about its quality and potential.</p><p><img loading="lazy" src="/assets/images/certificate-2f5b95ebb0816ead327ec169c12996b6.png" width="1080" height="684" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="03-active-community"><strong>03 Active Community</strong><a href="#03-active-community" class="hash-link" aria-label="Direct link to 03-active-community" title="Direct link to 03-active-community">​</a></h3><p>The community is currently very active. Since the end of November 2021, when StreamPark (based on 1.2.0-release) was implemented, StreamPark had just started to be recognized by everyone, and there were some minor bugs in the user experience (not affecting core functionality). At that time, in order to go live quickly, some features were disabled and some minor bugs were fixed. Just as we were preparing to contribute back to the community, we found that these had already been fixed, indicating that the community's iteration cycle is very fast. In the future, our company's team will also strive to stay in sync with the community, quickly implement new features, and improve data development efficiency while reducing maintenance costs.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="02-implementation-practice"><strong>02 Implementation Practice</strong><a href="#02-implementation-practice" class="hash-link" aria-label="Direct link to 02-implementation-practice" title="Direct link to 02-implementation-practice">​</a></h2><p>StreamPark's environment setup is very straightforward, following the official website's building tutorial you can complete the setup within a few hours. It now supports a front-end and back-end separation packaging deployment model, which can meet the needs of more companies, and there has already been a Docker Build related PR, suggesting that StreamPark's compilation and deployment will become even more convenient and quick in the future. Related documentation is as follows:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">http://www.streamxhub.com/docs/user-guide/deployment</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>For rapid implementation and production use, we chose the reliable On Yarn resource management mode (even though StreamPark already supports K8S quite well), and there are already many companies that have deployed using StreamPark on K8S, which you can refer to:</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">http://www.streamxhub.com/blog/flink-development-framework-streamx</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Integrating StreamPark with the Hadoop ecosystem can be said to be zero-cost (provided that Flink is integrated with the Hadoop ecosystem according to the Flink official website, and tasks can be launched via Flink scripts).</p><p>Currently, we are also conducting K8S testing and solution design, and will be migrating to K8S in the future.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="01-implementing-flinksql-tasks"><strong>01 Implementing FlinkSQL Tasks</strong><a href="#01-implementing-flinksql-tasks" class="hash-link" aria-label="Direct link to 01-implementing-flinksql-tasks" title="Direct link to 01-implementing-flinksql-tasks">​</a></h3><p>At present, our company's tasks based on Flink SQL are mainly for simple real-time ETL and computing scenarios, with about 10 tasks, all of which have been very stable since they went live.</p><p><img loading="lazy" src="/assets/images/online_flinksql-ca82a6f42e04e54e9f6da2b1e391b073.png" width="1080" height="118" class="img_ev3q"></p><p>StreamPark has thoughtfully prepared a demo SQL task that can be run directly on a newly set up platform. This attention to detail demonstrates the community's commitment to user experience. Initially, our simple tasks were written and executed using Flink SQL, and StreamPark's support for Flink SQL is excellent, with a superior SQL editor and innovative POM and Jar package dependency management that can meet many SQL scenario needs.</p><p>Currently, we are researching and designing solutions related to metadata, permissions, UDFs, etc.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="02-implementing-jar-tasks"><strong>02 Implementing Jar Tasks</strong><a href="#02-implementing-jar-tasks" class="hash-link" aria-label="Direct link to 02-implementing-jar-tasks" title="Direct link to 02-implementing-jar-tasks">​</a></h3><p>Since most of the data development team members have a background in Java and Scala, we've implemented Jar-based builds for more flexible development, transparent tuning of Flink tasks, and to cover more scenarios. Our implementation was in two phases:</p><p><strong>First Phase:</strong> StreamPark provides support for native Apache Flink projects. We configured our existing tasks' Git addresses in StreamPark, used Maven to package them as Jar files, and created StreamPark Apache Flink tasks for seamless migration. In this process, StreamPark was merely used as a platform tool for task submission and state maintenance, without leveraging the other features mentioned above.</p><p><strong>Second Phase:</strong> After migrating tasks to StreamPark in the first phase and having them run on the platform, the tasks' configurations, such as checkpoint, fault tolerance, and adjustments to business parameters within Flink tasks, required source code modifications, pushes, and builds. This was very inefficient and opaque.</p><p>Therefore, following StreamPark's QuickStart, we quickly integrated StreamPark's programming model, which is an encapsulation for StreamPark Flink tasks (for Apache Flink).</p><p>Example：</p><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">StreamingContext = ParameterTool + StreamExecutionEnvironment</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li>StreamingContext is the encapsulation object for StreamPark</li><li>ParameterTool is the parameter object after parsing the configuration file</li></ul><div class="codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain"> String value = ParameterTool.get("${user.custom.key}")</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li>StreamExecutionEnvironment is the native task context for Apache Flink</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="03-business-support--capability-opening"><strong>03 Business Support &amp; Capability Opening</strong><a href="#03-business-support--capability-opening" class="hash-link" aria-label="Direct link to 03-business-support--capability-opening" title="Direct link to 03-business-support--capability-opening">​</a></h2><p>Currently, Dustess Info's real-time computing platform based on StreamPark has been online since the end of November last year and has launched 50+ Flink tasks, including 10+ Flink SQL tasks and 40+ Jar tasks. At present, it is mainly used internally by the data team, and the real-time computing platform will be opened up for use by business teams across the company shortly, which will significantly increase the number of tasks.</p><p><img loading="lazy" src="/assets/images/online_jar-48549248f657388c7aebc0c8491660fa.png" width="1080" height="445" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="01-real-time-data-warehouse"><strong>01 Real-Time Data Warehouse</strong><a href="#01-real-time-data-warehouse" class="hash-link" aria-label="Direct link to 01-real-time-data-warehouse" title="Direct link to 01-real-time-data-warehouse">​</a></h3><p>The real-time data warehouse mainly uses Jar tasks because the model is more generic. Using Jar tasks can generically handle a large number of data table synchronization and calculations, and even achieve configuration-based synchronization. Our real-time data warehouse mainly uses Apache Doris for storage, with Flink handling the cleaning and calculations (the goal being storage-computation separation).</p><p>Using StreamPark to integrate other components is also very straightforward, and we have also abstracted the configuration related to Apache Doris and Kafka into the configuration file, which greatly enhances our development efficiency and flexibility.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="02-capability-opening"><strong>02 Capability Opening</strong><a href="#02-capability-opening" class="hash-link" aria-label="Direct link to 02-capability-opening" title="Direct link to 02-capability-opening">​</a></h3><p>Other business teams outside the data team also have many stream processing scenarios. Hence, after secondary development of the real-time computing platform based on StreamPark, we opened up the following capabilities to all business teams in the company:</p><ul><li>Business capability opening: The upstream real-time data warehouse collects all business tables through log collection and writes them into Kafka. Business teams can base their business-related development on Kafka, or they can perform OLAP analysis through the real-time data warehouse (Apache Doris).</li><li>Computing capability opening: The server resources of the big data platform are made available for use by business teams.</li><li>Solution opening: The mature Connectors of the Flink ecosystem and support for Exactly Once semantics can reduce the development and maintenance costs related to stream processing for business teams.</li></ul><p>Currently, StreamPark does not support multi-business group functions. The multi-business group function will be abstracted and contributed to the community.</p><p><img loading="lazy" src="/assets/images/manager-07ba2a4bc979cd2dd86fc9e07384ec61.png" width="1080" height="235" class="img_ev3q"></p><p><img loading="lazy" src="/assets/images/task_retrieval-eee86f9c0af117cbf15d2af5d528b2cc.png" width="1080" height="382" class="img_ev3q"></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="04-future-planning"><strong>04 Future Planning</strong><a href="#04-future-planning" class="hash-link" aria-label="Direct link to 04-future-planning" title="Direct link to 04-future-planning">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="01-flink-on-k8s"><strong>01 Flink on K8S</strong><a href="#01-flink-on-k8s" class="hash-link" aria-label="Direct link to 01-flink-on-k8s" title="Direct link to 01-flink-on-k8s">​</a></h3><p>Currently, all our company's Flink tasks run on Yarn, which meets current needs, but Flink on Kubernetes has the following advantages:</p><ul><li><strong>Unified Operations</strong>. The company has unified operations with a dedicated department managing K8S.</li><li><strong>CPU Isolation</strong>. There is CPU isolation between K8S Pods, so real-time tasks do not affect each other, leading to more stability.</li><li><strong>Separation of Storage and Computation</strong>. Flink's computational resources and state storage are separated; computational resources can be mixed with other component resources, improving machine utilization.</li><li><strong>Elastic Scaling</strong>. It is capable of elastic scaling, better saving manpower and material costs.</li></ul><p>I am also currently organizing and implementing related technical architectures and solutions and have completed the technical verification of Flink on Kubernetes using StreamPark in an experimental environment. With the support of the StreamPark platform and the enthusiastic help of the community, I believe that production implementation is not far off.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="02-stream-batch-unification-construction"><strong>02 Stream-Batch Unification Construction</strong><a href="#02-stream-batch-unification-construction" class="hash-link" aria-label="Direct link to 02-stream-batch-unification-construction" title="Direct link to 02-stream-batch-unification-construction">​</a></h3><p>Personally, I think the biggest difference between batch and stream processing lies in the scheduling strategy of operator tasks and the data transfer strategy between operators:</p><ul><li><strong>Batch processing</strong>: Upstream and downstream operator tasks have sequential scheduling (upstream tasks end and release resources), and data has a Shuffle strategy (landing on disk). The downside is lower timeliness and no intermediate state in computation, but the upside is high throughput, suitable for offline computation of super-large data volumes.</li><li><strong>Stream processing</strong>: Upstream and downstream operator tasks start at the same time (occupying resources simultaneously), and data is streamed between nodes through the network. The downside is insufficient throughput, but the advantage is high timeliness and intermediate state in computation, suitable for real-time and incremental computation scenarios.</li></ul><p>As mentioned above, I believe that choosing <strong>batch or stream processing</strong> <strong>is a tuning method for data development according to different data volumes and business scenarios</strong>. However, currently, because the computing engine and platform distinguish offline and real-time, it causes development and maintenance fragmentation, with prohibitively high costs. To achieve stream-batch unification, the following aspects must be realized:</p><ul><li>Unified storage (unification of metadata): Supports batch and stream writing/reading.</li><li>Unified computing engine: Able to use a set of APIs or SQL to develop offline and real-time tasks.</li><li>Unified data platform: Able to support the persistent real-time tasks, as well as offline scheduling strategies.</li></ul><p>Regarding the unification of stream and batch, I am also currently researching and organizing, and I welcome interested friends to discuss and study the project together.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="05-closing-words"><strong>05 Closing Words</strong><a href="#05-closing-words" class="hash-link" aria-label="Direct link to 05-closing-words" title="Direct link to 05-closing-words">​</a></h2><p>That's all for the sharing of StreamPark in the production practice at Dustess Info. Thank you all for reading this far. The original intention of writing this article was to bring a bit of StreamPark's production practice experience and reference to everyone, and together with the buddies in the StreamPark community, to jointly build StreamPark. In the future, I plan to participate and contribute more. A big thank you to the developers of StreamPark for providing such an excellent product; in many details, we can feel everyone's dedication. Although the current production version used by the company (1.2.0-release) still has some room for improvement in task group search, edit return jump page, and other interactive experiences, the merits outweigh the minor issues. I believe that StreamPark will get better and better, <strong>and I also believe that StreamPark will promote the popularity of Apache Flink</strong>. Finally, let's end with a phrase from the Apache Flink community: The future is real-time!</p><p><img loading="lazy" src="/assets/images/author-487ad3c1ad9a397cd4c2614f54976368.png" width="844" height="439" class="img_ev3q"></p>]]></content>
        <category label="StreamPark" term="StreamPark"/>
        <category label="Production Practice" term="Production Practice"/>
        <category label="FlinkSQL" term="FlinkSQL"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[StreamPark's Production Practice in Joyme]]></title>
        <id>https://streampark.apache.org/blog/streampark-usercase-joyme</id>
        <link href="https://streampark.apache.org/blog/streampark-usercase-joyme"/>
        <updated>2024-01-21T04:16:34.000Z</updated>
        <summary type="html"><![CDATA[Abstract]]></summary>
        <content type="html"><![CDATA[<p><strong>Abstract:</strong> This article presents the production practices of StreamPark at Joyme, written by Qin Jiyong, a big data engineer at Joyme. The main contents include:</p><ul><li>Encountering StreamPark</li><li>Flink SQL job development</li><li>Custom code job development</li><li>Monitoring and alerting</li><li>Common issues</li><li>Community impressions</li><li>Summary</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="1-encountering-streampark">1 Encountering StreamPark<a href="#1-encountering-streampark" class="hash-link" aria-label="Direct link to 1 Encountering StreamPark" title="Direct link to 1 Encountering StreamPark">​</a></h2><p>Encountering StreamPark was inevitable. Based on our existing real-time job development mode, we had to find an open-source platform to support our company's real-time business. Our current situation was as follows:</p><ul><li>We wrote jobs and packaged them to servers, then executed the Flink run command to submit them, which was a cumbersome and inefficient process.</li><li>Flink SQL was submitted through a self-developed old platform. The developers of the old platform had left, and no one maintained the subsequent code, even if someone did, they would have to face the problem of high maintenance costs.</li><li>Some of the authors were SparkStreaming jobs, with two sets of streaming engines and frameworks not unified, resulting in high development costs.</li><li>Real-time jobs were developed in Scala and Java, with languages and technology stacks not unified.</li></ul><p>For all these reasons, we needed an open-source platform to manage our real-time jobs, and we also needed to refactor to unify the development mode and language and centralize project management.</p><p>The first encounter with StreamPark basically confirmed our choice. We quickly deployed and installed according to the official documentation, performed some operations after setting up, and were greeted with a user-friendly interface. StreamPark's support for multiple versions of Flink, permission management, job monitoring, and other series of functions already met our needs well. Further understanding revealed that its community is also very active. We have witnessed the process of StreamPark's feature completion since version 1.1.0. The development team is very ambitious, and we believe they will continue to improve.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="2-development-of-flink-sql-jobs">2 Development of Flink SQL Jobs<a href="#2-development-of-flink-sql-jobs" class="hash-link" aria-label="Direct link to 2 Development of Flink SQL Jobs" title="Direct link to 2 Development of Flink SQL Jobs">​</a></h2><p>The Flink SQL development mode has brought great convenience. For some simple metric developments, it is possible to complete them with just a few SQL statements, without the need to write a single line of code. Flink SQL has facilitated the development work for many colleagues, especially since writing code can be somewhat difficult for those who work on warehouses.</p><p>To add a new task, you open the task addition interface of StreamPark, where the default Development Mode is Flink SQL mode. You can write the SQL logic directly in the Flink SQL section.</p><p>For the Flink SQL part, you can progressively write the logic SQL following the Flink official website's documentation. Generally, for our company, it consists of three parts: the Source connection, intermediate logic processing, and finally the Sink. Essentially, the Source is consuming data from Kafka, the logic layer will involve MySQL for dimension table queries, and the Sink part is mostly Elasticsearch, Redis, or MySQL.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="1-writing-sql"><strong>1. Writing SQL</strong><a href="#1-writing-sql" class="hash-link" aria-label="Direct link to 1-writing-sql" title="Direct link to 1-writing-sql">​</a></h3><div class="language-sql codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sql codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token comment" style="color:rgb(98, 114, 164)">-- Connect kafka</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">CREATE</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">TABLE</span><span class="token plain"> source_table </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"> </span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">Data</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">ROW</span><span class="token operator">&lt;</span><span class="token plain">uid STRING</span><span class="token operator">&gt;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">WITH</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'connector.type'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'kafka'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'connector.version'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'universal'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'connector.topic'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'主题'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'connector.properties.bootstrap.servers'</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">'broker地址'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'connector.startup-mode'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'latest-offset'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'update-mode'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'append'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'format.type'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'json'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'connector.properties.group.id'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'消费组id'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'format.derive-schema'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'true'</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)">-- Landing table sink</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">CREATE</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">TABLE</span><span class="token plain"> sink_table </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token identifier">uid</span><span class="token identifier punctuation" style="color:rgb(248, 248, 242)">`</span><span class="token plain"> STRING</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">WITH</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'connector.type'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'jdbc'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'connector.url'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'jdbc:mysql://xxx/xxx?useSSL=false'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'connector.username'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'username'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'connector.password'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'password'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'connector.table'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'tablename'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'connector.write.flush.max-rows'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'50'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'connector.write.flush.interval'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'2s'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token string" style="color:rgb(255, 121, 198)">'connector.write.max-retries'</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'3'</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)">-- Code logic pass</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">INSERT</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">INTO</span><span class="token plain"> sink_table</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">SELECT</span><span class="token plain">  </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">Data</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">uid  </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">FROM</span><span class="token plain"> source_table</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="2-add-dependency"><strong>2. Add Dependency</strong><a href="#2-add-dependency" class="hash-link" aria-label="Direct link to 2-add-dependency" title="Direct link to 2-add-dependency">​</a></h3><p>In terms of dependencies, it's an unique feature to Streampark. A complete Flink SQL job is innovatively split into two components within StreamPark: the SQL and the dependencies. The SQL part is easy to understand and requires no further explanation, but the dependencies are the various Connector JARs needed within the SQL, such as Kafka and MySQL Connectors. If these are used within the SQL, then these Connector dependencies must be introduced. In StreamPark, there are two ways to add dependencies: one is based on the standard Maven pom coordinates, and the other is by uploading the required Jars from a local source. These two methods can also be mixed and used as needed; simply apply, and these dependencies will be automatically loaded when the job is submitted.</p><p><img loading="lazy" src="/assets/images/add_dependency-281888d96a8f3ce6e9af01efef9de643.png" width="1080" height="469" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="3-parameter-configuration"><strong>3. Parameter Configuration</strong><a href="#3-parameter-configuration" class="hash-link" aria-label="Direct link to 3-parameter-configuration" title="Direct link to 3-parameter-configuration">​</a></h3><p>The task addition and modification page has listed some common parameter settings, and for more extensive configuration options, a yaml configuration file is provided. Here, we've only set up checkpoint and savepoint configurations. The first is the location of the checkpoint, and the second is the frequency of checkpoint execution. We haven't changed other configurations much; users can customize these settings as per their needs.</p><p>The rest of the parameter settings should be configured according to the specific circumstances of the job. If the volume of data processed is large or the logic is complex, it might require more memory and higher parallelism. Sometimes, adjustments need to be made multiple times based on the job's operational performance.</p><p><img loading="lazy" src="/assets/images/checkpoint_configuration-861a4f0439b1a0f8aade35e10e6b60c5.png" width="1080" height="610" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="4-dynamic-parameter-settings"><strong>4. Dynamic Parameter Settings</strong><a href="#4-dynamic-parameter-settings" class="hash-link" aria-label="Direct link to 4-dynamic-parameter-settings" title="Direct link to 4-dynamic-parameter-settings">​</a></h3><p>Since our deployment mode is on Yarn, we configured the name of the Yarn queue in the dynamic options. Some configurations have also been set to enable incremental checkpoints and state TTL (time-to-live), all of which can be found on Flink's official website. Before, some jobs frequently encountered out-of-memory issues. After adding the incremental parameter and TTL, the job operation improved significantly. Also, in cases where the Flink SQL job involves larger states and complex logic, I personally feel that it's better to implement them through streaming code for more control.</p><ul><li>-Dyarn.application.queue=Yarn queue name</li><li>-Dstate.backend.incremental=true</li><li>-Dtable.exec.state.ttl=expiration time</li></ul><p>After completing the configuration, submit &amp; deploy it from the application interface.</p><p><img loading="lazy" src="/assets/images/application_job-5518b58af2b481d7bdb36a7bae252c41.png" width="1080" height="422" class="img_ev3q"></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="3-custom-code-job-development">3 Custom Code Job Development<a href="#3-custom-code-job-development" class="hash-link" aria-label="Direct link to 3 Custom Code Job Development" title="Direct link to 3 Custom Code Job Development">​</a></h2><p>For streaming jobs, we use Flink Java for development, having refactored previous Spark Scala, Flink Scala, and Flink Java jobs and then integrated these projects together. The purpose of this integration is to facilitate maintenance. Custom code jobs require the submission of code to Git, followed by project configuration:</p><p><img loading="lazy" src="/assets/images/project_configuration-add3d079bba91ac4977b830d3c3fe8f7.png" width="1080" height="365" class="img_ev3q"></p><p>Once the configuration is completed, compile the corresponding project to finish the packaging phase. Thus, the Custom code jobs can also reference it. Compilation is required every time the code needs to go live; otherwise, only the last compiled code is available. Here's an issue: for security reasons, our company’s GitLab account passwords are regularly updated. This leads to a situation where the StreamPark projects have the old passwords configured, resulting in a failure when pulling projects from Git during compilation. To address this problem, we contacted the community and learned that the capability to modify projects has been added in the subsequent version 1.2.1.</p><p><img loading="lazy" src="/assets/images/flink_system-02dee8b704254087aae900731ae47076.png" width="1080" height="214" class="img_ev3q"></p><p>To create a new task, select Custom code, choose the Flink version, select the project and the module Jar package, and choose the development application mode as Apache Flink (standard Flink program), program main function entry class, and the task's name.</p><p><img loading="lazy" src="/assets/images/add_projectconfiguration-26b97212de577a0cbc46b59f1eceea0b.png" width="1080" height="536" class="img_ev3q"></p><p>As well as the task’s parallelism, monitoring method, etc., memory size should be configured based on the needs of the task. Program Args, the program parameters, are defined according to the program's needs. For example: If our unified startup class is StartJobApp, to start a job, it's necessary to pass the full name of the job, informing the startup class which class to find to launch the task—essentially, which is a reflection mechanism. After the job configuration is complete, it is also submitted with Submit and then deployed from the application interface.</p><p><img loading="lazy" src="/assets/images/application_interface-51c8f96e343842f32b56c3c889064cba.png" width="1080" height="500" class="img_ev3q"></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="4-monitoring-and-alerts">4 Monitoring and Alerts<a href="#4-monitoring-and-alerts" class="hash-link" aria-label="Direct link to 4 Monitoring and Alerts" title="Direct link to 4 Monitoring and Alerts">​</a></h2><p>The monitoring in StreamPark requires configuration in the setting module to set up the basic information for sending emails.</p><p><img loading="lazy" src="/assets/images/system_setting-6b5b21f22fc4a32b973ede0a5f21ebc2.png" width="1080" height="380" class="img_ev3q"></p><p>Then, within the tasks, configure the restart strategy: monitor how many times an exception occurs within a certain time, and then decide whether the strategy is to alert or restart, as well as which email address should receive the alert notifications. The version currently used by our company is 1.2.1, which supports only email sending.</p><p><img loading="lazy" src="/assets/images/email_setting-7b8ddba6688c75cfad32f5d16e93354f.png" width="1080" height="243" class="img_ev3q"></p><p>When our jobs fail, we can receive alerts through email. These alerts are quite clear, showing which job is in what state. You can also click on the specific address below to view details.</p><p><img loading="lazy" src="/assets/images/alarm_eamil-29b2875dbfcbeb071fef815ab751786a.png" width="1080" height="1517" class="img_ev3q"></p><p>Regarding alerts, we have developed a scheduled task based on StreamPark's t_flink_app table. Why do this? Because most people might not check their emails promptly when it comes to email notifications. Therefore, we opted to monitor the status of each task and send corresponding monitoring information to our Lark (Feishu) alert group, enabling us to promptly identify and address issues with the tasks. It's a simple Python script, then configured with crontab to execute at scheduled times.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="5-common-issues">5 Common Issues<a href="#5-common-issues" class="hash-link" aria-label="Direct link to 5 Common Issues" title="Direct link to 5 Common Issues">​</a></h2><p>When it comes to the abnormal issues of jobs, we have summarized them into the following categories:</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="1-job-launch-failure"><strong>1. Job Launch Failure</strong><a href="#1-job-launch-failure" class="hash-link" aria-label="Direct link to 1-job-launch-failure" title="Direct link to 1-job-launch-failure">​</a></h3><p>The issue of job launch failure refers to the situation where the job does not start upon initiation. In this case, one needs to check the detailed information logs on the interface. There is an eye-shaped button in our task list; by clicking on it, one can find the submitted job log information in the start logs. If there is clear prompt information, the issue can be directly addressed. If not, one has to check the streamx.out file under the logs/ directory of the backend deployment task to find the log information regarding the launch failure.</p><p><img loading="lazy" src="/assets/images/start_log-6ce6b3125c8693db96197193241d6807.png" width="1080" height="83" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="2-job-running-failure"><strong>2. Job Running Failure</strong><a href="#2-job-running-failure" class="hash-link" aria-label="Direct link to 2-job-running-failure" title="Direct link to 2-job-running-failure">​</a></h3><p>If the task has started but fails during the running phase, this situation might seem similar to the first, but is actually entirely different. This means that the task has been submitted to the cluster, but the task itself has problems running. One can still apply the troubleshooting method from the first scenario to open the specific logs of the job, find the task information on yarn, and then go to yarn's logs with the yarn's tackurl recorded in the logs to look for the specific reasons. Whether it is the absence of the Sql's Connector or a null pointer in a line of code, one can find the detailed stack information. With specific information, one can find the right remedy.</p><p><img loading="lazy" src="/assets/images/yarn_log-100e18b484ec81cf3165736de8259365.png" width="1080" height="82" class="img_ev3q"></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="6-community-impression">6 Community Impression<a href="#6-community-impression" class="hash-link" aria-label="Direct link to 6 Community Impression" title="Direct link to 6 Community Impression">​</a></h2><p>Often when we discuss issues in the StreamPark user group, we get immediate responses from community members. Issues that cannot be resolved at the moment are generally fixed in the next version or the latest code branch. In the group, we also see many non-community members actively helping each other out. There are many big names from other communities as well, and many members actively join the community development work. The whole community feels very active to me!</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="7-conclusion">7 Conclusion<a href="#7-conclusion" class="hash-link" aria-label="Direct link to 7 Conclusion" title="Direct link to 7 Conclusion">​</a></h2><p>Currently, our company runs 60 real-time jobs online, with Flink SQL and custom code each making up about half. More real-time tasks will be put online subsequently. Many colleagues worry about the stability of StreamPark, but based on several months of production practice in our company, StreamPark is just a platform to help you develop, deploy, monitor, and manage jobs. Whether it is stable or not depends on the stability of our own Hadoop Yarn cluster (we use the onyan mode) and has little to do with StreamPark itself. It also depends on the robustness of the Flink SQL or code you write. These two aspects should be the primary concerns. Only when these two aspects are problem-free can the flexibility of StreamPark be fully utilized to improve job performance. To discuss the stability of StreamPark in isolation is somewhat extreme.</p><p>That is all the content shared by StreamPark at Joyme. Thank you for reading this article. We are very grateful for such an excellent product provided by StreamPark, which is a true act of benefiting others. From version 1.0 to 1.2.1, the bugs encountered are promptly fixed, and every issue is taken seriously. We are still using the on yarn deployment mode. Restarting yarn will still cause jobs to be lost, but restarting yarn is not something we do every day. The community will also look to fix this problem as soon as possible. I believe that StreamPark will get better and better, with a promising future ahead.</p>]]></content>
        <category label="StreamPark" term="StreamPark"/>
        <category label="Production Practice" term="Production Practice"/>
        <category label="FlinkSQL" term="FlinkSQL"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[An All-in-One Computation Tool in Haibo Tech's Production Practice and facilitation in Smart City Construction]]></title>
        <id>https://streampark.apache.org/blog/streampark-usercase-haibo</id>
        <link href="https://streampark.apache.org/blog/streampark-usercase-haibo"/>
        <updated>2024-01-21T04:16:34.000Z</updated>
        <summary type="html"><![CDATA[Summary An All-in-One Computation Tool in Haibo Tech's Production Practice and facilitation in Smart City Construction," is the Big Data Architect at Haibo Tech. The main topics covered include:]]></summary>
        <content type="html"><![CDATA[<p><strong>Summary:</strong> The author of this article, "StreamPark: An All-in-One Computation Tool in Haibo Tech's Production Practice and facilitation in Smart City Construction," is the Big Data Architect at Haibo Tech. The main topics covered include:</p><ol><li>Choosing StreamPark</li><li>Getting Started Quickly</li><li>Application Scenarios</li><li>Feature Extensions</li><li>Future Expectations</li></ol><p>Haibo Tech is an industry-leading company offering AI IoT products and solutions. Currently, they provide full-stack solutions, including algorithms, software, and hardware products, to clients nationwide in public safety, smart cities, and smart manufacturing domains.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="01-choosing-streampark"><strong>01. Choosing StreamPark</strong><a href="#01-choosing-streampark" class="hash-link" aria-label="Direct link to 01-choosing-streampark" title="Direct link to 01-choosing-streampark">​</a></h2><p>Haibo Tech started using Flink SQL to aggregate and process various real-time IoT data since 2020. With the accelerated pace of smart city construction in various cities, the types and volume of IoT data to be aggregated are also increasing. This has resulted in an increasing number of Flink SQL tasks being maintained online, making a dedicated platform for managing numerous Flink SQL tasks an urgent need.</p><p>After evaluating Apache Zeppelin and StreamPark, we chose StreamPark as our real-time computing platform. Compared to Apache Zeppelin, StreamPark may not be as well-known. However, after experiencing the initial release of StreamPark and reading its design documentation, we recognized that its all-in-one design philosophy covers the entire lifecycle of Flink task development. This means that configuration, development, deployment, and operations can all be accomplished on a single platform. Our developers, operators, and testers can collaboratively work on StreamPark. The <strong>low-code</strong> + <strong>all-in-one</strong> design principles solidified our confidence in using StreamPark.</p><p>// Video link (streampark official video)</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="02-practical-implementation"><strong>02. Practical Implementation</strong><a href="#02-practical-implementation" class="hash-link" aria-label="Direct link to 02-practical-implementation" title="Direct link to 02-practical-implementation">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="1-quick-start"><strong>1. Quick Start</strong><a href="#1-quick-start" class="hash-link" aria-label="Direct link to 1-quick-start" title="Direct link to 1-quick-start">​</a></h3><p>Using StreamPark to accomplish a real-time aggregation task is as simple as putting an elephant into a fridge, and it can be done in just three steps:</p><ul><li>Edit SQL</li></ul><p><img loading="lazy" src="/assets/images/flink_sql-a8811954a9f765640bb08ad9cd139a15.png" width="1080" height="578" class="img_ev3q"></p><ul><li>Upload dependency packages</li></ul><p><img loading="lazy" src="/assets/images/dependency-172169d43c50f455fb7e2c7e08de32a2.png" width="1080" height="449" class="img_ev3q"></p><ul><li>Deploy and run</li></ul><p><img loading="lazy" src="/assets/images/deploy-d486a5c0eb238a9f2a6ce5f2b3013500.png" width="1080" height="538" class="img_ev3q"></p><p>With just the above three steps, you can complete the aggregation task from Mysql to Elasticsearch, significantly improving data access efficiency.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="2-production-practice"><strong>2. Production Practice</strong><a href="#2-production-practice" class="hash-link" aria-label="Direct link to 2-production-practice" title="Direct link to 2-production-practice">​</a></h3><p>StreamPark is primarily used at Haibo for running real-time Flink SQL tasks: reading data from Kafka, processing it, and outputting to Clickhouse or Elasticsearch.</p><p>Starting from October 2021, the company gradually migrated Flink SQL tasks to the StreamPark platform for centralized management. It supports the aggregation, computation, and alerting of our real-time IoT data.</p><p>As of now, StreamPark has been deployed in various government and public security production environments, aggregating and processing real-time IoT data, as well as capturing data on people and vehicles. Below is a screenshot of the StreamPark platform deployed on a city's dedicated network:</p><p><img loading="lazy" src="/assets/images/application-b12eb5d36d548a02e52ec12a28ddcec0.png" width="1080" height="613" class="img_ev3q"></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="03-application-scenarios"><strong>03. Application Scenarios</strong><a href="#03-application-scenarios" class="hash-link" aria-label="Direct link to 03-application-scenarios" title="Direct link to 03-application-scenarios">​</a></h2><h4 class="anchor anchorWithStickyNavbar_LWe7" id="1-real-time-iot-sensing-data-aggregation"><strong>1. Real-time IoT Sensing Data Aggregation</strong><a href="#1-real-time-iot-sensing-data-aggregation" class="hash-link" aria-label="Direct link to 1-real-time-iot-sensing-data-aggregation" title="Direct link to 1-real-time-iot-sensing-data-aggregation">​</a></h4><p>For aggregating real-time IoT sensing data, we directly use StreamPark to develop Flink SQL tasks. For methods not provided by Flink SQL, StreamPark also supports UDF-related functionalities. Users can upload UDF packages through StreamPark, and then call the relevant UDF in SQL to achieve more complex logical operations.</p><p>The "SQL+UDF" approach meets most of our data aggregation scenarios. If business changes in the future, we only need to modify the SQL statement in StreamPark to complete business changes and deployment.</p><p><img loading="lazy" src="/assets/images/data_aggregation-e5caba8eee38a8444df6cb3382a1d978.png" width="1080" height="607" class="img_ev3q"></p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="2-flink-cdc-database-synchronization"><strong>2. Flink CDC Database Synchronization</strong><a href="#2-flink-cdc-database-synchronization" class="hash-link" aria-label="Direct link to 2-flink-cdc-database-synchronization" title="Direct link to 2-flink-cdc-database-synchronization">​</a></h4><p>To achieve synchronization between various databases and data warehouses, we use StreamPark to develop Flink CDC SQL tasks. With the capabilities of Flink CDC, we've implemented data synchronization between Oracle and Oracle, as well as synchronization between Mysql/Postgresql and Clickhouse.</p><p><img loading="lazy" src="/assets/images/flink_cdc-318444c917eb66f591a5c75db9662e78.png" width="794" height="232" class="img_ev3q"></p><p><strong>3. Data Analysis Model Management</strong></p><p>For tasks that can't use Flink SQL and need Flink code development, such as real-time control models and offline data analysis models, StreamPark offers a Custom code approach, allowing users to upload executable Flink Jar packages and run them.</p><p>Currently, we have uploaded over 20 analysis models, such as personnel and vehicles, to StreamPark, which manages and operates them.</p><p><img loading="lazy" src="/assets/images/data_aggregation-e5caba8eee38a8444df6cb3382a1d978.png" width="1080" height="607" class="img_ev3q"></p><p><strong>In Summary:</strong> Whether it's Flink SQL tasks or Custom code tasks, StreamPark provides excellent support to meet various business scenarios. However, StreamPark lacks task scheduling capabilities. If you need to schedule tasks regularly, StreamPark currently cannot meet this need. Community members are actively developing scheduling-related modules, and the soon-to-be-released version 1.2.3 will support task scheduling capabilities, so stay tuned.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="04-feature-extension"><strong>04. Feature Extension</strong><a href="#04-feature-extension" class="hash-link" aria-label="Direct link to 04-feature-extension" title="Direct link to 04-feature-extension">​</a></h2><p>Datahub is a metadata management platform developed by Linkedin, offering data source management, data lineage, data quality checks, and more. Haibo Tech has developed an extension based on StreamPark and Datahub, implementing table-level/field-level lineage features. With the data lineage feature, users can check the field lineage relationship of Flink SQL and save the lineage relationship to the Linkedin/Datahub metadata management platform.</p><p>// Two video links (Data lineage feature developed based on streampark)</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="05-future-expectations"><strong>05. Future Expectations</strong><a href="#05-future-expectations" class="hash-link" aria-label="Direct link to 05-future-expectations" title="Direct link to 05-future-expectations">​</a></h2><p>Currently, the StreamPark community's Roadmap indicates that StreamPark 1.3.0 will usher in a brand new Workbench experience, a unified resource management center (unified management of JAR/UDF/Connectors), batch task scheduling, and more. These are also some of the brand-new features we are eagerly anticipating.</p><p>The Workbench will use a new workbench-style SQL development style. By selecting a data source, SQL can be generated automatically, further enhancing Flink task development efficiency. The unified UDF resource center will solve the current problem where each task has to upload its dependency package. The batch task scheduling feature will address StreamPark's current inability to schedule tasks.</p><p>Below is a prototype designed by StreamPark developers, so please stay tuned.</p><p><img loading="lazy" src="/assets/images/data_source-5f9b710b4186a08571192ae81ab350d1.png" width="830" height="518" class="img_ev3q"></p>]]></content>
        <category label="StreamPark" term="StreamPark"/>
        <category label="Production Practice" term="Production Practice"/>
        <category label="FlinkSQL" term="FlinkSQL"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Ziroom's Real-Time Computing Platform Practice Based on Apache StreamPark]]></title>
        <id>https://streampark.apache.org/blog/streampark-usercase-ziru</id>
        <link href="https://streampark.apache.org/blog/streampark-usercase-ziru"/>
        <updated>2024-01-21T04:16:34.000Z</updated>
        <summary type="html"><![CDATA[Introduction: Ziroom, an O2O internet company focusing on providing rental housing products and services, has built an online, data-driven, and intelligent platform that covers the entire chain of urban living. Real-time computing has always played an important role in Ziroom. To date, Ziroom processes TB-level data daily. This article, brought by the real-time computing team from Ziroom, introduces the in-depth practice of Ziroom's real-time computing platform based on StreamPark.]]></summary>
        <content type="html"><![CDATA[<p><img loading="lazy" src="/assets/images/cover-87ff8832da8f5d9398ed5a1e2f283d0d.png" width="1080" height="460" class="img_ev3q"></p><p><strong>Introduction:</strong> Ziroom, an O2O internet company focusing on providing rental housing products and services, has built an online, data-driven, and intelligent platform that covers the entire chain of urban living. Real-time computing has always played an important role in Ziroom. To date, Ziroom processes TB-level data daily. This article, brought by the real-time computing team from Ziroom, introduces the in-depth practice of Ziroom's real-time computing platform based on StreamPark.</p><ul><li>Challenges in real-time computing</li><li>The journey to the solution</li><li>In-depth practice based on StreamPark</li><li>Summary of practical experience and examples</li><li>Benefits brought by the implementation</li><li>Future plans</li></ul><p>As an O2O internet brand offering rental housing products and services, Ziroom was established in October 2011. To date, Ziroom has served nearly 500,000 landlords and 5 million customers, managing over 1 million housing units. As of March 2021, Ziroom has expanded to 10 major cities including Beijing, Shanghai, Shenzhen, Hangzhou, Nanjing, Guangzhou, Chengdu, Tianjin, Wuhan, and Suzhou. Ziroom has created an online, data-driven, and intelligent platform for quality residential products for both To C and To B markets, covering the entire chain of urban living. The Ziroom app has accumulated 140 million downloads, with an average of 400 million online service calls per day, and owns tens of thousands of smart housing units. Ziroom has now established an O2O closed loop for renting, services, and community on PC, app, and WeChat platforms, eliminating all redundant steps in the traditional renting model, restructuring the residential market through the O2O model, and building China's largest O2O youth living community.</p><p>With a vast user base, Ziroom has been committed to providing superior product experiences and achieving digital transformation of the enterprise. Since 2021, real-time computing, particularly Flink, has played an important role in Ziroom. To date, Ziroom processes TB-level data daily, with over 500 real-time jobs supporting more than 10 million data calls per day.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="challenges-in-real-time-computing"><strong>Challenges in Real-Time Computing</strong><a href="#challenges-in-real-time-computing" class="hash-link" aria-label="Direct link to challenges-in-real-time-computing" title="Direct link to challenges-in-real-time-computing">​</a></h2><p>At Ziroom, real-time computing is mainly divided into two application scenarios:</p><ul><li><p>Data synchronization: Includes Kafka, MySQL, and MongoDB data synchronization to Hive / Paimon / ClickHouse, etc.</p></li><li><p>Real-time data warehouse: Includes real-time indicators for businesses like rentals, acquisitions, and home services.</p></li></ul><p>In the process of implementing real-time computing, we faced several challenges, roughly as follows:</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="01-low-efficiency-in-job-deployment"><strong>01 Low Efficiency in Job Deployment</strong><a href="#01-low-efficiency-in-job-deployment" class="hash-link" aria-label="Direct link to 01-low-efficiency-in-job-deployment" title="Direct link to 01-low-efficiency-in-job-deployment">​</a></h3><p>The process of developing and deploying real-time jobs at Ziroom is as follows: data warehouse developers embed Flink SQL code in the program, debug locally, compile into FatJar, and then submit the job as a work order and JAR package to the operation team. The operation team member responsible for job deployment then deploys the job to the online Kubernetes session environment through the command line. This process involves many steps, each requiring manual intervention, resulting in extremely low efficiency and being prone to errors, affecting work efficiency and stability. Therefore, there is an urgent need to build an efficient and automated real-time computing platform to meet the growing demands of real-time computing.</p><p><img loading="lazy" src="/assets/images/job_goes_online-ae38a4f939687b0e80e8e5677885fe0d.png" width="1080" height="356" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="02-unclear-job-ownership-information"><strong>02 Unclear Job Ownership Information</strong><a href="#02-unclear-job-ownership-information" class="hash-link" aria-label="Direct link to 02-unclear-job-ownership-information" title="Direct link to 02-unclear-job-ownership-information">​</a></h3><p>Due to the lack of unified management of the real-time computing platform, business code is managed by GitLab. Although this solved some problems, we found deficiencies between the repository code and the management of online Flink jobs: lack of clear ownership, lack of grouping and effective permission control, leading to chaotic job management and difficult responsibility tracing. To ensure the consistency and controllability of code and online jobs, there is an urgent need to establish a strict and clear job management system, including strict code version control, clear job ownership and responsible persons, and effective permission control.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="03-difficulty-in-job-maintenance"><strong>03 Difficulty in Job Maintenance</strong><a href="#03-difficulty-in-job-maintenance" class="hash-link" aria-label="Direct link to 03-difficulty-in-job-maintenance" title="Direct link to 03-difficulty-in-job-maintenance">​</a></h3><p>At Ziroom, multiple versions of Flink jobs are running. Due to frequent API changes and lack of backward compatibility in major version upgrades of Apache Flink, the cost of upgrading project code becomes very high. Therefore, managing these different versions of jobs has become a headache.</p><p>Without a</p><p>unified job platform, these jobs are submitted using scripts. Jobs vary in importance and data volume, requiring different resources and runtime parameters, necessitating corresponding modifications. Modifications can be made by editing the submission script or directly setting parameters in the code, but this makes configuration information difficult to access, especially when jobs restart or fail and FlinkUI is unavailable, turning configuration information into a black box. Therefore, there is an urgent need for a more efficient platform that supports configuration of real-time computing jobs.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="04-difficulty-in-job-development-and-debugging"><strong>04 Difficulty in Job Development and Debugging</strong><a href="#04-difficulty-in-job-development-and-debugging" class="hash-link" aria-label="Direct link to 04-difficulty-in-job-development-and-debugging" title="Direct link to 04-difficulty-in-job-development-and-debugging">​</a></h3><p>In our previous development process, we typically embedded SQL code within program code in the local IDEA environment for job development and debugging, verifying the correctness of the program. However, this approach has several disadvantages:</p><ol><li><p>Difficulty in multi-data source debugging. Often, a requirement involves multiple different data sources. For local environment debugging, developers need to apply for white-list access to data, which is both time-consuming and cumbersome.</p></li><li><p>SQL code is hard to read and modify. As SQL code is embedded in program code, it's difficult to read and inconvenient to modify. More challenging is debugging through SQL segments, as the lack of SQL version control and syntax verification makes it hard for developers to locate specific SQL lines in client logs to identify the cause of execution failure.</p></li></ol><p>Therefore, there is a need to improve the efficiency of development and debugging.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="the-journey-to-the-solution"><strong>The Journey to the Solution</strong><a href="#the-journey-to-the-solution" class="hash-link" aria-label="Direct link to the-journey-to-the-solution" title="Direct link to the-journey-to-the-solution">​</a></h2><p>In the early stages of platform construction, we comprehensively surveyed almost all relevant projects in the industry, covering both commercial paid versions and open-source versions, starting from early 2022. After investigation and comparison, we found that these projects have their limitations to varying extents, and their usability and stability could not be effectively guaranteed.</p><p>Overall, StreamPark performed best in our evaluation. It was the only project without major flaws and with strong extensibility: supporting both SQL and JAR jobs, with the most complete and stable deployment mode for Flink jobs. Its unique architectural design not only avoids locking in specific Flink versions but also supports convenient version switching and parallel processing, effectively solving job dependency isolation and conflict issues. The job management &amp; operations capabilities we focused on were also very complete, including monitoring, alerts, SQL validation, SQL version comparison, CI, etc. StreamPark's support for Flink on K8s was the most comprehensive among all the open-source projects we surveyed. However, StreamPark's K8s mode submission required local image building, leading to storage resource consumption.</p><p>In the latest 2.2 version, the community has already restructured this part.</p><p>After analyzing the pros and cons of many open-source projects, we decided to participate in projects with excellent architecture, development potential, and an actively dedicated core team. Based on this understanding, we made the following decisions:</p><ol><li><p>In terms of job deployment mode, we decided to adopt the On Kubernetes mode. Real-time jobs have dynamic resource consumption, creating a strong need for Kubernetes' elastic scaling, which helps us better cope with data output fluctuations and ensure job stability.</p></li><li><p>In the selection of open-source components, after comprehensive comparison and evaluation of various indicators, we finally chose what was then StreamX. Subsequent close communication with the community allowed us to deeply appreciate the serious and responsible attitude of the founders and the united and friendly atmosphere of the community. We also witnessed the project's inclusion in the Apache Incubator in September 2022, making us hopeful for its future.</p></li><li><p>On the basis of StreamPark, we aim to promote integration with the existing ecosystem of the company to better meet our business needs.</p></li></ol><h2 class="anchor anchorWithStickyNavbar_LWe7" id="in-depth-practice-based-on-streampark"><strong>In-depth Practice Based on StreamPark</strong><a href="#in-depth-practice-based-on-streampark" class="hash-link" aria-label="Direct link to in-depth-practice-based-on-streampark" title="Direct link to in-depth-practice-based-on-streampark">​</a></h2><p>Based on the above decisions, we initiated the evolution of the real-time computing platform, oriented by "pain point needs," and built a stable, efficient, and easy-to-maintain real-time computing platform based on StreamPark. Since the beginning of 2022, we have participated in the construction of the community while officially scheduling our internal platform construction.</p><p>First, we further improved related functionalities on the basis of StreamPark:</p><p><img loading="lazy" src="/assets/images/platform_construction-b73e12b57a4a9f558ada77038496bf50.png" width="1080" height="522" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="01-ldap-login-support"><strong>01 LDAP Login Support</strong><a href="#01-ldap-login-support" class="hash-link" aria-label="Direct link to 01-ldap-login-support" title="Direct link to 01-ldap-login-support">​</a></h3><p>On the basis of StreamPark, we further improved related functionalities, including support for LDAP, so that in the future we can fully open up real-time capabilities, allowing analysts from the company's four business lines to use the platform, expected to reach about 170 people. With the increase in numbers, account management becomes increasingly important, especially in the case of personnel changes, account cancellation, and application become frequent and time-consuming operations. Therefore, integrating LDAP becomes particularly important. We communicated with the community in a timely manner and initiated a discussion, eventually contributing this Feature. Now, starting LDAP in StreamPark has become very simple, requiring just two steps:</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="step1-fill-in-the-corresponding-ldap">step1: Fill in the corresponding LDAP<a href="#step1-fill-in-the-corresponding-ldap" class="hash-link" aria-label="Direct link to step1: Fill in the corresponding LDAP" title="Direct link to step1: Fill in the corresponding LDAP">​</a></h4><p>configuration:</p><p>Edit the application.yml file, setting the LDAP basic information as follows:</p><div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token key atrule">ldap</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token comment" style="color:rgb(98, 114, 164)"># Is ldap enabled?</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">enable</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token boolean important">false</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token comment" style="color:rgb(98, 114, 164)">## AD server IP, default port 389</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">urls</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> ldap</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain">//99.99.99.99</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token number">389</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token comment" style="color:rgb(98, 114, 164)">## Login Account</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">base-dn</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> dc=streampark</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">dc=com</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">username</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> cn=Manager</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">dc=streampark</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">dc=com</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">password</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> streampark</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">user</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">identity-attribute</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> uid</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token key atrule">email-attribute</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> mail</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h4 class="anchor anchorWithStickyNavbar_LWe7" id="step2-ldap-login">step2: LDAP Login<a href="#step2-ldap-login" class="hash-link" aria-label="Direct link to step2: LDAP Login" title="Direct link to step2: LDAP Login">​</a></h4><p>On the login interface, click LDAP login method, then enter the corresponding account and password, and click to log in.</p><p><img loading="lazy" src="/assets/images/ldap-39a8f66b7bba105117ecbfc54551dc95.png" width="1080" height="581" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="02-automatic-ingress-generation-for-job-submission"><strong>02 Automatic Ingress Generation for Job Submission</strong><a href="#02-automatic-ingress-generation-for-job-submission" class="hash-link" aria-label="Direct link to 02-automatic-ingress-generation-for-job-submission" title="Direct link to 02-automatic-ingress-generation-for-job-submission">​</a></h3><p>Due to the company's network security policy, only port 80 is opened on the Kubernetes host machines by the operation team, making it impossible to directly access the job WebUI on Kubernetes via "domain + random port." To solve this problem, we needed to use Ingress to add a proxy layer to the access path, achieving the effect of access routing. In StreamPark version 2.0, we contributed the functionality related to Ingress <!-- -->[3]<!-- -->. We adopted a strategy pattern implementation, initially obtaining Kubernetes metadata information to identify its version and accordingly constructing respective objects, ensuring smooth use of the Ingress function across various Kubernetes environments.</p><p>The specific configuration steps are as follows:</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="step1-click-to-enter-setting--choose-ingress-setting-fill-in-the-domain-name">step1: Click to enter Setting-&gt; Choose Ingress Setting, fill in the domain name<a href="#step1-click-to-enter-setting--choose-ingress-setting-fill-in-the-domain-name" class="hash-link" aria-label="Direct link to step1: Click to enter Setting-> Choose Ingress Setting, fill in the domain name" title="Direct link to step1: Click to enter Setting-> Choose Ingress Setting, fill in the domain name">​</a></h4><p><img loading="lazy" src="/assets/images/ingress_setting-2b8e1403aae4ff708a05f61f87d34733.png" width="1080" height="384" class="img_ev3q"></p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="step2-submit-a-job">step2: Submit a job<a href="#step2-submit-a-job" class="hash-link" aria-label="Direct link to step2: Submit a job" title="Direct link to step2: Submit a job">​</a></h4><p><img loading="lazy" src="/assets/images/k8s_job-1759da059df126162f2b7e0c7b9b121a.png" width="1080" height="367" class="img_ev3q"></p><p>Upon entering the K8s management platform, you can observe that submitting a Flink job also corresponds to submitting an Ingress with the same name.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="step3-click-to-enter-flinks-webui">step3: Click to enter Flink's WebUI<a href="#step3-click-to-enter-flinks-webui" class="hash-link" aria-label="Direct link to step3: Click to enter Flink's WebUI" title="Direct link to step3: Click to enter Flink's WebUI">​</a></h4><p>You will notice that the generated address consists of three parts: domain + job submission namespace + job name.</p><p><img loading="lazy" src="/assets/images/flink_webui-ca719f066a60a19004af7d6761eae27d.png" width="1080" height="451" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="03-support-for-viewing-job-deployment-logs"><strong>03 Support for Viewing Job Deployment Logs</strong><a href="#03-support-for-viewing-job-deployment-logs" class="hash-link" aria-label="Direct link to 03-support-for-viewing-job-deployment-logs" title="Direct link to 03-support-for-viewing-job-deployment-logs">​</a></h3><p>In the process of continuous job deployment, we gradually realized that without logs, we cannot perform effective operations. Log retention, archiving, and viewing became an important part in our later problem-solving process. Therefore, in StreamPark version 2.0, we contributed the ability to archive startup logs in On Kubernetes mode and view them on the page <!-- -->[4]<!-- -->. Now, by clicking the log viewing button in the job list, it is very convenient to view the real-time logs of the job.</p><p><img loading="lazy" src="/assets/images/k8s_log-aafb7f2dff97d584b187ab4a22de9eaf.png" width="1080" height="473" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="04-integration-of-grafana-monitoring-chart-links"><strong>04 Integration of Grafana Monitoring Chart Links</strong><a href="#04-integration-of-grafana-monitoring-chart-links" class="hash-link" aria-label="Direct link to 04-integration-of-grafana-monitoring-chart-links" title="Direct link to 04-integration-of-grafana-monitoring-chart-links">​</a></h3><p>In actual use, as the number of jobs increased, the number of users rose, and more departments were involved, we faced the problem of difficulty in self-troubleshooting. Our team's operational capabilities are actually very limited. Due to the difference in professional fields, when we tell users to view charts and logs on Grafana and ELK, users often feel at a loss and do not know how to find information related to their jobs.</p><p>To solve this problem, we proposed a demand in the community: we hoped that each job could directly jump to the corresponding monitoring chart and log archive page through a hyperlink, so that users could directly view the monitoring information and logs related to their jobs. This avoids tedious searches in complex system interfaces, thus improving the efficiency of troubleshooting.</p><p>We had a discussion in the community, and it was quickly responded to, as everyone thought it was a common need. Soon, a developer contributed a design and related PR, and the issue was quickly resolved. Now, to enable this feature in StreamPark has become very simple:</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="step1-create-a-badge-label">step1: Create a badge label<a href="#step1-create-a-badge-label" class="hash-link" aria-label="Direct link to step1: Create a badge label" title="Direct link to step1: Create a badge label">​</a></h4><p><img loading="lazy" src="/assets/images/create_badge_label-a6542822bd5a1e9274ca0017d25a9ccd.png" width="1080" height="649" class="img_ev3q"></p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="step2-associate-the-badge-label-with-a-redirect-link">step2: Associate the badge label with a redirect link<a href="#step2-associate-the-badge-label-with-a-redirect-link" class="hash-link" aria-label="Direct link to step2: Associate the badge label with a redirect link" title="Direct link to step2: Associate the badge label with a redirect link">​</a></h4><p><img loading="lazy" src="/assets/images/relevancy-a1914717d6479d16e07f7f1e6193f409.png" width="1062" height="400" class="img_ev3q"></p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="step3-click-the-badge-label-for-link-redirection">step3: Click the badge label for link redirection<a href="#step3-click-the-badge-label-for-link-redirection" class="hash-link" aria-label="Direct link to step3: Click the badge label for link redirection" title="Direct link to step3: Click the badge label for link redirection">​</a></h4><p><img loading="lazy" src="/assets/images/link_jump-f353a479fac3e5576056edcaab705dda.png" width="1080" height="381" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="05-integration-of-flink-sql-security-for-permission-control"><strong>05 Integration of Flink SQL Security for Permission Control</strong><a href="#05-integration-of-flink-sql-security-for-permission-control" class="hash-link" aria-label="Direct link to 05-integration-of-flink-sql-security-for-permission-control" title="Direct link to 05-integration-of-flink-sql-security-for-permission-control">​</a></h3><p>In our system, lineage management is based on Apache Atlas, and permission management is based on the open-source project Flink-sql-security, which supports user-level data desensitization and row-level data access control, allowing specific users to only access desensitized data or authorized rows.</p><p>This design is to handle some complex inheritance logic. For example, when joining encrypted field age in Table A with Table B to obtain Table C, the age field in Table C should inherit the encryption logic of Table A to ensure the encryption status of data is not lost during processing. This way, we can better protect data security and ensure that data complies with security standards throughout the processing process.</p><p>For permission control, we developed a Flink-sql-security-streampark plugin based on Flink-s</p><p>ql-security. The basic implementation is as follows:</p><ol><li><p>During submission check, the system parses the submitted SQL, obtaining InputTable and OutputTable datasets.</p></li><li><p>The system queries the remote permission service to obtain the user's bound RBAC (Role-Based Access Control) permissions.</p></li><li><p>Based on the RBAC permissions, the system gets the encryption rules for the corresponding tables.</p></li><li><p>The system rewrites the SQL, wrapping the original SQL query fields with a preset encryption algorithm, thereby reorganizing the logic.</p></li><li><p>Finally, the system submits according to the reorganized logic.</p></li></ol><p>Through this integration and plugin development, we implemented permission control for user query requests, thereby ensuring data security.</p><p><strong>01 Row-level Permission Conditions</strong></p><p><img loading="lazy" src="/assets/images/row_level_permissions-cd7665f926dd3c92e8479be34f9084d5.png" width="1080" height="348" class="img_ev3q"></p><p><img loading="lazy" src="/assets/images/row_level_permissions_table-780239498d6b6d09c8a5c1ffe4ad44ef.png" width="1080" height="151" class="img_ev3q"></p><p>Input SQL</p><div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">SELECT * FROM orders</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>User A's actual execution SQL:</p><div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">SELECT * FROM orders WHERE region </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'beijing'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>User B's actual execution SQL:</p><div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">SELECT * FROM orders WHERE region </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">'hangzhou'</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><strong>02 Field Desensitization Conditions</strong></p><p><img loading="lazy" src="/assets/images/field_desensitization-3005c6f1d9c2f7ad0530d09a5a9aecea.png" width="1080" height="269" class="img_ev3q"></p><p><img loading="lazy" src="/assets/images/field_desensitization_table-e200cbbf0081e2d416411659a188bb90.png" width="1080" height="160" class="img_ev3q"></p><p>Input SQL</p><div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">SELECT name, age, price, phone FROM user</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Execution SQL:</p><p>User A's actual execution SQL:</p><div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">SELECT Encryption_function</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">name</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain">, age, price, Sensitive_field_functions</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">phone</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> FROM user</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>User B's actual execution SQL:</p><div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">SELECT name, Encryption_function</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">age</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain">, price, Sensitive_field_functions</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">phone</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> FROM user</span><span class="token punctuation" style="color:rgb(248, 248, 242)">;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="06-data-synchronization-platform-based-on-streampark"><strong>06 Data Synchronization Platform Based on StreamPark</strong><a href="#06-data-synchronization-platform-based-on-streampark" class="hash-link" aria-label="Direct link to 06-data-synchronization-platform-based-on-streampark" title="Direct link to 06-data-synchronization-platform-based-on-streampark">​</a></h3><p>With the successful implementation of StreamPark's technical solutions in the company, we achieved deep support for Flink jobs, bringing a qualitative leap in data processing. This prompted us to completely revamp our past data synchronization logic, aiming to reduce operational costs through technical optimization and integration. Therefore, we gradually replaced historical Sqoop jobs, Canal jobs, and Hive JDBC Handler jobs with Flink CDC jobs, Flink stream, and batch jobs. In this process, we continued to optimize and strengthen StreamPark's interface capabilities, adding a status callback mechanism and achieving perfect integration with the DolphinScheduler <!-- -->[7]<!-- --> scheduling system, further enhancing our data processing capabilities.</p><p>External system integration with StreamPark is simple, requiring only a few steps:</p><ol><li>First, create a token for API access:</li></ol><p><img loading="lazy" src="/assets/images/token-94cb364497fe129fc62be3bbb7193390.png" width="1080" height="288" class="img_ev3q"></p><ol start="2"><li>View the external call link of the Application:</li></ol><p><img loading="lazy" src="/assets/images/call_link-da9d24e3a1993590cf25da174d5fb676.png" width="1080" height="390" class="img_ev3q"></p><div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token function" style="color:rgb(80, 250, 123)">curl</span><span class="token plain"> -X POST </span><span class="token string" style="color:rgb(255, 121, 198)">'/flink/app/start'</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">-H </span><span class="token string" style="color:rgb(255, 121, 198)">'Authorization: $token'</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">-H </span><span class="token string" style="color:rgb(255, 121, 198)">'Content-Type: application/x-www-form-urlencoded; charset=UTF-8'</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">--data-urlencode </span><span class="token string" style="color:rgb(255, 121, 198)">'savePoint='</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">--data-urlencode </span><span class="token string" style="color:rgb(255, 121, 198)">'allowNonRestored=false'</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">--data-urlencode </span><span class="token string" style="color:rgb(255, 121, 198)">'savePointed=false'</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">\</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">--data-urlencode </span><span class="token string" style="color:rgb(255, 121, 198)">'id=100501'</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ol start="3"><li>Configure Http scheduling in DolphinScheduler</li></ol><p><img loading="lazy" src="/assets/images/http_scheduling-267e8ae0aa04d5901cd98bea50370d69.png" width="1080" height="576" class="img_ev3q"></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="summary-of-practical-experience"><strong>Summary of Practical Experience</strong><a href="#summary-of-practical-experience" class="hash-link" aria-label="Direct link to summary-of-practical-experience" title="Direct link to summary-of-practical-experience">​</a></h2><p>During our in-depth use of StreamPark, we summarized some common issues and explored solutions in the practice process, which we have compiled into examples for reference.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="01-building-base-images"><strong>01 Building Base Images</strong><a href="#01-building-base-images" class="hash-link" aria-label="Direct link to 01-building-base-images" title="Direct link to 01-building-base-images">​</a></h3><p>To deploy a Flink job on Kubernetes using StreamPark, you first need to prepare a Base image built on Flink. Then, on the Kubernetes platform, the user-provided image is used to start the Flink job. If we continue to use the official "bare image," it is far from sufficient for actual development. Business logic developed by users often involves multiple upstream and downstream data sources, requiring related data source Connectors and dependencies like Hadoop. Therefore, these dependencies need to be included in the image. Below, I will introduce the specific operation steps.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="step1-first-create-a-folder-containing-two-folders-and-a-dockerfile-file">step1: First, create a folder containing two folders and a Dockerfile file<a href="#step1-first-create-a-folder-containing-two-folders-and-a-dockerfile-file" class="hash-link" aria-label="Direct link to step1: First, create a folder containing two folders and a Dockerfile file" title="Direct link to step1: First, create a folder containing two folders and a Dockerfile file">​</a></h4><p><img loading="lazy" src="data:image/png;base64,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" width="796" height="166" class="img_ev3q"></p><p>conf folder: Contains HDFS configuration files, mainly for configuring Flink's Checkpoint writing and using Hive metadata in FlinkSQL</p><p><img loading="lazy" src="/assets/images/hdfs_conf-8af6d1660d09b58fc28a6fec1bff604b.png" width="824" height="284" class="img_ev3q"></p><p>lib folder: Contains the related Jar dependency packages, as follows:</p><p><img loading="lazy" src="/assets/images/lib-faa76eddded5bdcb4228bf65c2d3122d.png" width="842" height="722" class="img_ev3q"></p><p>Dockerfile file for defining image construction</p><div class="language-dockerfile codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-dockerfile codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">FROM apache/flink:1.14.5-scala_2.11-java8</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">ENV TIME_ZONE=Asia/Shanghai</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">COPY ./conf /opt/hadoop/conf</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">COPY lib $FLINK_HOME/lib/</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h4 class="anchor anchorWithStickyNavbar_LWe7" id="step2-image-build-command-using-multi-architecture-build-mode-as-follows">step2: Image build command using multi-architecture build mode, as follows:<a href="#step2-image-build-command-using-multi-architecture-build-mode-as-follows" class="hash-link" aria-label="Direct link to step2: Image build command using multi-architecture build mode, as follows:" title="Direct link to step2: Image build command using multi-architecture build mode, as follows:">​</a></h4><div class="language-dockerfile codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-dockerfile codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">docker buildx build --push --platform linux/amd64 -t ${private image repository address}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="02-base-image-integration-with-arthas-example"><strong>02 Base Image Integration with Arthas Example</strong><a href="#02-base-image-integration-with-arthas-example" class="hash-link" aria-label="Direct link to 02-base-image-integration-with-arthas-example" title="Direct link to 02-base-image-integration-with-arthas-example">​</a></h3><p>As more jobs are released and go live within our company, we often encounter performance degradation in long-running jobs, such as reduced Kafka consumption capacity, increased memory usage, and extended GC time. We recommend using Arthas, an open-source Java diagnostic tool by Alibaba. It allows real-time global viewing of Java application load, memory, GC, thread status, and without modifying application code, it enables viewing method call parameters, exceptions, monitoring method execution time, class loading information, etc., greatly enhancing our efficiency in troubleshooting online issues.</p><p><img loading="lazy" src="/assets/images/arthas-31f8df2a167d53420d2b4a828003a449.png" width="1080" height="526" class="img_ev3q"></p><p><img loading="lazy" src="/assets/images/advanced-e5c462ae9a888deddb5939a7c8065732.png" width="1080" height="416" class="img_ev3q"></p><p><img loading="lazy" src="/assets/images/arthas_log-fbc7dc0891690e569c6ad63359fc52fd.png" width="1080" height="390" class="img_ev3q"></p><p>Therefore, we integrated Arthas into the base image to facilitate runtime problem troubleshooting.</p><div class="language-dockerfile codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-dockerfile codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">FROM apache/flink:1.14.5-scala_2.11-java8</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">ENV TIME_ZONE=Asia/Shanghai</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">COPY ./conf /opt/hadoop/conf</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">COPY lib $FLINK_HOME/lib/</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">RUN apt-get update --fix-missing &amp;&amp; apt-get install -y fontconfig --fix-missing &amp;&amp; \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    apt-get install -y openjdk-8-jdk &amp;&amp; \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    apt-get install -y ant &amp;&amp; \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    apt-get clean;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">RUN apt-get install sudo -y</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Fix certificate issues</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">RUN apt-get update &amp;&amp; \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    apt-get install ca-certificates-java &amp;&amp; \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    apt-get clean &amp;&amp; \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    update-ca-certificates -f;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Setup JAVA_HOME -- useful for docker commandline</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">ENV JAVA_HOME /usr/lib/jvm/java-8-openjdk-amd64/</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">RUN export JAVA_HOME</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">RUN apt-get install -y unzip</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">RUN curl -Lo arthas-packaging-latest-bin.zip  'https://arthas.aliyun.com/download/latest_version?mirror=aliyun'</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">RUN unzip -d arthas-latest-bin arthas-packaging-latest-bin.zip</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="03-resolution-of-dependency-conflicts-in-images"><strong>03 Resolution of Dependency Conflicts in Images</strong><a href="#03-resolution-of-dependency-conflicts-in-images" class="hash-link" aria-label="Direct link to 03-resolution-of-dependency-conflicts-in-images" title="Direct link to 03-resolution-of-dependency-conflicts-in-images">​</a></h3><p>In the process of using StreamPark, we often encounter dependency conflict exceptions like NoClassDefFoundError, ClassNotFoundException, and NoSuchMethodError in Flink jobs running on base images. The troubleshooting approach is to find the package path of the conflicting class indicated in the error. For example, if the error class is in org.apache.orc:orc-core, go to the corresponding module directory, run <code>mvn dependency::tree</code>, search for orc-core, see who brought in the dependency, and remove it using exclusion. Below, I will introduce in detail a method of custom packaging to resolve dependency conflicts, illustrated by a dependency conflict caused by the flink-shaded-hadoop-3-uber JAR package in a base image.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="step1-clone-the-flink-shaded-project-locally">step1: Clone the flink-shaded project locally👇<a href="#step1-clone-the-flink-shaded-project-locally" class="hash-link" aria-label="Direct link to step1: Clone the flink-shaded project locally👇" title="Direct link to step1: Clone the flink-shaded project locally👇">​</a></h4><div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token function" style="color:rgb(80, 250, 123)">git</span><span class="token plain"> clone https://github.com/apache/flink-shaded.git</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><img loading="lazy" src="/assets/images/flink_shaded-f21909c81059b2ea4ebd8307998cbc26.png" width="1080" height="529" class="img_ev3q"></p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="step2-load-the-project-into-idea">step2: Load the project into IDEA<a href="#step2-load-the-project-into-idea" class="hash-link" aria-label="Direct link to step2: Load the project into IDEA" title="Direct link to step2: Load the project into IDEA">​</a></h4><p><img loading="lazy" src="/assets/images/idea-d654040d5fad6fefd756ede9a9ac8a4b.png" width="1080" height="586" class="img_ev3q"></p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="step3-exclude-the-conflicting-parts-and-then-package-them">step3: Exclude the conflicting parts and then package them.<a href="#step3-exclude-the-conflicting-parts-and-then-package-them" class="hash-link" aria-label="Direct link to step3: Exclude the conflicting parts and then package them." title="Direct link to step3: Exclude the conflicting parts and then package them.">​</a></h4><h3 class="anchor anchorWithStickyNavbar_LWe7" id="04-centralized-job-configuration-example"><strong>04 Centralized Job Configuration Example</strong><a href="#04-centralized-job-configuration-example" class="hash-link" aria-label="Direct link to 04-centralized-job-configuration-example" title="Direct link to 04-centralized-job-configuration-example">​</a></h3><p>One of the great conveniences of using StreamPark is centralized configuration management. You can configure all settings in the conf file in the Flink directory bound to the platform.</p><div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token builtin class-name" style="color:rgb(189, 147, 249)">cd</span><span class="token plain"> /flink-1.14.5/conf</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token function" style="color:rgb(80, 250, 123)">vim</span><span class="token plain"> flink-conf.yaml</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><img loading="lazy" src="/assets/images/conf-ff77bc47a1f6af137a3326cc05cfdfee.png" width="1080" height="562" class="img_ev3q"></p><p>After completing the configuration, save it. Then go to the platform's Setting, and click on the Flink Conf icon.</p><p><img loading="lazy" src="/assets/images/flink_conf-db4fdbcbac08f9e19eaf550c1332de25.png" width="1080" height="351" class="img_ev3q"></p><p>Clicking Sync Conf will synchronize the global configuration file, and new jobs will be submitted with the new configuration.</p><p><img loading="lazy" src="/assets/images/sync_conf-9d2b45b6f42376859fda062127e33d82.png" width="1080" height="485" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="05-streampark-dns-resolution-configuration"><strong>05 StreamPark DNS Resolution Configuration</strong><a href="#05-streampark-dns-resolution-configuration" class="hash-link" aria-label="Direct link to 05-streampark-dns-resolution-configuration" title="Direct link to 05-streampark-dns-resolution-configuration">​</a></h3><p>A correct and reasonable DNS resolution configuration is very important when submitting FlinkSQL on the StreamPark platform. It mainly involves the following points:</p><ol><li><p>Flink jobs' Checkpoint writing to HDFS requires a snapshot write to an HDFS node obtained through ResourceManager. If there are expansions in the Hadoop cluster in the enterprise, and these new nodes are not covered by the DNS resolution service, this will directly lead to Checkpoint failure, affecting online stability.</p></li><li><p>Flink jobs typically need to configure connection strings for different internal data sources. Configuring the database's real IP address often leads to job exits due to IP changes during database migration. Therefore, in production, connection strings are often composed of domain names and attribute parameters, with DNS services resolving them to real IP addresses for access.</p></li></ol><p>Initially, we maintained DNS configuration through Pod Template.</p><div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">apiVersion: v1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">kind: Pod</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">metadata:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  name: pod-template</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">spec:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  hostAliases:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    - ip: </span><span class="token number">10.216</span><span class="token plain">.xxx.79</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      hostnames:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        - handoop1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    - </span><span class="token function" style="color:rgb(80, 250, 123)">host</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">names:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        - handoop2</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      ip: </span><span class="token number">10.16</span><span class="token plain">.xx.48</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    - hostnames:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        - handoop3</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      ip: </span><span class="token number">10.16</span><span class="token plain">.xx.49</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    - hostnames:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        - handoop4</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">      ip: </span><span class="token number">10.16</span><span class="token plain">.xx.50</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">   </span><span class="token punctuation" style="color:rgb(248, 248, 242)">..</span><span class="token punctuation" style="color:rgb(248, 248, 242)">..</span><span class="token punctuation" style="color:rgb(248, 248, 242)">..</span><span class="token plain">.</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Although theoretically feasible, we encountered a series of problems in practice. When expanding HDFS, we found failures in Flink's Checkpoint function, and database migration also faced connection failures, causing sudden online service outages. After in-depth investigation, we found that the root cause was in DNS resolution.</p><p>Previously, we used hostAliases to maintain the mapping between domain names and IP addresses. However, this method was costly in practice, as every update of hostAliases required stopping all Flink jobs, undoubtedly increasing our operational costs. To seek a more flexible and reliable method to manage DNS resolution configuration and ensure the normal operation of Flink jobs, we decided to build dnsmasq for bidirectional DNS resolution.</p><p>After configuring and installing dnsmasq, we first needed to override the resolv.conf configuration file in the /etc directory of the Flink image. However, since resolv.conf is a read-only file, if we want to override it, we need to use mounting. Therefore, we first configured resolv.conf as a ConfigMap for use during the override. This way, we can more flexibly and reliably manage DNS resolution configuration, ensuring stable operation of Flink jobs.</p><div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token key atrule">apiVersion</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> v1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">data</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">resolv.conf</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> "nameserver  10.216.138.226" //DNS service</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">kind</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> ConfigMap</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token key atrule">metadata</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">creationTimestamp</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"2022-07-13T10:16:18Z"</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">managedFields</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">name</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> dns</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">configmap</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">  </span><span class="token key atrule">namespace</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> native</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">flink</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Mounting it through Pod Template.</p><p><img loading="lazy" src="/assets/images/pod_template-d8a9864bc8486d493025cc5e8b0e6dd1.png" width="1080" height="476" class="img_ev3q"></p><p>This way, DNS related to the big data platform can be maintained on dnsmasq, while the host machine running Flink jobs can follow the DNS resolution process.</p><ol><li><p>First, check the local hosts file to see if there is a corresponding relationship, read the record for resolution, and proceed to the next step if not.</p></li><li><p>The operating system checks the local DNS cache, and if not found, moves to the next step.</p></li><li><p>The operating system searches the DNS server address defined in our network configuration.</p></li></ol><p>This achieves dynamic recognition of DNS changes.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="06-multi-instance-deployment-practice"><strong>06 Multi-Instance Deployment Practice</strong><a href="#06-multi-instance-deployment-practice" class="hash-link" aria-label="Direct link to 06-multi-instance-deployment-practice" title="Direct link to 06-multi-instance-deployment-practice">​</a></h3><p>In actual production environments, we often need to operate multiple clusters, including a set for testing and a set for official online use. Tasks are first verified and performance tested in the test cluster, then released to the official online cluster after ensuring accuracy.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="step1-modify-the-port-number-to-avoid-conflicts-between-multiple-service-ports">step1: Modify the port number to avoid conflicts between multiple service ports<a href="#step1-modify-the-port-number-to-avoid-conflicts-between-multiple-service-ports" class="hash-link" aria-label="Direct link to step1: Modify the port number to avoid conflicts between multiple service ports" title="Direct link to step1: Modify the port number to avoid conflicts between multiple service ports">​</a></h4><p><img loading="lazy" src="/assets/images/port_number-e421801c946def0b0e2df3747239fec6.png" width="1080" height="622" class="img_ev3q"></p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="step2-modify-workspace">step2: Modify workspace<a href="#step2-modify-workspace" class="hash-link" aria-label="Direct link to step2: Modify workspace" title="Direct link to step2: Modify workspace">​</a></h4><p>Different instance services need to configure different workspaces to avoid resource interference leading to strange bugs.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="step3-launch-multi-instance-services">step3: Launch multi-instance services<a href="#step3-launch-multi-instance-services" class="hash-link" aria-label="Direct link to step3: Launch multi-instance services" title="Direct link to step3: Launch multi-instance services">​</a></h4><p>To achieve isolation between production and testing environments, we introduced a key step at the beginning of the startup process. We input the command (for the Hadoop B cluster):</p><div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token builtin class-name" style="color:rgb(189, 147, 249)">export</span><span class="token plain"> </span><span class="token assign-left variable" style="color:rgb(189, 147, 249);font-style:italic">HADOOP_CONF_DIR</span><span class="token operator">=</span><span class="token plain">/home/streamx/conf</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>This effectively cut off the default logic of Flink on K8s loading HDFS configuration. This operation ensures that A StreamPark only connects to A Hadoop environment, while B StreamPark connects to B Hadoop environment, thus achieving complete isolation between testing and production environments.</p><p>Specifically, after this command takes effect, we can ensure that Flink jobs submitted on port 10002 connect to the B Hadoop environment. Thus, the B Hadoop environment is isolated from the Hadoop environment used by Flink jobs submitted on port 10000 in the past, effectively preventing interference between different environments and ensuring system stability and reliability.</p><p>The following content is an analysis of Flink's logic for loading the Hadoop environment:</p><div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">// Process of finding Hadoop configuration files</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">//1. First</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> check if the parameter kubernetes.hadoop.conf.config</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">map.name is added</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">@Override</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">public Optional&lt;String</span><span class="token punctuation" style="color:rgb(248, 248, 242)">&gt;</span><span class="token plain"> get</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">ExistingHadoopConfigurationConfigMap() </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    final String existingHadoopConfigMap =</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            flinkConfig.getString(KubernetesConfigOptions.HADOOP_CONF_CONFIG_MAP);</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if (StringUtils.isBlank(existingHadoopConfigMap)) </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return Optional.empty();</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"> else </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return Optional.of(existingHadoopConfigMap.trim());</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">@Override</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">public Optional&lt;String</span><span class="token punctuation" style="color:rgb(248, 248, 242)">&gt;</span><span class="token plain"> getLocalHadoopConfigurationDirectory() </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    // 2. If parameter 1 is not specified</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> check for the HADOOP_CONF_DIR environment variable in the local environment where the native command is submitted</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    final String hadoopConfDirEnv = System.getenv(Constants.ENV_HADOOP_CONF_DIR);</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if (StringUtils.isNotBlank(hadoopConfDirEnv)) </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return Optional.of(hadoopConfDirEnv);</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    // 3. If environment variable 2 is not present</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> continue to check for the HADOOP_HOME environment variable</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    final String hadoopHomeEnv = System.getenv(Constants.ENV_HADOOP_HOME);</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if (StringUtils.isNotBlank(hadoopHomeEnv)) </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        // Hadoop 2.2+</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        final File hadoop2ConfDir = new File(hadoopHomeEnv</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> "/etc/hadoop");</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if (hadoop2ConfDir.exists()) </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            return Optional.of(hadoop2ConfDir.getAbsolutePath());</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        // Hadoop 1.x</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        final File hadoop1ConfDir = a new File(hadoopHomeEnv</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> "/conf");</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        if (hadoop1ConfDir.exists()) </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            return Optional.of(hadoop1ConfDir.getAbsolutePath());</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return Optional.empty();</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">final List&lt;File</span><span class="token punctuation" style="color:rgb(248, 248, 242)">&gt;</span><span class="token plain"> hadoopConfigurationFileItems = getHadoopConfigurationFileItems(localHadoopConfigurationDirectory.get());</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">// If 1</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> </span><span class="token number">2</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> 3 are not found</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> it means there is no Hadoop environment</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">if (hadoopConfigurationFileItems.isEmpty()) </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    LOG.warn(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            "Found 0 files in directory </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> skip to mount the Hadoop Configuration ConfigMap."</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">            localHadoopConfigurationDirectory.get());</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return flinkPod;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">// If 2 or 3 exists</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> it will look for core</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">site.xml and hdfs</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">site.xml files in the path</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">private List&lt;File</span><span class="token punctuation" style="color:rgb(248, 248, 242)">&gt;</span><span class="token plain"> getHadoopConfigurationFileItems(String localHadoopConfigurationDirectory) </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    final List&lt;String</span><span class="token punctuation" style="color:rgb(248, 248, 242)">&gt;</span><span class="token plain"> expectedFileNames = new ArrayList&lt;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">&gt;</span><span class="token plain">();</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    expectedFileNames.add("core</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">site.xml");</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    expectedFileNames.add("hdfs</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">site.xml");</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    final File directory = new File(localHadoopConfigurationDirectory);</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    if (directory.exists() and directory.isDirectory()) </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return Arrays.stream(directory.listFiles())</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                .filter(</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                        file </span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token punctuation" style="color:rgb(248, 248, 242)">&gt;</span><span class="token scalar string" style="color:rgb(255, 121, 198)"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token scalar string" style="color:rgb(255, 121, 198)">                                file.isFile()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token scalar string" style="color:rgb(255, 121, 198)">                                        and expectedFileNames.stream()</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token scalar string" style="color:rgb(255, 121, 198)">                                                .anyMatch(name -&gt; file.getName().equals(name)))</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">                .collect(Collectors.toList());</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"> else </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">        return Collections.emptyList();</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">// If a Hadoop environment is present</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> the above two files will be parsed as key</span><span class="token punctuation" style="color:rgb(248, 248, 242)">-</span><span class="token plain">value pairs</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> and then constructed into a ConfigMap</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> with the name following this naming rule</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">public static String getHadoopConfConfigMapName(String clusterId) </span><span class="token punctuation" style="color:rgb(248, 248, 242)">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    return Constants.HADOOP_CONF_CONFIG_MAP_PREFIX + clusterId;</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Then conduct process port occupancy queries:</p><div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token function" style="color:rgb(80, 250, 123)">netstat</span><span class="token plain"> -tlnp </span><span class="token operator">|</span><span class="token plain"> </span><span class="token function" style="color:rgb(80, 250, 123)">grep</span><span class="token plain"> </span><span class="token number">10000</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token function" style="color:rgb(80, 250, 123)">netstat</span><span class="token plain"> -tlnp </span><span class="token operator">|</span><span class="token plain"> </span><span class="token function" style="color:rgb(80, 250, 123)">grep</span><span class="token plain"> </span><span class="token number">10002</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="benefits-brought"><strong>Benefits Brought</strong><a href="#benefits-brought" class="hash-link" aria-label="Direct link to benefits-brought" title="Direct link to benefits-brought">​</a></h2><p>Our team has been using StreamX (the predecessor of StreamPark) and, after more than a year of practice and refinement, StreamPark has significantly improved our challenges in developing, managing, and operating Apache Flink jobs. As a one-stop service platform, StreamPark greatly simplifies the entire development process. Now, we can complete job development, compilation, and release directly on the StreamPark platform, not only lowering the management and deployment threshold of Flink but also significantly improving development efficiency.</p><p>Since deploying StreamPark, we have been using the platform on a large scale in a production environment. From initially managing over 50 FlinkSQL jobs to nearly 500 jobs now, as shown in the diagram, StreamPark is divided into 7 teams, each with dozens of jobs. This transformation not only demonstrates StreamPark's scalability and efficiency but also fully proves its strong practical value in actual business.</p><p><img loading="lazy" src="/assets/images/production_environment-4f155f3b14a4e95c5367ba99a6c5a6f8.png" width="1080" height="522" class="img_ev3q"></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="future-expectations"><strong>Future Expectations</strong><a href="#future-expectations" class="hash-link" aria-label="Direct link to future-expectations" title="Direct link to future-expectations">​</a></h2><p>As one of the early users of StreamPark, we have maintained close communication with the community, participating in the stability improvement of StreamPark. We have submitted bugs encountered in production operation and new features to the community. In the future, we hope to manage the metadata information of Apache Paimon lake tables and the capability of auxiliary jobs for</p><p>Paimon's Actions on StreamPark. Based on the Flink engine, by interfacing with the Catalog of lake tables and Action jobs, we aim to realize the management and optimization of lake table jobs in one integrated capability. Currently, StreamPark is working on integrating the capabilities with Paimon data, which will greatly assist in real-time data lake ingestion in the future.</p><p>We are very grateful for the technical support that the StreamPark team has provided us all along. We wish Apache StreamPark continued success, more users, and its early graduation to become a top-level Apache project.</p>]]></content>
        <category label="StreamPark" term="StreamPark"/>
        <category label="Production Practice" term="Production Practice"/>
    </entry>
</feed>