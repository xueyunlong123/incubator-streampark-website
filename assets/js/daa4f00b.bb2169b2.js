(self.webpackChunkapache_streampark_website=self.webpackChunkapache_streampark_website||[]).push([[6456],{3905:(e,t,a)=>{"use strict";a.d(t,{Zo:()=>c,kt:()=>f});var n=a(67294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function l(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function o(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?l(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):l(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function i(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},l=Object.keys(e);for(n=0;n<l.length;n++)a=l[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(n=0;n<l.length;n++)a=l[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var s=n.createContext({}),m=function(e){var t=n.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):o(o({},t),e)),a},c=function(e){var t=m(e.components);return n.createElement(s.Provider,{value:t},e.children)},d="mdxType",p={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},u=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,l=e.originalType,s=e.parentName,c=i(e,["components","mdxType","originalType","parentName"]),d=m(a),u=r,f=d["".concat(s,".").concat(u)]||d[u]||p[u]||l;return a?n.createElement(f,o(o({ref:t},c),{},{components:a})):n.createElement(f,o({ref:t},c))}));function f(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var l=a.length,o=new Array(l);o[0]=u;var i={};for(var s in t)hasOwnProperty.call(t,s)&&(i[s]=t[s]);i.originalType=e,i[d]="string"==typeof e?e:r,o[1]=i;for(var m=2;m<l;m++)o[m]=a[m];return n.createElement.apply(null,o)}return n.createElement.apply(null,a)}u.displayName="MDXCreateElement"},46954:(e,t,a)=>{"use strict";a.d(t,{OC:()=>h,k:()=>y,_3:()=>k,zS:()=>g,Lh:()=>u,fx:()=>d,HL:()=>p,rK:()=>b,LP:()=>f,zx:()=>v,C5:()=>E});var n=a(67294);const r={option:[{opt:"-t",longOpt:"target",desc:"Deployment mode(only support yarn-per-job,application)",deprecated:!1,value:" yarn-per-job | application "},{opt:"-d",longOpt:"detached",desc:"run as detached mode",deprecated:!1,value:"true | false"},{opt:"-n",longOpt:"allowNonRestoredState",desc:"allow to skip savepoint state that cannot be restored",deprecated:!1,value:"true | false"},{opt:"-sae",longOpt:"shutdownOnAttachedExit",desc:"If the job is submitted in attached, when job cancel close cluster",deprecated:!1,value:"true | false"},{opt:"-m",longOpt:"jobmanager",desc:"Address of the JobManager to which to connect",deprecated:!1,value:"yarn-cluster | address"},{opt:"-p",longOpt:"parallelism",desc:"Program parallelism",deprecated:!0,value:"int"},{opt:"-c",longOpt:"class",desc:'Class with the program entry point ("main()" method)',deprecated:!0,value:"String"}],property:[{name:"$internal.application.main",desc:'Class with the program entry point ("main()" method)',required:!0},{name:"pipeline.name",desc:"Job name",required:!0},{name:"yarn.application.queue",desc:"YARN queue",required:!1},{name:"taskmanager.numberOfTaskSlots",desc:"Taskmanager slot number",required:!1},{name:"parallelism.default",desc:"Program parallelism",required:!1}],memory:[{group:"JM heap Memory",name:"jobmanager.memory.heap.size",desc:"JVM Heap Memory size for JobManager. The minimum recommended JVM Heap size is 128.000mb (134217728 bytes)."},{group:"JM Off-heap Memory",name:"jobmanager.memory.off-heap.size",desc:"Off-heap Memory size for JobManager. This option covers all off-heap memory usage including direct and native memory allocation. The JVM direct memory limit of the JobManager process (-XX:MaxDirectMemorySize) will be set to this value if the limit is enabled by jobmanager.memory.enable-jvm-direct-memory-limit"},{group:"JVM Metaspace",name:"jobmanager.memory.jvm-metaspace.size",desc:"JVM Metaspace Size for the JobManager."},{group:"JVM Size",name:"jobmanager.memory.jvm-overhead.min",desc:"Min JVM Overhead size for the JobManager. This is off-heap memory reserved for JVM overhead, such as thread stack space, compile cache, etc. This includes native memory but not direct memory, and will not be counted when Flink calculates JVM max direct memory size parameter. The size of JVM Overhead is derived to make up the configured fraction of the Total Process Memory. If the derived size is less or greater than the configured min or max size, the min or max size will be used. The exact size of JVM Overhead can be explicitly specified by setting the min and max size to the same value."},{group:"JVM Size",name:"jobmanager.memory.jvm-overhead.max",desc:"Max JVM Overhead size for the JobManager. This is off-heap memory reserved for JVM overhead, such as thread stack space, compile cache, etc. This includes native memory but not direct memory, and will not be counted when Flink calculates JVM max direct memory size parameter. The size of JVM Overhead is derived to make up the configured fraction of the Total Process Memory. If the derived size is less or greater than the configured min or max size, the min or max size will be used. The exact size of JVM Overhead can be explicitly specified by setting the min and max size to the same value."},{group:"JVM Size",name:"jobmanager.memory.jvm-overhead.fraction",desc:"Fraction of Total Process Memory to be reserved for JVM Overhead. This is off-heap memory reserved for JVM overhead, such as thread stack space, compile cache, etc. This includes native memory but not direct memory, and will not be counted when Flink calculates JVM max direct memory size parameter. The size of JVM Overhead is derived to make up the configured fraction of the Total Process Memory. If the derived size is less or greater than the configured min or max size, the min or max size will be used. The exact size of JVM Overhead can be explicitly specified by setting the min and max size to the same value."},{group:"Framework Heap Memory",name:"taskmanager.memory.framework.heap.size",desc:"Framework Heap Memory size for TaskExecutors. This is the size of JVM heap memory reserved for TaskExecutor framework, which will not be allocated to task slots."},{group:"Task Heap Memory",name:"taskmanager.memory.task.heap.size",desc:"Task Heap Memory size for TaskExecutors. This is the size of JVM heap memory reserved for tasks. If not specified, it will be derived as Total Flink Memory minus Framework Heap Memory, Framework Off-Heap Memory, Task Off-Heap Memory, Managed Memory and Network Memory."},{group:"Managed memory",name:"taskmanager.memory.managed.size",desc:"Managed Memory size for TaskExecutors. This is the size of off-heap memory managed by the memory manager, reserved for sorting, hash tables, caching of intermediate results and RocksDB state backend. Memory consumers can either allocate memory from the memory manager in the form of MemorySegments, or reserve bytes from the memory manager and keep their memory usage within that boundary. If unspecified, it will be derived to make up the configured fraction of the Total Flink Memory."},{group:"Managed memory",name:"taskmanager.memory.managed.fraction",desc:"Fraction of Total Flink Memory to be used as Managed Memory, if Managed Memory size is not explicitly specified."},{group:"Framework off-heap memory",name:"taskmanager.memory.framework.off-heap.size",desc:"Framework Off-Heap Memory size for TaskExecutors. This is the size of off-heap memory (JVM direct memory and native memory) reserved for TaskExecutor framework, which will not be allocated to task slots. The configured value will be fully counted when Flink calculates the JVM max direct memory size parameter."},{group:"Taskmanager off-heap memory",name:"taskmanager.memory.task.off-heap.size",desc:"Task Off-Heap Memory size for TaskExecutors. This is the size of off heap memory (JVM direct memory and native memory) reserved for tasks. The configured value will be fully counted when Flink calculates the JVM max direct memory size parameter."},{group:"JVM Metaspace",name:"taskmanager.memory.jvm-metaspace.size",desc:"JVM Metaspace Size for the TaskExecutors."}],totalMem:[{group:"Flink total memory",tm:"taskmanager.memory.flink.size",jm:"jobmanager.memory.flink.size"},{group:"Flink process total memory",tm:"taskmanager.memory.process.size",jm:"jobmanager.memory.process.size"}],checkpoints:[{name:"execution.checkpointing.interval",desc:"Interval period of checkpoint",value:"Duration"},{name:"execution.checkpointing.timeout",desc:"timeout",value:"Duration"},{name:"execution.checkpointing.mode",desc:"semantics",value:" EXACTLY_ONCE | AT_LEAST_ONCE "},{name:"execution.checkpointing.unaligned",desc:"unaligned",value:"true | false"}],backend:[{name:"state.backend",desc:"Type of backend storage",value:"hashmap | rocksdb",mode:""},{name:"state.checkpoint-storage",desc:"The checkpoint storage implementation to be used to checkpoint state.",value:"jobmanager | filesystem ",mode:""},{name:"state.backend.incremental",desc:"Whether to enable increment",value:" true | false",mode:"rocksdb"}],fixedDelay:[{name:"attempts",desc:"Number of Flink attempts to restart",value:"3"},{name:"delay",desc:"Specify how long to restart after the task fails",value:"none | s | m | min | h | d"}],failureRate:[{name:"max-failures-per-interval",desc:"Maximum number of restarts in given time interval before failing a job",value:"3"},{name:"failure-rate-interval",desc:"Time interval for measuring failure",value:"None | s | m | min | h | d"},{name:"delay",desc:"Delay between two consecutive restart attempts",value:"None | s | m | min | h | d"}],tables:[{name:"planner",desc:"Table Planner",value:"blink | old | any"},{name:"mode",desc:"Table Mode",value:"streaming | batch"},{name:"catalog",desc:"Catalog,Specifies that the will be used during initialization",value:""},{name:"database",desc:"Database,Specifies that the will be used during initialization",value:""}],deploymentEnvs:[{name:"OS",version:"Linux",required:!0,other:"UnSupport Windows"},{name:"JAVA",version:"1.8+",required:!0,other:null},{name:"MySQL",version:"5.6+",required:!0,other:null},{name:"Flink",version:"1.12.0+",required:!0,other:"Flink version >= 1.12"},{name:"Hadoop",version:"2+",required:!1,other:"Optional, If on yarn, hadoop envs is required."}],developmentEnvs:[{name:"OS",version:"Linux",required:!1,other:"Supports Windows, recommended to use Mac/Linux."},{name:"IDE",version:"Intellij IDEA",required:!1,other:"Recommended to use Intellij IDEA"},{name:"JAVA",version:"1.8 +",required:!0,other:null},{name:"Scala",version:"2.12.x",required:!0,other:"install scala-plugin in Intellij IDEA"},{name:"Nodejs",version:"16.14.x ~ 18",required:!0,other:"https://nodejs.org"},{name:"pnpm",version:"7.11.2",required:!0,other:"npm install -g pnpm"},{name:"Flink",version:"1.12.0 +",required:!0,other:"Flink >= 1.12, just download and unpack it."},{name:"MySQL",version:"5.6 +",required:!1,other:null},{name:"Hadoop",version:"2 +",required:!1,other:"Optional, If on yarn, hadoop envs is required."}]};let l=null,o=0;function i(e){l||(l=window.document.createElement("div"),l.setAttribute("class","cpt-toast-wrapper"),window.document.body.append(l));let t=""+Date.now()+o++,a=window.document.createElement("div");a.setAttribute("id",t),a.innerHTML=`<div class="cpt-toast"><span class="${e.icon}">${e.msg}</span></div>`,l.append(a),setTimeout((()=>{window.document.getElementById(t).remove()}),e.time||1e3)}const s={success(e,t){i({msg:e,time:t,icon:"success"})},error(e,t){i({msg:e,time:t,icon:"error"})},info(e,t){i({msg:e,time:t,icon:"info"})}};var m=a(74855);const c=()=>{s.success("Copy succeeded \ud83c\udf89")},d=()=>n.createElement("div",null,n.createElement("table",{className:"table-data",style:{width:"100%",display:"inline-table"}},n.createElement("thead",null,n.createElement("tr",null,n.createElement("td",{style:{width:"80px"}},"Short Param"),n.createElement("td",null,'Full Param(prefix"--")'),n.createElement("td",{style:{width:"60px"}},"Effective"),n.createElement("td",null,"Value & Type"),n.createElement("td",null,"Description"))),n.createElement("tbody",null,r.option.map(((e,t)=>n.createElement("tr",{key:t},n.createElement("td",null,e.opt),n.createElement("td",null,e.longOpt),n.createElement("td",null,e.deprecated?n.createElement("span",{className:"icon-times"}):n.createElement("span",{className:"icon-check"})),n.createElement("td",null,e.value),n.createElement("td",null,e.desc))))))),p=()=>n.createElement("div",null,n.createElement("table",{className:"table-data",style:{width:"100%",display:"inline-table"}},n.createElement("thead",null,n.createElement("tr",null,n.createElement("td",null,"Key"),n.createElement("td",null,"Description"),n.createElement("td",null,"Required"))),n.createElement("tbody",null,r.property.map(((e,t)=>n.createElement("tr",{key:t},n.createElement("td",null,n.createElement("span",{className:"label-info"},e.name),n.createElement(m.CopyToClipboard,{text:e.name,onCopy:()=>c()},n.createElement("i",{className:"icon-copy"}))),n.createElement("td",null,e.desc),n.createElement("td",null,e.required?n.createElement("span",{className:"icon-toggle-on",title:"Required"}):n.createElement("span",{className:"icon-toggle-off",title:"Optional"})))))))),u=()=>n.createElement("div",null,n.createElement("table",{className:"table-data",style:{width:"100%",display:"inline-table"}},n.createElement("thead",null,n.createElement("tr",null,n.createElement("td",{style:{width:"380px"}},"Key"),n.createElement("td",null,"Description"))),n.createElement("tbody",null,r.memory.map(((e,t)=>n.createElement("tr",{key:t},n.createElement("td",null,n.createElement("span",{className:"label-info"},e.name),n.createElement(m.CopyToClipboard,{text:e.name,onCopy:()=>c()},n.createElement("i",{className:"icon-copy"}))),n.createElement("td",null,e.desc))))))),f=()=>n.createElement("div",null,n.createElement("table",{className:"table-data",style:{width:"100%",display:"inline-table"}},n.createElement("thead",null,n.createElement("tr",null,n.createElement("td",null,"Item"),n.createElement("td",null,"TaskManager Config"),n.createElement("td",null,"JobManager Config"))),n.createElement("tbody",null,r.totalMem.map(((e,t)=>n.createElement("tr",{key:t},n.createElement("td",null,e.group),n.createElement("td",null,n.createElement("span",{className:"label-info"},e.tm),n.createElement(m.CopyToClipboard,{text:e.tm,onCopy:()=>c()},n.createElement("i",{className:"icon-copy"}))),n.createElement("td",null,n.createElement("span",{className:"label-info"},e.jm),n.createElement(m.CopyToClipboard,{text:e.jm,onCopy:()=>c()},n.createElement("i",{className:"icon-copy"}))))))))),y=()=>n.createElement("div",null,n.createElement("table",{className:"table-data",style:{width:"100%",display:"inline-table"}},n.createElement("thead",null,n.createElement("tr",null,n.createElement("td",null,"Item"),n.createElement("td",null,"Description"),n.createElement("td",null,"Value | Type"))),n.createElement("tbody",null,r.checkpoints.map(((e,t)=>n.createElement("tr",{key:t},n.createElement("td",null,e.name),n.createElement("td",null,e.desc),n.createElement("td",null,e.value))))))),h=()=>n.createElement("div",null,n.createElement("table",{className:"table-data",style:{width:"100%",display:"inline-table"}},n.createElement("thead",null,n.createElement("tr",null,n.createElement("td",null,"Item"),n.createElement("td",null,"Description"),n.createElement("td",null,"Value | Type"),n.createElement("td",null,"Effective rules"))),n.createElement("tbody",null,r.backend.map(((e,t)=>n.createElement("tr",{key:t},n.createElement("td",null,n.createElement("span",{className:"label-info"},e.name),n.createElement(m.CopyToClipboard,{text:e.name,onCopy:()=>c()},n.createElement("i",{className:"icon-copy"}))),n.createElement("td",null,e.desc),n.createElement("td",null,e.value),n.createElement("td",null,e.mode))))))),g=()=>n.createElement("div",null,n.createElement("table",{className:"table-data",style:{width:"100%",display:"inline-table"}},n.createElement("thead",null,n.createElement("tr",null,n.createElement("td",null,"Item"),n.createElement("td",null,"Description"),n.createElement("td",null,"Value | Unit"))),n.createElement("tbody",null,r.fixedDelay.map(((e,t)=>n.createElement("tr",{key:t},n.createElement("td",null,n.createElement("span",{className:"label-info"},e.name),n.createElement(m.CopyToClipboard,{text:e.name,onCopy:()=>c()},n.createElement("i",{className:"icon-copy"}))),n.createElement("td",null,e.desc),n.createElement("td",null,e.value))))))),k=()=>n.createElement("div",null,n.createElement("table",{className:"table-data",style:{width:"100%",display:"inline-table"}},n.createElement("thead",null,n.createElement("tr",null,n.createElement("td",null,"Item"),n.createElement("td",null,"Description"),n.createElement("td",null,"Value | Unit"))),n.createElement("tbody",null,r.failureRate.map(((e,t)=>n.createElement("tr",{key:t},n.createElement("td",null,n.createElement("span",{className:"label-info"},e.name),n.createElement(m.CopyToClipboard,{text:e.name,onCopy:()=>c()},n.createElement("i",{className:"icon-copy"}))),n.createElement("td",null,e.desc),n.createElement("td",null,e.value))))))),b=()=>n.createElement("div",null,n.createElement("table",{className:"table-data",style:{width:"100%",display:"inline-table"}},n.createElement("thead",null,n.createElement("tr",null,n.createElement("td",null,"Item"),n.createElement("td",null,"Description"),n.createElement("td",null,"Value"))),n.createElement("tbody",null,r.tables.map(((e,t)=>n.createElement("tr",{key:t},n.createElement("td",null,n.createElement("span",{className:"label-info"},e.name),n.createElement(m.CopyToClipboard,{text:e.name,onCopy:()=>c()},n.createElement("i",{className:"icon-copy"}))),n.createElement("td",null,e.desc),n.createElement("td",null,e.value))))))),v=()=>n.createElement("div",null,n.createElement("table",{className:"table-data",style:{width:"100%",display:"inline-table"}},n.createElement("thead",null,n.createElement("tr",null,n.createElement("td",null,"Item"),n.createElement("td",null,"Version"),n.createElement("td",null,"Required"),n.createElement("td",null,"Other"))),n.createElement("tbody",null,r.deploymentEnvs.map(((e,t)=>n.createElement("tr",{key:t},n.createElement("td",null,n.createElement("span",{className:"label-info"},e.name)),n.createElement("td",null,e.version),n.createElement("td",null,e.required?n.createElement("span",{className:"icon-toggle-on",title:"Required"}):n.createElement("span",{className:"icon-toggle-off",title:"Optional"})),n.createElement("td",null,e.other))))))),E=()=>n.createElement("div",null,n.createElement("table",{className:"table-data",style:{width:"100%",display:"inline-table"}},n.createElement("thead",null,n.createElement("tr",null,n.createElement("td",null,"Item"),n.createElement("td",null,"Version"),n.createElement("td",null,"Required"),n.createElement("td",null,"Other"))),n.createElement("tbody",null,r.developmentEnvs.map(((e,t)=>n.createElement("tr",{key:t},n.createElement("td",null,n.createElement("span",{className:"label-info"},e.name)),n.createElement("td",null,e.version),n.createElement("td",null,e.required?n.createElement("span",{className:"icon-toggle-on",title:"Required"}):n.createElement("span",{className:"icon-toggle-off",title:"Optional"})),n.createElement("td",null,e.other)))))))},1398:(e,t,a)=>{"use strict";a.r(t),a.d(t,{assets:()=>m,contentTitle:()=>i,default:()=>p,frontMatter:()=>o,metadata:()=>s,toc:()=>c});var n=a(87462),r=(a(67294),a(3905)),l=a(46954);const o={id:"deployment",title:"Platform Deployment",sidebar_position:1},i=void 0,s={unversionedId:"user-guide/deployment",id:"user-guide/deployment",title:"Platform Deployment",description:"The overall component stack structure of StreamPark is as follows. It consists of two major parts: streampark-core and streampark-console. streampark-console is a very important module, positioned as a integrated real-time data platform,  streaming data warehouse Platform, Low Code, Flink & Spark task hosting platform, can better manage Flink tasks, integrate project compilation, publishing, parameter configuration, startup, savepoint, flame graph ( flame graph ), Flink SQL, monitoring and many other functions are integrated into one, which greatly simplifies the daily operation and maintenance of Flink tasks and integrates many best practices. Its ultimate goal is to create a one-stop big data solution that integrates real-time data warehouses and batches",source:"@site/docs/user-guide/1-deployment.md",sourceDirName:"user-guide",slug:"/user-guide/deployment",permalink:"/docs/user-guide/deployment",draft:!1,editUrl:"https://github.com/apache/incubator-streampark-website/edit/dev/docs/user-guide/1-deployment.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{id:"deployment",title:"Platform Deployment",sidebar_position:1},sidebar:"tutorialSidebar",previous:{title:"What is StreamPark",permalink:"/docs/intro"},next:{title:"Quick Start",permalink:"/docs/user-guide/quick-start"}},m={},c=[{value:"Environmental requirements",id:"environmental-requirements",level:2},{value:"Hadoop",id:"hadoop",level:3},{value:"Kubernetes",id:"kubernetes",level:3},{value:"Build &amp; Deploy",id:"build--deploy",level:2},{value:"Environmental requirements",id:"environmental-requirements-1",level:3},{value:"install streampark",id:"install-streampark",level:3},{value:"Initialize table structure",id:"initialize-table-structure",level:5},{value:"Modify the configuration",id:"modify-the-configuration",level:5},{value:"Create a new database <code>streampark</code>",id:"create-a-new-database-streampark",level:6},{value:"Modify connection information",id:"modify-connection-information",level:6},{value:"Modify workspace",id:"modify-workspace",level:6},{value:"Start",id:"start",level:5},{value:"login system",id:"login-system",level:3},{value:"System Configuration",id:"system-configuration",level:2},{value:"System Setting",id:"system-setting",level:3},{value:"Alert Setting",id:"alert-setting",level:3},{value:"Flink Home",id:"flink-home",level:3},{value:"Flink Cluster",id:"flink-cluster",level:3}],d={toc:c};function p(e){let{components:t,...o}=e;return(0,r.kt)("wrapper",(0,n.Z)({},d,o,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("p",null,"The overall component stack structure of StreamPark is as follows. It consists of two major parts: streampark-core and streampark-console. streampark-console is a very important module, positioned as a ",(0,r.kt)("strong",{parentName:"p"},"integrated real-time data platform"),", ",(0,r.kt)("strong",{parentName:"p"}," streaming data warehouse Platform"),", ",(0,r.kt)("strong",{parentName:"p"},"Low Code"),", ",(0,r.kt)("strong",{parentName:"p"},"Flink & Spark task hosting platform"),", can better manage Flink tasks, integrate project compilation, publishing, parameter configuration, startup, savepoint, flame graph ( flame graph ), Flink SQL, monitoring and many other functions are integrated into one, which greatly simplifies the daily operation and maintenance of Flink tasks and integrates many best practices. Its ultimate goal is to create a one-stop big data solution that integrates real-time data warehouses and batches"),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"StreamPark Archite",src:a(92714).Z,width:"2734",height:"1311"})),(0,r.kt)("p",null,"streampark-console provides an out-of-the-box installation package. Before installation, there are some requirements for the environment. The specific requirements are as follows:"),(0,r.kt)("h2",{id:"environmental-requirements"},"Environmental requirements"),(0,r.kt)(l.zx,{mdxType:"DeploymentEnvs"}),(0,r.kt)("p",null,"At present, StreamPark has released tasks for Flink, and supports both ",(0,r.kt)("inlineCode",{parentName:"p"},"Flink on YARN")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"Flink on Kubernetes")," modes."),(0,r.kt)("h3",{id:"hadoop"},"Hadoop"),(0,r.kt)("p",null,"To use ",(0,r.kt)("inlineCode",{parentName:"p"},"Flink on YARN"),", you need to install and configure Hadoop-related environment variables in the deployed cluster. For example, if you installed the hadoop environment based on CDH,\nRelated environment variables can refer to the following configuration:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"export HADOOP_HOME=/opt/cloudera/parcels/CDH/lib/hadoop #hadoop installation manual\nexport HADOOP_CONF_DIR=/etc/hadoop/conf\nexport HIVE_HOME=$HADOOP_HOME/../hive\nexport HBASE_HOME=$HADOOP_HOME/../hbase\nexport HADOOP_HDFS_HOME=$HADOOP_HOME/../hadoop-hdfs\nexport HADOOP_MAPRED_HOME=$HADOOP_HOME/../hadoop-mapreduce\nexport HADOOP_YARN_HOME=$HADOOP_HOME/../hadoop-yarn\n")),(0,r.kt)("h3",{id:"kubernetes"},"Kubernetes"),(0,r.kt)("p",null,"Using ",(0,r.kt)("inlineCode",{parentName:"p"},"Flink on Kubernetes")," requires additional deployment/or use of an existing Kubernetes cluster, please refer to the entry: ",(0,r.kt)("a",{parentName:"p",href:"/docs/flink-k8s/k8s-dev"},(0,r.kt)("strong",{parentName:"a"},"StreamPark Flink-K8s Integration Support")),"."),(0,r.kt)("h2",{id:"build--deploy"},"Build & Deploy"),(0,r.kt)("p",null,"You can directly download the compiled ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/apache/incubator-streampark/releases"},(0,r.kt)("strong",{parentName:"a"},"release package"))," (recommended), or you can choose to manually compile and install. The manual compilation and installation steps are as follows:"),(0,r.kt)("h3",{id:"environmental-requirements-1"},"Environmental requirements"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Maven 3.6+"),(0,r.kt)("li",{parentName:"ul"},"npm 7.11.2 ( ",(0,r.kt)("a",{parentName:"li",href:"https://nodejs.org/en/"},"https://nodejs.org/en/")," )"),(0,r.kt)("li",{parentName:"ul"},"pnpm (npm install -g pnpm)"),(0,r.kt)("li",{parentName:"ul"},"JDK 1.8+")),(0,r.kt)("h3",{id:"install-streampark"},"install streampark"),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://streampark.apache.org/download"},"download")," streampark release package, unpacking as follows"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-textmate"},".\nstreampark-console-service-2.0.0\n\u251c\u2500\u2500 bin\n\u2502    \u251c\u2500\u2500 startup.sh                           //startup script\n\u2502    \u251c\u2500\u2500 setclasspath.sh                      //Scripts related to java environment variables (internal use, users do not need to pay attention)\n\u2502    \u251c\u2500\u2500 shutdown.sh                          //stop script\n\u2502    \u251c\u2500\u2500 yaml.sh                              //Internally uses a script that parses yaml parameters (for internal use, users don't need to pay attention)\n\u251c\u2500\u2500 conf\n\u2502    \u251c\u2500\u2500 application.yaml                     //Project configuration file (be careful not to change the name)\n\u2502    \u251c\u2500\u2500 flink-application.template           //flink configuration template (for internal use, users don't need to pay attention)\n\u2502    \u251c\u2500\u2500 logback-spring.xml                   //logback\n\u2502    \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 lib\n\u2502    \u2514\u2500\u2500 *.jar                                //Project jar package\n\u251c\u2500\u2500 client\n\u2502    \u2514\u2500\u2500 streampark-flink-sqlclient-2.0.0.jar    //Flink SQl submit related functions (for internal use, users do not need to pay attention)\n\u251c\u2500\u2500 script\n\u2502     \u251c\u2500\u2500 schema                             \n\u2502     \u2502      \u251c\u2500\u2500 mysql-schema.sql            // mysql ddl\n\u2502     \u2502      \u2514\u2500\u2500 pgsql-schema.sql            // pgsql ddl\n\u2502     \u251c\u2500\u2500 data                             \n\u2502     \u2502      \u251c\u2500\u2500 mysql-data.sql              // mysql init data\n\u2502     \u2502      \u2514\u2500\u2500 pgsql-data.sql              // pgsql init data\n\u2502     \u251c\u2500\u2500 upgrade                            \n\u2502     \u2502      \u251c\u2500\u2500 1.2.3.sql                   // 1.2.3 upgrade sql     \n\u2502     \u2502      \u2514\u2500\u2500 2.0.0.sql                   // 2.0.0 upgrade sql       \n\u2502     \u2502      ... \n\u251c\u2500\u2500 logs                                     // log dir\n\u251c\u2500\u2500 temp                                     // temp dir, don't remove\n")),(0,r.kt)("h5",{id:"initialize-table-structure"},"Initialize table structure"),(0,r.kt)("p",null,"In the installation process of versions before 1.2.1, there is no need to manually initialize data, just set the database information, and some column operations such as table creation and data initialization will be automatically completed. Versions after 1.2.1 (included) are not included. Automatic table creation and upgrade requires the user to manually execute ddl for initialization. The ddl description is as follows:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-textmate"},"\u251c\u2500\u2500 script\n\u2502     \u251c\u2500\u2500 schema                             \n\u2502     \u2502      \u251c\u2500\u2500 mysql-schema.sql            // mysql ddl\n\u2502     \u2502      \u2514\u2500\u2500 pgsql-schema.sql            // pgsql ddl\n\u2502     \u251c\u2500\u2500 data                             \n\u2502     \u2502      \u251c\u2500\u2500 mysql-data.sql              // mysql init data\n\u2502     \u2502      \u2514\u2500\u2500 pgsql-data.sql              // pgsql init data\n\u2502     \u251c\u2500\u2500 upgrade                            \n\u2502     \u2502      \u251c\u2500\u2500 1.2.3.sql                   // 1.2.3 upgrade sql     \n\u2502     \u2502      \u2514\u2500\u2500 2.0.0.sql                   // 2.0.0 upgrade sql       \n\u2502     \u2502      ... \n\u251c\u2500\u2500 logs                                     // log dir\n\u251c\u2500\u2500 temp                                     // temp dir, don't remove\n")),(0,r.kt)("p",null,"If streampark first installation, need to connect to the corresponding database client to execute the script under the ",(0,r.kt)("inlineCode",{parentName:"p"},"schema")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"data")," directories in sequence, and if it is an upgrade, execute under ",(0,r.kt)("inlineCode",{parentName:"p"},"upgrade")," sql file of the corresponding version number."),(0,r.kt)("h5",{id:"modify-the-configuration"},"Modify the configuration"),(0,r.kt)("p",null,"The installation and unpacking have been completed, and the next step is to prepare the data-related work"),(0,r.kt)("h6",{id:"create-a-new-database-streampark"},"Create a new database ",(0,r.kt)("inlineCode",{parentName:"h6"},"streampark")),(0,r.kt)("p",null,"Make sure to create a new database ",(0,r.kt)("inlineCode",{parentName:"p"},"streampark")," in mysql that the deployment machine can connect to"),(0,r.kt)("h6",{id:"modify-connection-information"},"Modify connection information"),(0,r.kt)("p",null,"Go to ",(0,r.kt)("inlineCode",{parentName:"p"},"conf"),", modify ",(0,r.kt)("inlineCode",{parentName:"p"},"conf/application.yml"),", find the spring item, find the profiles.active configuration, and modify it to the corresponding information, as follows"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},"spring:\n  profiles.active: mysql #[h2,pgsql,mysql]\n  application.name: StreamPark\n  devtools.restart.enabled: false\n  mvc.pathmatch.matching-strategy: ant_path_matcher\n  servlet:\n    multipart:\n      enabled: true\n      max-file-size: 500MB\n      max-request-size: 500MB\n  aop.proxy-target-class: true\n  messages.encoding: utf-8\n  jackson:\n    date-format: yyyy-MM-dd HH:mm:ss\n    time-zone: GMT+8\n  main:\n    allow-circular-references: true\n    banner-mode: off\n")),(0,r.kt)("p",null,"After modify ",(0,r.kt)("inlineCode",{parentName:"p"},"conf/application.yml"),", then modify the ",(0,r.kt)("inlineCode",{parentName:"p"},"config/application-mysql.yml")," to change the config information of database as follows:"),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Tips: Because of license incompatibility between Apache project and mysql jdbc driver, so you should download mysql jdbc driver by yourself and put it in $STREAMPARK_HOME/lib")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},"spring:\n  datasource:\n    username: root\n    password: xxxx\n    driver-class-name: com.mysql.cj.jdbc.Driver\n    url: jdbc:mysql://localhost:3306/streampark?useSSL=false&useUnicode=true&characterEncoding=UTF-8&allowPublicKeyRetrieval=false&useJDBCCompliantTimezoneShift=true&useLegacyDatetimeCode=false&serverTimezone=GMT%2B8\n")),(0,r.kt)("h6",{id:"modify-workspace"},"Modify workspace"),(0,r.kt)("p",null,"Go to ",(0,r.kt)("inlineCode",{parentName:"p"},"conf"),", modify ",(0,r.kt)("inlineCode",{parentName:"p"},"conf/application.yml"),", find the item streampark, find the workspace configuration, and change it to a directory that the user has permission to."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},"streampark:\n  # HADOOP_USER_NAME If it is on yarn mode ( yarn-prejob | yarn-application | yarn-session), you need to configure hadoop-user-name\n  hadoop-user-name: hdfs\n  # Local workspace, used to store project source code, build directory, etc.\n  workspace:\n    local: /opt/streampark_workspace # A local workspace directory (very important), users can change the directory by themselves, it is recommended to put it in other places separately to store the project source code, the built directory, etc.\n    remote: hdfs:///streampark   # support hdfs:///streampark/ \u3001 /streampark \u3001hdfs://host:ip/streampark/\n")),(0,r.kt)("h5",{id:"start"},"Start"),(0,r.kt)("p",null,"Enter ",(0,r.kt)("inlineCode",{parentName:"p"},"bin")," and directly execute startup.sh to start the project. The default port is ",(0,r.kt)("strong",{parentName:"p"},"10000"),", if there is no accident, it will start successfully"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"cd streampark-console-service-2.0.0/bin\nbash startup.sh\n")),(0,r.kt)("p",null,"Relevant logs will be output to ",(0,r.kt)("strong",{parentName:"p"},"streampark-console-service-1.0.0/logs/streampark.out")),(0,r.kt)("h3",{id:"login-system"},"login system"),(0,r.kt)("p",null,"After the above steps, even if the deployment is completed, you can directly log in to the system"),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"StreamPark Login",src:a(5053).Z,width:"1727",height:"891"})),(0,r.kt)("admonition",{title:"hint",type:"tip"},(0,r.kt)("p",{parentName:"admonition"},"Default password: ",(0,r.kt)("strong",null," admin / streampark "))),(0,r.kt)("h2",{id:"system-configuration"},"System Configuration"),(0,r.kt)("p",null,"After entering the system, the first thing to do is to modify the system configuration. Under the menu/StreamPark/Setting, the operation interface is as follows:"),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"StreamPark Settings",src:a(97441).Z,width:"1768",height:"1294"})),(0,r.kt)("p",null,"The main configuration items are divided into the following categories"),(0,r.kt)("div",{class:"counter"},(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"System Setting"),(0,r.kt)("li",{parentName:"ul"},"Alert Setting"),(0,r.kt)("li",{parentName:"ul"},"Flink Home"),(0,r.kt)("li",{parentName:"ul"},"Flink Cluster"))),(0,r.kt)("h3",{id:"system-setting"},"System Setting"),(0,r.kt)("p",null,"The current system configuration includes:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Maven Setting"),(0,r.kt)("li",{parentName:"ul"},"Docker Setting"),(0,r.kt)("li",{parentName:"ul"},"Sender Email Setting"),(0,r.kt)("li",{parentName:"ul"},"Ingress Setting")),(0,r.kt)("h3",{id:"alert-setting"},"Alert Setting"),(0,r.kt)("p",null,"The configuration related to Alert Email is to configure the information of the sender's email. For the specific configuration, please refer to the relevant mailbox information and documents for configuration."),(0,r.kt)("h3",{id:"flink-home"},"Flink Home"),(0,r.kt)("p",null,"The global Flink Home is configured here. This is the only place in the system to specify the Flink environment, which will apply to all jobs."),(0,r.kt)("admonition",{title:"hint",type:"info"},(0,r.kt)("p",{parentName:"admonition"},"Special Note: The minimum supported Flink version is 1.12.0, and later versions are supported")),(0,r.kt)("h3",{id:"flink-cluster"},"Flink Cluster"),(0,r.kt)("p",null,"The cluster modes currently supported by Flink include:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Standalone"),(0,r.kt)("li",{parentName:"ul"},"Yarn Session"),(0,r.kt)("li",{parentName:"ul"},"Kubernetes Session")))}p.isMDXComponent=!0},20640:(e,t,a)=>{"use strict";var n=a(11742),r={"text/plain":"Text","text/html":"Url",default:"Text"};e.exports=function(e,t){var a,l,o,i,s,m,c=!1;t||(t={}),a=t.debug||!1;try{if(o=n(),i=document.createRange(),s=document.getSelection(),(m=document.createElement("span")).textContent=e,m.ariaHidden="true",m.style.all="unset",m.style.position="fixed",m.style.top=0,m.style.clip="rect(0, 0, 0, 0)",m.style.whiteSpace="pre",m.style.webkitUserSelect="text",m.style.MozUserSelect="text",m.style.msUserSelect="text",m.style.userSelect="text",m.addEventListener("copy",(function(n){if(n.stopPropagation(),t.format)if(n.preventDefault(),void 0===n.clipboardData){a&&console.warn("unable to use e.clipboardData"),a&&console.warn("trying IE specific stuff"),window.clipboardData.clearData();var l=r[t.format]||r.default;window.clipboardData.setData(l,e)}else n.clipboardData.clearData(),n.clipboardData.setData(t.format,e);t.onCopy&&(n.preventDefault(),t.onCopy(n.clipboardData))})),document.body.appendChild(m),i.selectNodeContents(m),s.addRange(i),!document.execCommand("copy"))throw new Error("copy command was unsuccessful");c=!0}catch(d){a&&console.error("unable to copy using execCommand: ",d),a&&console.warn("trying IE specific stuff");try{window.clipboardData.setData(t.format||"text",e),t.onCopy&&t.onCopy(window.clipboardData),c=!0}catch(d){a&&console.error("unable to copy using clipboardData: ",d),a&&console.error("falling back to prompt"),l=function(e){var t=(/mac os x/i.test(navigator.userAgent)?"\u2318":"Ctrl")+"+C";return e.replace(/#{\s*key\s*}/g,t)}("message"in t?t.message:"Copy to clipboard: #{key}, Enter"),window.prompt(l,e)}}finally{s&&("function"==typeof s.removeRange?s.removeRange(i):s.removeAllRanges()),m&&document.body.removeChild(m),o()}return c}},74300:(e,t,a)=>{"use strict";function n(e){return n="function"==typeof Symbol&&"symbol"==typeof Symbol.iterator?function(e){return typeof e}:function(e){return e&&"function"==typeof Symbol&&e.constructor===Symbol&&e!==Symbol.prototype?"symbol":typeof e},n(e)}Object.defineProperty(t,"__esModule",{value:!0}),t.CopyToClipboard=void 0;var r=i(a(67294)),l=i(a(20640)),o=["text","onCopy","options","children"];function i(e){return e&&e.__esModule?e:{default:e}}function s(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function m(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?s(Object(a),!0).forEach((function(t){k(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):s(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function c(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},l=Object.keys(e);for(n=0;n<l.length;n++)a=l[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(n=0;n<l.length;n++)a=l[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}function d(e,t){if(!(e instanceof t))throw new TypeError("Cannot call a class as a function")}function p(e,t){for(var a=0;a<t.length;a++){var n=t[a];n.enumerable=n.enumerable||!1,n.configurable=!0,"value"in n&&(n.writable=!0),Object.defineProperty(e,n.key,n)}}function u(e,t){return u=Object.setPrototypeOf||function(e,t){return e.__proto__=t,e},u(e,t)}function f(e){var t=function(){if("undefined"==typeof Reflect||!Reflect.construct)return!1;if(Reflect.construct.sham)return!1;if("function"==typeof Proxy)return!0;try{return Boolean.prototype.valueOf.call(Reflect.construct(Boolean,[],(function(){}))),!0}catch(e){return!1}}();return function(){var a,n=g(e);if(t){var r=g(this).constructor;a=Reflect.construct(n,arguments,r)}else a=n.apply(this,arguments);return y(this,a)}}function y(e,t){if(t&&("object"===n(t)||"function"==typeof t))return t;if(void 0!==t)throw new TypeError("Derived constructors may only return object or undefined");return h(e)}function h(e){if(void 0===e)throw new ReferenceError("this hasn't been initialised - super() hasn't been called");return e}function g(e){return g=Object.setPrototypeOf?Object.getPrototypeOf:function(e){return e.__proto__||Object.getPrototypeOf(e)},g(e)}function k(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}var b=function(e){!function(e,t){if("function"!=typeof t&&null!==t)throw new TypeError("Super expression must either be null or a function");e.prototype=Object.create(t&&t.prototype,{constructor:{value:e,writable:!0,configurable:!0}}),Object.defineProperty(e,"prototype",{writable:!1}),t&&u(e,t)}(s,e);var t,a,n,i=f(s);function s(){var e;d(this,s);for(var t=arguments.length,a=new Array(t),n=0;n<t;n++)a[n]=arguments[n];return k(h(e=i.call.apply(i,[this].concat(a))),"onClick",(function(t){var a=e.props,n=a.text,o=a.onCopy,i=a.children,s=a.options,m=r.default.Children.only(i),c=(0,l.default)(n,s);o&&o(n,c),m&&m.props&&"function"==typeof m.props.onClick&&m.props.onClick(t)})),e}return t=s,(a=[{key:"render",value:function(){var e=this.props,t=(e.text,e.onCopy,e.options,e.children),a=c(e,o),n=r.default.Children.only(t);return r.default.cloneElement(n,m(m({},a),{},{onClick:this.onClick}))}}])&&p(t.prototype,a),n&&p(t,n),Object.defineProperty(t,"prototype",{writable:!1}),s}(r.default.PureComponent);t.CopyToClipboard=b,k(b,"defaultProps",{onCopy:void 0,options:void 0})},74855:(e,t,a)=>{"use strict";var n=a(74300).CopyToClipboard;n.CopyToClipboard=n,e.exports=n},11742:e=>{e.exports=function(){var e=document.getSelection();if(!e.rangeCount)return function(){};for(var t=document.activeElement,a=[],n=0;n<e.rangeCount;n++)a.push(e.getRangeAt(n));switch(t.tagName.toUpperCase()){case"INPUT":case"TEXTAREA":t.blur();break;default:t=null}return e.removeAllRanges(),function(){"Caret"===e.type&&e.removeAllRanges(),e.rangeCount||a.forEach((function(t){e.addRange(t)})),t&&t.focus()}}},5053:(e,t,a)=>{"use strict";a.d(t,{Z:()=>n});const n=a.p+"assets/images/streampark_login-c38d72811068f2d3b2bd865ac7cb759b.jpeg"},97441:(e,t,a)=>{"use strict";a.d(t,{Z:()=>n});const n=a.p+"assets/images/streampark_settings_2.0.0-8af18c05b4a169fb3b482186c00dcadf.png"},92714:(e,t,a)=>{"use strict";a.d(t,{Z:()=>n});const n=a.p+"assets/images/streampark_archite-ff9eba80347b8b3c47d241007386f7bc.png"}}]);