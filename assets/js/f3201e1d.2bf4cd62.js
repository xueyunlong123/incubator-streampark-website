"use strict";(self.webpackChunkapache_streampark_website=self.webpackChunkapache_streampark_website||[]).push([[1374],{3905:(e,t,n)=>{n.d(t,{Zo:()=>u,kt:()=>k});var r=n(67294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,r,a=function(e,t){if(null==e)return{};var n,r,a={},o=Object.keys(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var l=r.createContext({}),p=function(e){var t=r.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},u=function(e){var t=p(e.components);return r.createElement(l.Provider,{value:t},e.children)},c="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},m=r.forwardRef((function(e,t){var n=e.components,a=e.mdxType,o=e.originalType,l=e.parentName,u=s(e,["components","mdxType","originalType","parentName"]),c=p(n),m=a,k=c["".concat(l,".").concat(m)]||c[m]||d[m]||o;return n?r.createElement(k,i(i({ref:t},u),{},{components:n})):r.createElement(k,i({ref:t},u))}));function k(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var o=n.length,i=new Array(o);i[0]=m;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s[c]="string"==typeof e?e:a,i[1]=s;for(var p=2;p<o;p++)i[p]=n[p];return r.createElement.apply(null,i)}return r.createElement.apply(null,n)}m.displayName="MDXCreateElement"},6645:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>i,default:()=>c,frontMatter:()=>o,metadata:()=>s,toc:()=>p});var r=n(87462),a=(n(67294),n(3905));const o={id:"quick-start",title:"Quick Start",sidebar_position:2},i=void 0,s={unversionedId:"user-guide/quick-start",id:"user-guide/quick-start",title:"Quick Start",description:"How to use",source:"@site/docs/user-guide/2-quickstart.md",sourceDirName:"user-guide",slug:"/user-guide/quick-start",permalink:"/docs/user-guide/quick-start",draft:!1,editUrl:"https://github.com/apache/incubator-streampark-website/edit/dev/docs/user-guide/2-quickstart.md",tags:[],version:"current",sidebarPosition:2,frontMatter:{id:"quick-start",title:"Quick Start",sidebar_position:2},sidebar:"tutorialSidebar",previous:{title:"Platform Deployment",permalink:"/docs/user-guide/deployment"},next:{title:"Development Guide",permalink:"/docs/user-guide/development"}},l={},p=[{value:"How to use",id:"how-to-use",level:2},{value:"Deploy DataStream tasks",id:"deploy-datastream-tasks",level:3},{value:"Deploy the FlinkSql task",id:"deploy-the-flinksql-task",level:3},{value:"Task start process",id:"task-start-process",level:3}],u={toc:p};function c(e){let{components:t,...n}=e;return(0,a.kt)("wrapper",(0,r.Z)({},u,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h2",{id:"how-to-use"},"How to use"),(0,a.kt)("p",null,"The installation of the one-stop platform ",(0,a.kt)("inlineCode",{parentName:"p"},"streampark-console")," has been introduced in detail in the previous chapter. In this chapter, let's see how to quickly deploy and run a job with ",(0,a.kt)("inlineCode",{parentName:"p"},"streampark-console"),". The official structure and specification) and projects developed with ",(0,a.kt)("inlineCode",{parentName:"p"},"streampark")," are well supported. Let's use ",(0,a.kt)("inlineCode",{parentName:"p"},"streampark-quickstart")," to quickly start the journey of ",(0,a.kt)("inlineCode",{parentName:"p"},"streampark-console")),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},"streampark-quickstart")," is a sample program for developing Flink by StreamPark. For details, please refer to:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Github: ",(0,a.kt)("a",{parentName:"li",href:"https://github.com/apache/incubator-streampark-quickstart"},"https://github.com/apache/incubator-streampark-quickstart.git"))),(0,a.kt)("h3",{id:"deploy-datastream-tasks"},"Deploy DataStream tasks"),(0,a.kt)("p",null,"The following example demonstrates how to deploy a DataStream application"),(0,a.kt)("h3",{id:"deploy-the-flinksql-task"},"Deploy the FlinkSql task"),(0,a.kt)("p",null,"The following example demonstrates how to deploy a FlinkSql application"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"The flink sql used in the project demonstration is as follows")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-sql"},"CREATE TABLE user_log (\n    user_id VARCHAR,\n    item_id VARCHAR,\n    category_id VARCHAR,\n    behavior VARCHAR,\n    ts TIMESTAMP(3)\n ) WITH (\n'connector' = 'kafka', -- Using the kafka connector\n'properties.group.id' = 'group01' ,\n'topic' = 'user_behavior',  -- kafka topic\n'properties.bootstrap.servers'='kafka-1:9092,kafka-2:9092,kafka-3:9092',\n'scan.startup.mode' = 'earliest-offset', -- Read from start offset\n'format' = 'json'  -- The data source format is json\n );\n\nCREATE TABLE pvuv_sink (\n    dt VARCHAR,\n    pv BIGINT,\n    uv BIGINT,\n    PRIMARY KEY (dt,pv,uv) NOT ENFORCED\n ) WITH (\n'connector' = 'jdbc', -- using jdbc connector\n'url' = 'jdbc:mysql://test-mysql:3306/test', -- jdbc url\n'table-name' = 'pvuv_sink', -- Table Name\n'username' = 'root', -- username\n'password' = '123456', --password\n'sink.buffer-flush.max-rows' = '1' -- Default 5000, changed to 1 for demonstration\n );\n\nINSERT INTO pvuv_sink\nSELECT\n  DATE_FORMAT(ts, 'yyyy-MM-dd HH:00') dt,\n  COUNT(*) AS pv,\n  COUNT(DISTINCT user_id) AS uv\nFROM user_log\nGROUP BY DATE_FORMAT(ts, 'yyyy-MM-dd HH:00');\n")),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"The maven dependencies are used as follows")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-xml"},"\n<dependency>\n    <groupId>mysql</groupId>\n    <artifactId>mysql-connector-java</artifactId>\n    <version>5.1.48</version>\n</dependency>\n\n<dependency>\n    <groupId>org.apache.flink</groupId>\n    <artifactId>flink-sql-connector-kafka_2.11</artifactId>\n    <version>1.14.6</version>\n</dependency>\n\n<dependency>\n    <groupId>org.apache.flink</groupId>\n    <artifactId>flink-connector-jdbc_2.11</artifactId>\n    <version>1.14.6</version>\n</dependency>\n\n\n")),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"The data sent by Kafka simulation is as follows")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-json"},'\n{"user_id": "543462", "item_id":"1715", "category_id": "1464116", "behavior": "pv", "ts":"2021-02-01 01:00:00"}\n{"user_id": "662867", "item_id":"2244074","category_id":"1575622","behavior": "pv", "ts":"2021-02-01 01:00:00"}\n{"user_id": "662867", "item_id":"2244074","category_id":"1575622","behavior": "pv", "ts":"2021-02-01 01:00:00"}\n{"user_id": "662867", "item_id":"2244074","category_id":"1575622","behavior": "learning flink", "ts":"2021-02-01 01:00:00"}\n\n')),(0,a.kt)("h3",{id:"task-start-process"},"Task start process"),(0,a.kt)("p",null,"The task startup flow chart is as follows"),(0,a.kt)("center",null,(0,a.kt)("img",{src:"/doc/image/streampark_start.png"}),(0,a.kt)("br",null),(0,a.kt)("strong",null,"streampark-console submit task process")),(0,a.kt)("p",null,"Regarding the concept of the project, ",(0,a.kt)("inlineCode",{parentName:"p"},"Development Mode"),", ",(0,a.kt)("inlineCode",{parentName:"p"},"savepoint"),", ",(0,a.kt)("inlineCode",{parentName:"p"},"NoteBook"),", custom jar management, task release, task recovery, parameter configuration, parameter comparison, multi-version management and more tutorials and documents will be continuously updated. .."))}c.isMDXComponent=!0}}]);