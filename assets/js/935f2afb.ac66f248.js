"use strict";(self.webpackChunkapache_streampark_website=self.webpackChunkapache_streampark_website||[]).push([[53],{1109:e=>{e.exports=JSON.parse('{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"link","label":"What is StreamPark","href":"/docs/intro","docId":"intro"},{"type":"category","label":"User guide","collapsible":true,"collapsed":false,"items":[{"type":"link","label":"Platform Deployment","href":"/docs/user-guide/deployment","docId":"user-guide/deployment"},{"type":"link","label":"Quick Start","href":"/docs/user-guide/quick-start","docId":"user-guide/quick-start"},{"type":"link","label":"Development Guide","href":"/docs/user-guide/development","docId":"user-guide/development"},{"type":"link","label":"Docker Tutorial","href":"/docs/user-guide/docker-deployment","docId":"user-guide/docker-deployment"},{"type":"link","label":"LDAP Tutorial","href":"/docs/user-guide/LDAP","docId":"user-guide/LDAP"},{"type":"link","label":"Team & member Management","href":"/docs/user-guide/Team","docId":"user-guide/Team"},{"type":"link","label":"Variable Management","href":"/docs/user-guide/Variable","docId":"user-guide/Variable"},{"type":"link","label":"Yarn Queue Management","href":"/docs/user-guide/YarnQueueManagement","docId":"user-guide/YarnQueueManagement"},{"type":"link","label":"External Link Management","href":"/docs/user-guide/ExternalLink","docId":"user-guide/ExternalLink"},{"type":"link","label":"SSO Integration","href":"/docs/user-guide/SSO","docId":"user-guide/SSO"},{"type":"link","label":"Introduction","href":"/docs/user-guide/platformInstall","docId":"user-guide/platformInstall"},{"type":"link","label":"Quick Start","href":"/docs/user-guide/platformBasicUsage","docId":"user-guide/platformBasicUsage"}]},{"type":"category","label":"Development framework","collapsible":true,"collapsed":false,"items":[{"type":"link","label":"Programming Paradigm","href":"/docs/development/Programming-paradigm","docId":"development/Programming-paradigm"},{"type":"link","label":"Project Configuration","href":"/docs/development/config","docId":"development/config"},{"type":"link","label":"Alert Configuration","href":"/docs/development/alert-conf","docId":"development/alert-conf"}]},{"type":"category","label":"DataStream Connector","collapsible":true,"collapsed":false,"items":[{"type":"link","label":"Apache Kafka Connector","href":"/docs/connector/Kafka-Connector","docId":"connector/Kafka-Connector"},{"type":"link","label":"JDBC Connector","href":"/docs/connector/Jdbc-Connector","docId":"connector/Jdbc-Connector"},{"type":"link","label":"ClickHouse Connector","href":"/docs/connector/Clickhouse-Connector","docId":"connector/Clickhouse-Connector"},{"type":"link","label":"Apache Doris Connector","href":"/docs/connector/Doris-Connector","docId":"connector/Doris-Connector"},{"type":"link","label":"Elasticsearch Connector","href":"/docs/connector/Elasticsearch-Connector","docId":"connector/Elasticsearch-Connector"},{"type":"link","label":"Apache HBase Connector","href":"/docs/connector/Hbase-Connector","docId":"connector/Hbase-Connector"},{"type":"link","label":"Http Connector","href":"/docs/connector/Http-Connector","docId":"connector/Http-Connector"},{"type":"link","label":"Redis Connector","href":"/docs/connector/Redis-Connector","docId":"connector/Redis-Connector"}]},{"type":"link","label":"Advanced extensions","href":"/docs/advanced/","docId":"advanced/advanced"},{"type":"category","label":"Deployment","collapsible":true,"collapsed":false,"items":[{"type":"link","label":"Flink on K8s ","href":"/docs/flink-k8s/k8s-dev","docId":"flink-k8s/k8s-dev"},{"type":"link","label":"Kubernetes PVC Resource usage","href":"/docs/flink-k8s/k8s-pvc-integration","docId":"flink-k8s/k8s-pvc-integration"},{"type":"link","label":"Hadoop Resource Integration","href":"/docs/flink-k8s/hadoop-resource-integration","docId":"flink-k8s/hadoop-resource-integration"}]}]},"docs":{"advanced/advanced":{"id":"advanced/advanced","title":"Advanced Extension","description":"Coming soon","sidebar":"tutorialSidebar"},"connector/Clickhouse-Connector":{"id":"connector/Clickhouse-Connector","title":"ClickHouse Connector","description":"ClickHouse is a columnar database management system (DBMS) for online analytics (OLAP).","sidebar":"tutorialSidebar"},"connector/Doris-Connector":{"id":"connector/Doris-Connector","title":"Apache Doris Connector","description":"Apache Doris Connector","sidebar":"tutorialSidebar"},"connector/Elasticsearch-Connector":{"id":"connector/Elasticsearch-Connector","title":"Elasticsearch Connector","description":"Elasticsearch is a distributed, RESTful style search and data analysis","sidebar":"tutorialSidebar"},"connector/Hbase-Connector":{"id":"connector/Hbase-Connector","title":"Apache HBase Connector","description":"Apache HBase is a highly reliable, high-performance, column-oriented, and scalable distributed storage system. Using HBase technology,","sidebar":"tutorialSidebar"},"connector/Http-Connector":{"id":"connector/Http-Connector","title":"Http Connector","description":"Some background services receive data through HTTP requests. In this scenario, Flink can write result data through HTTP","sidebar":"tutorialSidebar"},"connector/Jdbc-Connector":{"id":"connector/Jdbc-Connector","title":"JDBC Connector","description":"Flink officially provides the JDBC connector for reading from or writing to JDBC, which can provides AT_LEAST_ONCE (at least once) processing semantics","sidebar":"tutorialSidebar"},"connector/Kafka-Connector":{"id":"connector/Kafka-Connector","title":"Apache Kafka Connector","description":"Flink officially provides a connector to Apache Kafka connector for reading from or writing to a Kafka topic, providing exactly once processing semantics","sidebar":"tutorialSidebar"},"connector/Redis-Connector":{"id":"connector/Redis-Connector","title":"Redis Connector","description":"Redis is an open source in-memory data structure storage system that can be used as a database, cache, and messaging middleware. It supports many types of data structures such as strings, hashes, lists, sets, ordered sets and range queries, bitmaps, hyperlogloglogs and geospatial index radius queries. Redis has built-in transactions and various levels of disk persistence, and provides high availability through Redis Sentinel and Cluster.","sidebar":"tutorialSidebar"},"development/alert-conf":{"id":"development/alert-conf","title":"Alert Configuration","description":"StreamPark supports a variety of alerts, mainly as follows\uff1a","sidebar":"tutorialSidebar"},"development/config":{"id":"development/config","title":"Project Configuration","description":"Configuration is very important in StreamPark.","sidebar":"tutorialSidebar"},"development/Programming-paradigm":{"id":"development/Programming-paradigm","title":"Programming Paradigm","description":"There are some rules and conventions to be followed in any framework. Only by following and mastering these rules can we use them more easily and achieve twice the result with half the effort.When we develop Flink job, we actually use the API provided by Flink to write an executable program (which must have a main() function) according to the development method required by Flink. We access variousConnectorin the program, and after a series of operatoroperations, we finally sink the data to the target storage through the Connector .","sidebar":"tutorialSidebar"},"flink-k8s/hadoop-resource-integration":{"id":"flink-k8s/hadoop-resource-integration","title":"Hadoop Resource Integration","description":"Using Hadoop resource in Flink on K8s","sidebar":"tutorialSidebar"},"flink-k8s/k8s-dev":{"id":"flink-k8s/k8s-dev","title":"Flink on K8s ","description":"StreamPark Flink Kubernetes is based on Flink Native Kubernetes and support deployment modes as below\uff1a","sidebar":"tutorialSidebar"},"flink-k8s/k8s-pvc-integration":{"id":"flink-k8s/k8s-pvc-integration","title":"Kubernetes PVC Resource usage","description":"Resource usage instructions of K8s PVC","sidebar":"tutorialSidebar"},"intro":{"id":"intro","title":"What is StreamPark","description":"make stream processing easier!!!","sidebar":"tutorialSidebar"},"user-guide/deployment":{"id":"user-guide/deployment","title":"Platform Deployment","description":"The overall component stack structure of StreamPark is as follows. It consists of two major parts: streampark-core and streampark-console. streampark-console is a very important module, positioned as a integrated real-time data platform,  streaming data warehouse Platform, Low Code, Flink & Spark task hosting platform, can better manage Flink tasks, integrate project compilation, publishing, parameter configuration, startup, savepoint, flame graph ( flame graph ), Flink SQL, monitoring and many other functions are integrated into one, which greatly simplifies the daily operation and maintenance of Flink tasks and integrates many best practices. Its ultimate goal is to create a one-stop big data solution that integrates real-time data warehouses and batches","sidebar":"tutorialSidebar"},"user-guide/development":{"id":"user-guide/development","title":"Development Guide","description":"Environment Requirements","sidebar":"tutorialSidebar"},"user-guide/docker-deployment":{"id":"user-guide/docker-deployment","title":"Docker Tutorial","description":"This tutorial uses the docker method to deploy StreamPark via Docker.","sidebar":"tutorialSidebar"},"user-guide/ExternalLink":{"id":"user-guide/ExternalLink","title":"External Link Management","description":"Background","sidebar":"tutorialSidebar"},"user-guide/LDAP":{"id":"user-guide/LDAP","title":"LDAP Tutorial","description":"LDAP Introduction","sidebar":"tutorialSidebar"},"user-guide/platformBasicUsage":{"id":"user-guide/platformBasicUsage","title":"Quick Start","description":"Note: This section is designed to provide a convenient process for submitting Flink jobs using the StreamPark platform through simple operational steps.","sidebar":"tutorialSidebar"},"user-guide/platformInstall":{"id":"user-guide/platformInstall","title":"Introduction","description":"Purpose and Scope","sidebar":"tutorialSidebar"},"user-guide/quick-start":{"id":"user-guide/quick-start","title":"Quick Start","description":"How to use","sidebar":"tutorialSidebar"},"user-guide/SSO":{"id":"user-guide/SSO","title":"SSO Integration","description":"Background","sidebar":"tutorialSidebar"},"user-guide/Team":{"id":"user-guide/Team","title":"Team & member Management","description":"User Management","sidebar":"tutorialSidebar"},"user-guide/Variable":{"id":"user-guide/Variable","title":"Variable Management","description":"Background Introduction","sidebar":"tutorialSidebar"},"user-guide/YarnQueueManagement":{"id":"user-guide/YarnQueueManagement","title":"Yarn Queue Management","description":"Background","sidebar":"tutorialSidebar"}}}')}}]);